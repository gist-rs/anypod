Agentic systems: enterprise connectors, new evals, and reliability

Mistral Le Chat adds 20+ MCP connectors and “Memories.” Le Chat now plugs into Stripe, GitHub, Atlassian, Linear, Notion, Snowflake (coming soon), and more, with fine-grained access controls and persistent, user-editable memory. This turns Le Chat into a single surface for cross-SaaS action and retrieval, while remaining enterprise-manageable. See the launch thread from @MistralAI and Stripe’s demo by @emilygsands.

Benchmarking agents:

Artificial Analysis updated its Intelligence Index (V3) to include Terminal-Bench Hard and τ²-Bench (Telecom). GPT‑5 leads, with o3 close behind; xAI’s Grok Code Fast 1/Grok 4 and Claude/Kimi/gpt-oss families perform well on tool calling/agent tasks. Details: @ArtificialAnlys, follow-up 1, 2.

MCP‑Universe (Salesforce) evaluates agents across 231 real-world tasks using actual MCP servers (Google Maps, GitHub, Yahoo Finance, Playwright, etc.) with code-based evaluators. Top model achieves 43.7% success; performance is highly domain-specific; “more tools” can hurt. Links: @_philschmid, paper/leaderboard.

TAU Bench caveat: a no-tool SFT baseline can beat Qwen3‑4B in the Airline domain by being sycophantic; fix proposed to restore tool-use signal: @_lewtun, follow-ups, 2.
Reliability tooling: Galileo’s agent evals (real-time guardrails, Luna‑2) target production reliability and cost, which Gartner predicts will sink 40% of projects by 2027: @omarsar0, 2, 3. Also see the “xpander” agent backend (memory, tools, state, guardrails; self-hostable): @_avichawla, repo.
Finally, OpenPipe published a recipe to train a deep research agent via RL that beats Sonnet‑4 on DeepResearch Bench in ~30 hours on an H200 (~$350): @corbtt, follow-up.

High‑performance RL and inference: Slime v0.1.0, ZeroGPU AoT, symmetric all‑to‑all, and 4‑/8‑bit

Zhipu/THUDM open-sourced Slime v0.1.0, the RL infra behind GLM‑4.5. Highlights: FP8 rollout, DeepEP, multi‑token prediction, speculative decoding, unified tensor offload via CUDA VMM (LD_PRELOAD hijack of cudaMalloc/free), CPU Adam, Megatron + DeepEP support, GSPO for MoE. Result: GLM‑4.5 (355B‑A32B) decoding improved from <10 to 60–70 tok/s; used in 8‑node GLM‑4.5 and 16‑node DeepSeek‑R1 training. Clever NCCL teardown to reclaim memory; fixes for DeepEP overlap edge cases. Deep dive: @ZhihuFrontier, feature checklist.

PyTorch symmetric memory + custom all‑to‑all: intranode all2all can be up to ~1.9× faster on H100s with symmetric memory and low‑contention routes vs defaults; large gap in stock PyTorch surfaced by @cloneofsimo and thread update, with discussion from @giffmana.

ZeroGPU AoT compilation (Hugging Face Spaces): Ahead‑of‑time compiling models before deploy shrinks cold starts and improves throughput (reported 1.3–1.8× for FLUX/Wan). Blog + examples: @RisingSayak, 1, 2. Integrated into anycoder demos: @_akhaliq, app.

Precision/efficiency notes: NVIDIA’s NVFP4 4‑bit training ablations stirred discussion (@eliebakouch, follow-up); INT4 Seed‑OSS model reports “no accuracy loss” with vLLM inference (@HaihaoShen).

Adaptive LLM routing under budget constraints frames router design as a contextual bandit to optimize quality per cost, supporting user‑budget policies: @omarsar0, paper.

Model releases and capabilities

Microsoft’s rStar2‑Agent (14B, agentic RL) achieves frontier‑level math/tooling performance using GRPO‑RoC and a multi‑stage SFT→RL recipe; trained on 64 MI300Xs for 510 RL steps. Scores: AIME24 80.6%, AIME25 69.8%, beating DeepSeek‑R1 (671B). Code: @iScienceLuvr, repo/abs.

Hermes 4 open‑weight reasoning (Nous): 70B/405B (Llama‑3.1 bases) with hybrid explicit thinking (<think>…</think>), assistant‑only loss, long trajectories (up to 16k), tool‑aware formatting, strong math/code/alignment, and refusal dynamics. Dense training details and infra (TorchTitan/FSDP/TP, Flex Attention, DataForge). Summary: @gm8xx8.

Tencent Hunyuan‑MT‑7B (translation) and Hunyuan‑MT‑Chimera (ensemble), supporting 33 languages including 5 Chinese minority languages; demos on HF/Gradio: @_akhaliq, demo, plus @SOSOHAJALAB.

Small VLM: R‑4B (Apache‑2.0) claims SoTA small vision‑LM with reasoning; Transformers integration with custom code: @mervenoyann, model.

Video/AV: AUSM (Autoregressive Universal Video Segmentation) ties LLM‑style AR pipelines to streaming video perception: @miran_heo. VibeVoice (long‑form TTS via next‑token diffusion) generates up to 90 minutes of 4‑speaker dialogue in a 64k window with 80× compression vs Encodec and strong coherence: @TheTuringPost.

Data, toolchains, and developer updates

Jupyter Agent Dataset (Hugging Face): 2B tokens from 51k Kaggle notebooks + 7TB datasets, with real code‑execution traces (Qwen3‑Coder + E2B); substantially improves code execution/data analysis skills. Launch: @a_yukh, recap: @maximelabonne.

LangChain/LangGraph 1.0 alpha (Py/JS): LangGraph remains the low‑level agent orchestration substrate; LangChain 1.0 refocuses around a central agent abstraction and standardized content blocks, keeping model/vendor portability. Announcement: @LangChainAI, @hwchase17.

Vector/routing and on‑device: Qdrant adds post‑search relevance re‑scoring (freshness/proximity/decay functions) for business logic alignment (1, 2); ChromaSwift (beta) brings retrieval to iOS with on‑device MLX embeddings and persistence: @trychroma.

Code execution ergonomics: Anthropic API added bash, view/create/str_replace primitives, Seaborn/OpenCV, and extended container lifetime to 30 days, cutting tokens and enabling richer workflows: @alexalbert__, update.

One‑liners: Chainlit remains a fast UI scaffold for LLM chats (@rasbt); Google’s Gemini URL Context fetches and processes up to 20 URLs inline with no extra tool pricing (@LiorOnAI).

Industry/platform moves

Anthropic raised $13B at a $183B post‑money valuation led by ICONIQ, citing capacity expansion, model capability, and safety research: @AnthropicAI.

OpenAI: acquired Statsig; founder @vijayeraji becomes CTO of Applications (ChatGPT/Codex). @kevinweil launches “OpenAI for Science” to build an AI-powered scientific instrument; role note. Realtime API continues to mature (tips); @weights_biases added DeepSeek V3.1 and gpt‑oss‑20B/120B to OpenRouter via W&B Inference.

Research highlights

Diffusion Language Models can “early commit.” On GSM8K/MMLU, correct answers can be identified by half the refinement steps (97%/99% of cases). Prophet is a training‑free fast‑decoding scheme that decides when to stop sampling: @iScienceLuvr, abs.

AHELM (audio‑language eval). Holistic ALM benchmark across 10 aspects (perception, reasoning, fairness, multilinguality, toxicity, etc.), with new PARADE and CoRe‑Bench. Gemini 2.5 Pro leads 5/10 but shows group unfairness in ASR: @iScienceLuvr, abs/site.

DyT: Transformers without normalization layers (Dynamic Tanh replaces LayerNorm/RMSNorm) claim SOTA across vision, language, speech in reported settings: @LiorOnAI, abs/code.

Goldfish Loss: randomly drop tokens from the cross‑entropy loss to mitigate memorization while preserving downstream performance; potentially useful for exploration in low‑data reasoning RL: @vikhyatk, paper.

STREAM: a checklist for transparent ChemBio safety eval reporting (e.g., human baselines), to make peer review tractable: @lucafrighetti, context.
