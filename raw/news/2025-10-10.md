Humanoid Robotics: Figure 03 launch, capabilities, and industry moves

Introducing Figure 03: Figure unveiled its next-gen humanoid with a highly produced demo and a detailed write-up on system design and product goals. The team emphasizes “nothing in this film is teleoperated,” positioning F.03 for “Helix, for the home, and for the world at scale.” See launch and follow-ups from @Figure_robot, @adcock_brett, and write-up links from @adcock_brett. For broader robotics context: SoftBank is acquiring ABB’s robotics unit for $5.4B per The Rundown.

Discussion: Early reviews note some demo quirks (e.g., sorting choices), but overall the capability trajectory and non-teleop claim drew strong interest from practitioners; see reactions from @Teknium1.

Open frontier modeling and releases: Reflection’s $2B, Diffusion LMs, GLM-4.6, and small-model reasoning

Reflection raises $2B to build frontier open-weight models: The lab is scaling large MoE pretraining and RL from scratch with an explicit open-intelligence roadmap (safety and evals emphasized). Founder and team context (AlphaGo, PaLM, Gemini contributors) and hiring across SF/NY/London. Read the statement from @reflection_ai and commentary by @achowdhery and @ClementDelangue.

Diffusion Language Models go bigger (open): Radical Numerics released RND1, a 30B-parameter sparse MoE DLM (3B active), with weights, code, and training details to catalyze research into DLM inference/post-training and a simple AR-to-diffusion conversion pipeline. See the announcement and resources via @RadicalNumerics and a concise summary thread by @iScienceLuvr.

Zhipu’s GLM-4.6 and open models momentum: Zhipu’s GLM-4.6 posts strong results on the Design Arena benchmark per @Zai_org. Cline notes GLM-4.5-Air and Qwen3-Coder are the most popular local models in their agent IDE (tweet).

Tiny reasoning at the edge: AI21’s Jamba Reasoning 3B leads “tiny” reasoning models with 52% on IFBench per @AI21Labs. Related, Alibaba’s Qwen continues to push breadth: Qwen3-Omni (native end-to-end multimodal) and Qwen-Image-Edit 2509 now ranked #3 overall, leading open-weight models (@Alibaba_Qwen, tweet).

Developer tools and agent stacks: Claude Code plugins, VS Code AI, Gemini ecosystem

Claude Code opens up plugins: Anthropic shipped a plugin system and marketplace for Claude Code. Update your CLI and add via “/plugin marketplace add anthropics/claude-code.” Early community marketplaces emerging. See threads from @The_Whole_Daisy and @_catwu.

VS Code v1.105 September release: AI-first UX improvements include GitHub MCP registry integration, AI merge-conflict resolution, OS notifications, and chain-of-thought rendering with GPT-5-Codex. Details and livestream via @code.

Google’s Gemini platform updates: New “model search” in AI Studio (@GoogleAIStudio), hosted docs for the Gemini CLI (@_philschmid), and “Gemini Enterprise” as a no-code front door to build agents and automate workflows across Workspace/M365/Salesforce and more (@Google, @JeffDean).

Memory and eval-driven optimization in agent pipelines: Developers test memory layers like Mem0 (@helloiamleonie) and use DSPy/GEPA to switch models at 20x lower cost without regressions (@JacksonAtkinsX); see also DSPy TS usage demo (@ryancarson).

Benchmarks and evaluations: ARC-AGI, METR time-horizons, FrontierMath, and domain leaderboards

GPT-5 Pro posts new SOTA on ARC-AGI: Verified by ARC Prize, GPT-5 Pro achieved 70.2% on ARC-AGI-1 ($4.78/task) and 18.3% on ARC-AGI-2 ($7.41/task), the highest frontier LLM score on the semi-private benchmark to date (@arcprize).

Time-horizon on agentic SWE tasks: METR estimates Claude Sonnet 4.5’s 50%-time-horizon at ~1 hr 53 min (CI 50–235 min), a statistically significant improvement over Sonnet 4 but below Opus 4.1 point estimates; see @METR_Evals.

Math and reasoning evaluations: Epoch reports Gemini 2.5 “Deep Think” set a new record on FrontierMath (manual API evaluation due to lack of public API), with broader math capability analysis in thread (@EpochAIResearch). ARC-AGI numbers prompted debate on recent progress pacing vs. trendlines (see @scaling01, @teortaxesTex).

Vision/editing and design tasks: Qwen Image Edit 2509 ranks #3 overall, leading open-weight models (@Alibaba_Qwen). GLM-4.6 shows strong performance on Design Arena (@Zai_org).

Systems, performance, and infra: GPU kernels, inference benchmarking, and MLX speed

GPU kernels and “register tiles”: tinygrad is porting ThunderKittens’ “register tile” abstraction (“registers are the wrong primitive”) as “tinykittens,” citing simpler yet performant GPU code (tinygrad). Awni Hannun dropped a concise MLX matmul primer to illuminate tensor core fundamentals (tweet).

Real-world inference benchmarking at scale: SemiAnalysis launched InferenceMAX, a daily cross-stack benchmark suite spanning H100/H200/B200/GB200/MI300X/MI325X/MI355X (soon TPUs/Trainium), focused on throughput, cost per million tokens, latency/throughput tradeoffs, and tokens per MW across modern servers and inference stacks (@dylan522p).

On-device and Apple silicon: Qwen3-30B-A3B 4-bit hits 473 tok/s on M3 Ultra via MLX (@ivanfioravanti). Google released a Gemma 3 270M fine-tune-to-deploy flow that compresses to <300MB and runs in-browser/on-device (@googleaidevs; tutorial by @osanseviero).

Multimodal/video: Sora 2 momentum, Genie 3 recognition, and WAN 2.2

Sora 2 growth + free HF demo: Sora 2 hit 1M app downloads in under 5 days (despite invites and NA-only) with rapid iteration on features and moderation (@billpeeb). A limited-time Sora 2 text-to-video demo is live on Hugging Face and getting used in the wild (tweet). The cameo use-case exploded, with notable NIL-driven virality (@jakepaul).

Genie 3 named a TIME Best Invention: Google DeepMind’s interactive world model continues to draw attention for generating playable environments from text/image prompts (@GoogleDeepMind, @demishassabis).

WAN 2.2 Animate tips and workflows: Community tutorials show improved lighting/flame behavior and practical pipelines for animation tasks (@heyglif, @jon_durbin).

Safety, bias, and security

Few-shot poisoning may suffice: Anthropic, with UK AISI and the Turing Institute, shows that a small, fixed number of malicious documents can implant backdoors across model sizes—challenging prior assumptions that poisoning requires a sizable dataset fraction. Read the summary and paper from @AnthropicAI.

Political bias definitions and evaluation: OpenAI researchers propose a framework to define, measure, and mitigate political bias in LLMs (@nataliestaud).


Notes

Elastic acquired Jina AI to deepen multimodal/multilingual search and context engineering in Elastic’s agentic stack (tweet).

Gemini crossed 1.057B visits in Sept 2025 (+285% YoY), its first month over 1B visits (@Similarweb).

State of AI 2025 is out; usage, safety, infra, and research trends summarized (@nathanbenaich).



AI Reddit Recap
/r/LocalLlama + /r/localLLM Recap
1. Microsoft UserLM-8B 'User' Role-Simulation Model Announcement
microsoft/UserLM-8b - “Unlike typical LLMs that are trained to play the role of the 'assistant' in conversation, we trained UserLM-8b to simulate the 'user' role” (Activity: 548): Microsoft’s UserLM-8b is an 8B-parameter user-simulator LLM fine-tuned from Llama3‑8b‑Base to predict user turns (from WildChat) rather than act as an assistant; it takes a single task-intent input and emits initial/follow-up user utterances or an <|endconversation|> token (paper, HF). Training used full-parameter finetuning on a filtered WildChat‑1M with max seq len 2048, batch size 1024, lr 2e-5, on 4× RTX A6000 over ~227 h. Evaluations report lower perplexity (distributional alignment), stronger scores on six intrinsic user-simulator metrics, and broader/diverse extrinsic simulation effects versus prompted assistant baselines; the research release warns of risks (role drift, hallucination, English-only testing, inherited biases) and recommends guardrails (token filtering, end-of-dialogue avoidance, length/repetition thresholds). Commenters highlight the meta trend of AI training/evaluating AI and express safety/availability concerns (possible takedown), with little substantive technical critique in-thread.

Several commenters highlight the closed-loop risk of "AI evaluating AI" if UserLM-8b is used to simulate users that other models then optimize against. This can induce feedback loops and distribution shift where models overfit to the simulator’s style/tokens, degrading benchmark validity and leading to artifacts like reward hacking, prompt overfitting, and misleading improvements that don’t transfer to real users.

There’s concern the release might be pulled for safety reasons, implying reproducibility and availability risk for experiments with UserLM-8b. Practically, this means researchers should pin exact checkpoints and versions early to preserve comparability across runs and avoid future benchmark drift if artifacts/weights are taken down or altered.

Tiny reasoning models, JEPA density estimation, and new multimodal LLMs

Samsung’s 7M Tiny Recursive Model (TRM): A simple, highly efficient recursive reasoner that beats prior HRM (27M) on ARC-AGI and Sudoku using a smaller, single-network design and full backprop through recursion. Notable findings: fewer layers improved generalization (4→2 layers: 79.5%→87.4% on Sudoku) and swapping self-attention for MLP helped in fixed-length contexts. Great overview from @rasbt, with the paper trending per @jm_alexia. Paper: https://arxiv.org/abs/2510.04871

JEPA-SCORE turns encoders into density estimators: LeCun’s team shows the JEPA anti-collapse term implicitly estimates data density. From any trained JEPA (I-JEPA, DINOv2, MetaCLIP), compute p(x) in closed form via the Jacobian to power data curation, outlier detection, etc., no retraining required. Details via @jiqizhixin and the authors’ note @randall_balestr; paper: arxiv.org/abs/2510.05949.

AI21’s Jamba Reasoning 3B (Apache-2.0): Hybrid SSM-Transformer model tops speed/accuracy at long context; 3–5x faster vs Llama 3.2 3B and Qwen3 4B at 32K tokens; ~16 tok/s at 16K context on iPhone 16 Pro; up to 64K context. Available on HF/Kaggle/LM Studio/llama.cpp. @AI21Labs, 1, 2.

Alibaba’s Qwen3 Omni/Omni Realtime: Natively unified audio–video–text architecture with “Thinker” and “Talker” MoEs; 119 text languages, 19 speech-in, 10 speech-out. BigBench Audio: 58–59% (vs Gemini 2.0 Flash 36%, below GPT‑4o Realtime 68%); time-to-first-audio 4.8s (30B) / 0.9s (Realtime). 30B weights (Instruct/Thinking/Captioner) released under Apache-2.0. Summary via Artificial Analysis and follow-up.

Open-weight image editing leader from Alibaba: Qwen Image Edit 2509 debuts multi-image editing; #3 overall in the Artificial Analysis Arena and top open-weights model; Apache-2.0 with weights on HF; priced $30/1k images on fal/replicate. Benchmarks via @ArtificialAnlys and acknowledgement from @Alibaba_Qwen.

Retrieval at micro-scale: New ColBERT Nano models at 250K–950K params show late interaction can work shockingly well at tiny sizes. Models and collection from @neumll; reaction from @lateinteraction.

RL and agentic systems: serverless, in-the-flow optimization, and code eval

Serverless RL lands (CoreWeave × W&B × OpenPipe): Train agents faster/cheaper with zero infra. Claims: 40% cheaper, 28% faster wall-clock vs self-managed GPUs; instant deploy to prod via W&B Inference; includes ART (trainer) and RULER (universal verifier). Launch posts from @corbtt, @weights_biases, @CoreWeave. Context: CoreWeave acquired OpenPipe on Sept 8; product shipped Oct 8 per @shawnup and covered by WIRED.

AgentFlow (Stanford): in-the-flow RL for tool use and planning: A team of Planner/Executor/Verifier/Generator agents with Flow-GRPO trains the Planner inside the system. On 10 benchmarks, a 7B backbone beats Llama‑3.1‑405B and GPT‑4o on multiple categories (avg +14% on search/agentic/math). Code/models/demo: @lupantech, paper via @_akhaliq.

ADK goes protocol-native: Google’s open-source Agent Development Kit now supports MCP (tools), A2A (agents), and AG‑UI (user/agent UX) and plugs into React via CopilotKit—bridging backend agents to full-stack apps. Overview by @_avichawla and repo link AG‑UI.

Executable code eval at scale: BigCodeArena introduces human-in-the-loop evaluation on runnable code (vs text-only preference data) across languages—opening the door to more faithful code generation assessment. Announced by @BigCodeProject and contributors @terryyuezhuo.

Also notable: LoRA-for-RL baseline repo to compare LoRA/DoRA/QLoRA in RL (UpupWang); semi‑online DPO (Meta) summary and HF link (ben_burtenshaw); OpenAI spotlight on prompt optimizers (GEPA) (DSPyOSS).

Tooling and infra: no‑GIL Python lands, “voice‑prompt” dev, and Sora integrations

Python 3.14: free‑threaded interpreter is no longer experimental—a major unlock for multi-core Python without the GIL. Announcement via @charliermarsh. Pydantic 2.12 shipped same day with 3.14 support (samuel_colvin).

Google AI Studio adds voice “vibe coding”: Dictate app changes or features; STT auto-cleans fillers for cleaner prompts. Demos/links from @GoogleAIStudio and @ammaar.

Stripe for AI builders: New API to track model pricing changes and protect margins; Agentic Commerce Protocol + Shared Payment Tokens; and “Stripe inside Gemini” for commerce flows. Details from @emilygsands and follow-up 1, 2.

Sora 2: fast integrations and public demo:

MCP server for Sora (generate/remix/status/download) by @skirano.

Time-limited free text→video demo on Hugging Face (_akhaliq); Sora app hit 1M downloads in <5 days despite invite-flow constraints (billpeeb).

Runway Gen‑4 Turbo now supports arbitrary 2–10s durations via API—pay for what you generate (RunwayMLDevs).

Infra tidbits: Together’s Instant Clusters get burn‑in/NVLink/NCCL validation and token/sec reference runs (togethercompute); ThunderKittens “register tile” insight coming to tinygrad (tinygrad); LFM2MoE 8B 3‑bit on iPhone 17 Pro with MLX (sach1n).

Funding, talent, and leaderboards

Grid-scale bet on batteries: Base Power raised a $1B Series C to build “America’s next power company,” scaling manufacturing in Austin to put a battery on every home; multiple top-tier investors participated. Details from @ZachBDell and @JLopas.

Relace raises $23M (a16z) to build rails for AI codegen: Shipping the fastest apply model on OpenRouter (10k tok/s), SOTA code reranking and embeddings; working on Relace Repos (retrieval-native SCM). Announcements via @steph_palazzolo and @pfactorialz.

Key talent move: Shunyu Yao left Anthropic for Google DeepMind; cited disagreement with Anthropic’s public China stance among reasons. Background via @Yuchenj_UW and profile by @ZhihuFrontier.

Open model leaderboard movement: DeepSeek‑V3.2‑Exp (MIT license) enters LM Arena Top‑10; its “thinking” variant is now #2 open model (arena).

Data, evaluation, and retrieval practices

Rolling “Humanity’s Last Exam”: CAIS released a dynamic fork of the well-known eval dataset on HF Datasets that swaps easier questions for harder ones as models improve; gated to avoid contamination. Commentary and broader evals roadmap by @Thom_Wolf.

Understanding model heuristics: Goodfire AI models LLM behavior via causal abstraction to disentangle competing algorithms even on simple tasks (GoodfireAI).

Sycophancy has behavioral costs: Interaction with sycophantic AIs reduced willingness to repair interpersonal conflict while increasing beliefs of being right (camrobjones).

Retrieval and parsing tips: Micro‑ColBERT late interaction retrievers (250K params) punch above size class (lateinteraction); LlamaIndex’s parse vs extract design guide for document agents (llama_index).

OpenAI Dev Day: Apps, Agents, Codex, and developer tooling

Apps SDK, AgentKit, ChatKit Studio, Guardrails, Evals: A comprehensive drop of building blocks for agentic apps was cataloged by @swyx with official links: Apps in ChatGPT + Apps SDK, AgentKit, ChatKit Studio, Guardrails, and Evals. New models include GPT‑5 Pro, realtime/audio/image minis, and API access to Sora 2 / Sora 2 Pro. Early developer feedback spans:

Positive onboarding and fast MCP server hookup (example).

Codex (OpenAI’s new internal dev tool) GA: Slack integration praised and “accelerating work” internally; also a visible “1T token award” culture push (@gdb, @gdb, @gdb).

Cursor added “plan mode” to let agents run longer via editable Markdown plans (@cursor_ai).

Debate on “workflow builders”: Several argue visual flowcharts are brittle/limited vs. code-first orchestration and agent loops with tools. See critiques and alternatives from @assaf_elovic, @hwchase17, @jerryjliu0, @skirano, and clarifications on agent semantics (@fabianstelzer, @BlackHC).

Agents, program synthesis, and UI control

Google DeepMind’s CodeMender (security agent): Automatically finds and patches critical vulnerabilities at scale; 72 upstreamed fixes, handles codebases up to 4.5M LOC, and uses program analysis for validation (blog, details).

Microsoft Agent Framework (AutoGen + Semantic Kernel): A unified, open-source SDK for enterprise multi-agent systems; Azure AI Foundry-first, with long-running workflows, OpenTelemetry tracing, Voice Live API GA, and responsible AI tooling (overview, blog).

Gemini 2.5 Computer Use (UI agents): New model to control browsers and Android UIs via vision + reasoning; API preview and integration examples (e.g., Browserbase) shared by @GoogleDeepMind and @osanseviero.

Agent courses and frameworks: Andrew Ng’s Agentic AI course focuses on reflection, tool use, planning, and multi-agent collaboration; LlamaIndex Workflows/Agents emphasize code-first orchestration with state mgmt and deployment; commentary on multi-agent shared memory (MongoDB blog).

Open models and benchmarks: GLM 4.6, Qwen3-VL, DeepSeek, MoE-on-edge

GLM‑4.6 (Zhipu) update: MIT-licensed, MoE 355B total/32B active, now with 200K context. Independent evals report +5 pts vs 4.5 in reasoning mode (56 on AAI), better token efficiency (−14% tokens at similar quality), and broad API availability (DeepInfra FP8, Novita/GMI BF16, Parasail FP8). Self-hosting in BF16 ~710 GB (summary, evals).

Open-weights closing the agentic gap: On Terminal‑Bench Hard (coding + terminal), DeepSeek V3.2 Exp, Kimi K2 0905, and GLM‑4.6 show major gains; DeepSeek surpasses Gemini 2.5 Pro in this setting (analysis). On GAIA2, DeepSeek v3.1 Terminus looks strong for OSS agents (note).

Vision leaderboards: Qwen3‑VL reached #2 on vision, making Qwen the first open-source family to top both text and vision leaderboards (@Alibaba_Qwen); Tencent’s Hunyuan‑Vision‑1.5‑Thinking reached #3 on LMArena (@TencentHunyuan). Sora 2 and Sora 2 Pro are now in the Video Arena for head‑to‑head comparisons (@arena).

Liquid AI LFM2‑8B‑A1B (smol MoE on-device): 8.3B total/1.5B active, pretrained on 12T tokens, runs via llama.cpp/vLLM; early reports show it outpacing Qwen3‑1.7B on Galaxy S24 Ultra and AMD HX370 (announce, arch, bench, wrap).

Research threads worth reading

New attention variant (CCA): Zyphra’s Compressed Convolutional Attention executes attention in a compressed latent space; claims lower FLOPs, KV cache on par with GQA/MLA, and 3x fewer params vs MHA, with a fused kernel for real speedups. Paper + kernels in thread (announce, context).

Tiny Recursion Model (TRM, 7M params): Recursive-reasoning model hits 45% on ARC‑AGI‑1 and 8% on ARC‑AGI‑2, surpassing many LLMs at a fraction of size—follow‑up to HRM with 75% fewer params (@jm_alexia, discussion).

Training and RL advances:

Evolution Strategies at scale outperform PPO/GRPO for some LLM finetuning regimes (@hardmaru).

Reinforce‑Ada addresses GRPO signal collapse; drop‑in, sharper gradients (@hendrydong).

BroRL argues scaling rollouts (broadened exploration) beats step-scaling plateau (thread).

TRL now supports efficient online training with vLLM; Colab → multi‑GPU (guide).

Compression, vision, tokenization, and sims:

SSDD (Single‑Step Diffusion Decoder) improves image autoencoder reconstructions with single‑step decode (thread).

VideoRAG: scalable retrieval + reasoning over 134+ hours via graph-grounded multimodal indexing (overview).

SuperBPE tokenizer (“Tokenization from first principles”) claims 20% training sample efficiency gains via cross-word merges (@iamgrigorev).

iMac: world-model training with imagined autocurricula for generalization (@ahguzelUK).

REFRAG write‑up suggests vector‑conditioned generation yields big TTFT/throughput gains; treat as exploratory community analysis (summary).

Infra, inference, and tooling

Hugging Face:

In‑browser GGUF metadata editing via Xet-based partial file updates (@ngxson, @ggerganov).

TRL RFC to simplify trainers to the most-used paths (RFC).

Academia Hub adds University of Zurich; ZeroGPU access and collab features (announce).

Scaling and ops:

SkyPilot docs for scaling TorchTitan beyond Slurm (K8s/clouds) (@skypilot_org, @AIatMeta).

Distributed training ops: handy MPI visuals PDF (@TheZachMueller); asynch send/recv walkthrough (post).

KV caching explained + speed impact, with a concise visual recap (@_avichawla).

GPU cluster sanity checks: HF’s gpu-friends used for node stress testing (@_lewtun). Active chatter on cloud H100 pricing/capacity (e.g.).

Benchmarks, evals, and community

Leaderboards and evals: Open‑vs‑closed gap narrows on agentic tasks (@hardmaru); Qwen3‑VL and Hunyuan‑Vision wins noted above; multiple COLM papers on reasoning, ToM, long‑context coding, unlearning, etc. (Stanford NLP list, talks).

Courses, events, and tools:

DeepLearning.AI’s Agentic AI course by @AndrewYNg.

NVIDIA Robotics fireside (BEHAVIOR benchmark) with @drfeifei.

Together’s Batch Inference API upgrades for larger datasets and lower costs (thread).
