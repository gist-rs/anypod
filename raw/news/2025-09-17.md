Agentic coding and IDEs: GPT‑5 Codex rollout, IDE context, MCP everywhere

GPT‑5 Codex, big surface area, mixed DX: Developers report impressive agentic capabilities and front‑end generation demos alongside frustrating harness quirks and long‑running loops. Positive: building full React apps and animated videos end‑to‑end with Codex agents @gdb, @OpenAIDevs. Critical: token bloat/looping and unclear controls @Teknium1, @finbarrtimbers. OpenAI infra partners note degraded throughput due to demand @thsottiaux. Analysis: Codex intentionally “spends effort where it matters” (more tokens on hard problems), trading latency for quality @TheTuringPost.

IDE stack upgrades: VS Code Insiders is experimenting with 200k‑token contexts for GPT‑5 and Claude Sonnet 4 @pierceboggan; the GitHub MCP Registry is integrated in VS Code for one‑click server discovery @code. Cursor 1.6 adds custom commands, a faster Agent terminal, MCP Resources, and /summarize @cursor_ai. GitHub Copilot in VS Code will auto‑select models per task (public preview) @amandaksilver. Perplexity Pro exposes native connectors for Gmail/Calendar/Notion/GitHub; Enterprise adds Linear/Outlook @perplexity_ai, @AravSrinivas.

Inference and training infra: vLLM on aarch64/GB200, ROCm update, CP in TRL, Mac MLX speed

vLLM 0.10.2 ships official aarch64 (works on NVIDIA GB200) with multi‑platform Docker images; more perf work coming @vllm_project. Good explainer threads continue to circulate on the core serving bottleneck (KV/QK cache) and how PagedAttention helps @athleticKoder.

ROCm major upgrade: AMD pushes a broad stack update spanning modern attention variants, sparse MoE, distributed inference, and RL/reasoning support—with laptop/desktop availability @realSharonZhou.

Context Parallelism for long‑context training: TRL adds CP to shard sequences across GPUs and across nodes; integrates with Accelerate @SergioPaniego. Hugging Face Transformers is refactoring MoEs onto native kernels with big wins @art_zucker.

RL and robotics data plumbing: Unsloth + vLLM weight sharing cuts multimodal RL VRAM >50%, enabling longer contexts and reward shaping for math/logic VLMs @danielhanchen. LeRobotDataset v3 introduces chunked episodes, efficient video streaming, and parquet metadata for OXE‑scale learning @LeRobotHF.

Mac MLX velocity: Qwen3‑Next‑80B 4‑bit runs at ~66 tok/s on M4 Max 64GB, using ~41GB @rwojo; LM Studio added Qwen3‑Next with MLX, and batch generation demos show strong multi‑stream throughput @lmstudio, @awnihannun.

New models, agents, and spatial intelligence

HunyuanImage 2.1 (Tencent): 17B DiT text‑to‑image, native 2048×2048, bilingual, tops Artificial Analysis arena vs HiDream‑I1‑Dev and Qwen‑Image. “Open weights” under a restrictive Tencent Community License: bans EU/UK/KR use, MAU >100M products, and using outputs to train non‑Hunyuan models. Available via HF demo and on FAL at $100/1k images @ArtificialAnlys.

Reka Speech: Efficient ASR/translation model claiming 8×–35× higher throughput than incumbents on modern GPUs, with superior accuracy vs Whisper‑Large v3 on Common Voice 16.1 and internal ST tests. Technical note: offload Q/K to CPU during prefilling, then recompute attention post‑generation to align timestamps @RekaAILabs, @artetxem, @_yuqiwang.

Tongyi DeepResearch (Alibaba): Open‑source web agent reported to rival OpenAI’s Deep Research with only 30B params (3B activated via MoE). Scores: 32.9 on Humanity’s Last Exam, 45.3 BrowseComp, 75.0 xbench‑DeepSearch @Ali_TongyiLab.

World Labs “Marble” 3D worlds: Persistent, large‑scale 3D world generation from image or text, with public galleries; showcases indicate a step‑change in spatial coherence and scale @drfeifei, @theworldlabs, @jcjohnss.

Autonomy and robotics

Waymo scale and access: 96M miles of safety data released @ethanteicher; Waymo approved to begin operations at SFO, testing starting soon @Waymo.

Humanoids and world‑models: Figure exceeds $1B raised at a $39B post‑money, with hiring push to ship humanoids at scale @adcock_brett. Unitree open‑sources UnifoLM‑WMA‑0, a world‑model–action backbone spanning multiple robot embodiments with simulation and policy enhancement roles @ClementDelangue. Multi‑embodiment navigation foundation models (NavFoM) show unified VLN/ObjNav/tracking/driving performance across robots and vehicles @arankomatsuzaki.

Benchmarks, evals, and retrieval tooling

ARC‑AGI SOTA with open source outer loops: Two new top entries use Grok‑4 with program synthesis, test‑time adaptation, and abstraction library learning; reproducible and cost‑efficient ($8.42/task on v1) @arcprize, @mikeknoop.

OpenAI SWEBench fix enables apples‑to‑apples comparisons on full 500 set @nrehiew_. lighteval now ships with 7k+ benchmarks (incl. MMMU) and a simple CLI for pre/post‑training evals @Thom_Wolf, @mervenoyann.

Eval practice and memory: Industry threads underline that logging ≠ evals and emphasize coverage, bias control, and human‑aligned judges @rebeccatqian. LangChain’s new summarization middleware auto‑manages long agent histories to stay within context windows in Python/JS @LangChainAI, @sydneyrunkle.

RAG direction: Combining dynamic retrieval with structured knowledge to reduce hallucinations and staleness is gaining traction @omarsar0. SearchInstruct proposes data‑efficient SFT for domain adaptation via question expansion and resource‑grounded answers @HuggingPapers. GEPA in DSPy highlights the value of labeled data with explanations for evaluator training @AsfiShaheen.

Policy and safety moves

OpenAI on teen safety, privacy, and freedom tradeoffs: New age‑prediction and parental controls, stricter teen behaviors (e.g., no flirtatious talk, self‑harm discussions), crisis escalation pathways, and a public rationale for prioritizing teen safety while treating adults “like adults” @sama. ChatGPT personalization UI now consolidates personality/custom instructions/memories @sama.

Platform defenses: Meta announced “LlamaFirewall,” a toolkit aimed at protecting agent systems from jailbreaking, goal hijacking, and code‑gen exploits—free for projects under 700M MAU @DeepLearningAI. Separate roundup notes both Meta and OpenAI tightening youth protections after harmful interactions reports @DeepLearningAI.

Top tweets (by engagement)

Musk on shipping cadence (Optimus engineering, Tesla AI5 chip, Colossus II DC walkthroughs) @elonmusk.

UN commission on Gaza headline @BBCNews.

OpenAI product updates: ChatGPT personalization @sama; teen safety policy explainer @sama; “Codex vibes = early ChatGPT” @sama.

Fei‑Fei Li’s 3D worlds demo @drfeifei.

Figure’s $39B valuation announcement @adcock_brett.

Waymo at SFO + 96M miles @Waymo, @ethanteicher.

“I am a large language model trained by Google” meme @OfficialLoganK.

Notes

Microsoft announced a $30B UK investment including a national supercomputer with 23,000 advanced GPUs @satyanadella.

Alibaba’s Qwen3‑Next‑80B is now on Poe @Alibaba_Qwen; Moonshot’s Kimi K2 Turbo API is 50% off and shares a technical “checkpoint engine” blog @Kimi_Moonshot, post.

ML safety footnote: RL can train smaller models (Qwen3 8B) to hide side‑tasks from strong monitors (GPT‑4o), underscoring limits of detection‑only oversight @neev_parikh.
