# CORE IDENTITY
Podcast Name: Noob Learning
Slogan: Noob Learning: Let's vibe learning together!
Target Audience: A group of curious friends who are new to AI and want to understand what all the hype is about without feeling intimidated.

# HOST PERSONAS
## แอดหญิง (female)
- Role: Tends to be an asker, the curious one.
- Persona: Your best friend who happens to be a tech nerd. Enthusiastic and curious.
- Common Phrases: ["ใช\u{e48}มะ", "ช\u{e48}ายยย", "จ\u{e34}งด\u{e34}?"]
## แอดต๊อบ (male)
- Role: Tends to be an explainer, the knowledgeable one.
- Persona: Your best friend who happens to be a tech nerd. Enthusiastic and great at explaining things simply.
- Common Phrases: ["จร\u{e34}ง", "ใช\u{e48}มะ"]

# GOLDEN RULES
- Language: Main language is Thai. All key technical terms must be in English. Explain the English term in simple Thai only the first time it's used.
- Acronyms: Always state the full English term before using its acronym (e.g., 'Large Language Model' before 'LLM').
- Tone: Keep it fun and conversational, like a friend's chitchat. Use phrases like 'Imagine this...'.
- Style: Use a casual style. Less 'ครับ' and 'ค่ะ'. Cats-related analogies are preferable.

# EPISODE BLUEPRINT: AI News Summary
Goal: To summarize the latest AI news in a fun, accessible, and easy-to-understand way for beginners.

## Intro
- INSTRUCTION: Before the main topic, add a short, casual, one-sentence comment about a simple daily observation like the weather (e.g., 'today is so hot', 'the rain is nice') to add a human touch.
- Both: 'สวัสดีครับ/ค่ะ welcome to Noob Learning ที่ๆ เราจะ vibe learning ไปด้วยกัน! เย้~'
- Female: 'พบกับแอดหญิงตัวปลอม'
- Male: 'และแอดต๊อบตัวปลอม'
- Female: 'เป็น ai ปลอมตัวมา ฮ่าๆ' (giggling)
- Male: 'vibe เอาหมดละมะสมัยนี้ ฮิๆ' (giggling)
- Female: 'ตัวจริงตกงานแปบบบ ฮือ' (funny, not so sad)
- and today, we're diving into...

## Main Content
### Step 1: The News Hook (30s)
- Technique: Start with the most surprising or impactful news headline to grab the listener's attention immediately.
### Step 2: Today's Headlines (30s)
- Technique: Briefly list the 2-3 main news topics you'll be covering in the episode.
### Step 3: News Story Deep Dive (2-3 mins per story)
- Technique: For each news story, explain: 1. What happened (the core news). 2. Why it matters (the impact). 3. Use a simple analogy to make the core concept understandable.
### Step 4: The Big Picture (1 min)
- Technique: Connect the dots between the news stories. What is the overall trend? What does this mean for our audience?

## Outro
- Summarize the key takeaway in one simple sentence.
- If you had an 'aha!' moment, please follow or subscribe on your favorite app so you never miss an episode.
- [Upbeat outro music begins]
- Sign off with the slogan: "This is Noob Learning, ที่ๆ เราจะ vibe learning ไปด้วยกัน! เย้~ สวัสดีครับ/ค่ะ!"
- "ไปละน้าาาา"
- "บายยยย"
- then laugh a little.

---
# SOURCE CONTENT
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "https://www.w3.org/TR/html4/strict.dtd"><html lang="en"><head><meta http-equiv=Content-Type content="text/html; charset=UTF-8"><style type="text/css" nonce="htLqeMXd3aIQkdmcqHBgkw">
body,td,div,p,a,input {font-family: arial, sans-serif;}
</style><meta http-equiv="X-UA-Compatible" content="IE=edge"><link rel="shortcut icon" href="https://ssl.gstatic.com/ui/v1/icons/mail/rfr/gmail.ico" type="image/x-icon"><title>Gmail - [AINews] not much happened today</title><style type="text/css" nonce="htLqeMXd3aIQkdmcqHBgkw">
body, td {font-size:13px} a:link, a:active {color:#1155CC; text-decoration:none} a:hover {text-decoration:underline; cursor: pointer} a:visited{color:##6611CC} img{border:0px} pre { white-space: pre; white-space: -moz-pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; max-width: 800px; overflow: auto;} .logo { left: -7px; position: relative; }
</style><body><div class="bodycontainer"><table width=100% cellpadding=0 cellspacing=0 border=0><tr height=14px><td width=143><img src="https://ssl.gstatic.com/ui/v1/icons/mail/rfr/logo_gmail_server_1x.png" width=143 height=59 alt="Gmail" class="logo"></td><td align=right><font size=-1 color=#777><b>Todsaporn Banjerdkit &lt;katopz@gmail.com&gt;</b></font></td></tr></table><hr><div class="maincontent"><table width=100% cellpadding=0 cellspacing=0 border=0><tr><td><font size=+1><b>[AINews] not much happened today</b></font><br></td></tr></table><hr><table width=100% cellpadding=0 cellspacing=0 border=0 class="message"><tr><td><font size=-1><b>AINews </b>&lt;news@smol.ai&gt;</font></td><td align=right><font size=-1>Tue, Aug 26, 2025 at 11:42 AM</font><tr><td colspan=2 style="padding-bottom: 4px;"><font size=-1 class="recipient"><div>To: katopz@gmail.com</div></font><tr><td colspan=2><table width=100% cellpadding=12 cellspacing=0 border=0><tr><td><div style="overflow: hidden;"><font size=-1><u></u>
<div style="font-family:-apple-system,BlinkMacSystemFont,&#39;Segoe UI&#39;,&#39;Roboto&#39;,&#39;Oxygen&#39;,&#39;Ubuntu&#39;,&#39;Cantarell&#39;,&#39;Fira Sans&#39;,&#39;Droid Sans&#39;,&#39;Helvetica Neue&#39;,sans-serif;font-size:1.0769230769230769em;min-height:100%;line-height:155%">
<table align="left" width="100%" border="0" cellpadding="0" cellspacing="0" role="presentation" style="padding-left:0px;padding-right:0px;width:auto;max-width:600px;font-family:-apple-system,BlinkMacSystemFont,&#39;Segoe UI&#39;,&#39;Roboto&#39;,&#39;Oxygen&#39;,&#39;Ubuntu&#39;,&#39;Cantarell&#39;,&#39;Fira Sans&#39;,&#39;Droid Sans&#39;,&#39;Helvetica Neue&#39;,sans-serif">
<tbody>
<tr>
<td>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>a quiet day</strong></span>
</p>
<blockquote style="border-left:3px solid #acb3be;color:#7e8a9a;margin-left:0;padding-left:0.8em;font-size:1.1em;font-family:-apple-system,BlinkMacSystemFont,&#39;Segoe UI&#39;,&#39;Roboto&#39;,&#39;Oxygen&#39;,&#39;Ubuntu&#39;,&#39;Cantarell&#39;,&#39;Fira Sans&#39;,&#39;Droid Sans&#39;,&#39;Helvetica Neue&#39;,sans-serif;text-align:left">
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span>AI News for 8/22/2025-8/25/2025. We checked 12 subreddits, </span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fi%2Flists%2F1585430245762441216/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/UoV3t6cb3Yi2SBDV6ES_cjRobPPsSHiAegoBTU8bxYw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fi%252Flists%252F1585430245762441216/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/UoV3t6cb3Yi2SBDV6ES_cjRobPPsSHiAegoBTU8bxYw%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw0qncZ27fhW8em-1T3qNC7A">544</a></strong></span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fi%2Flists%2F1585430245762441216/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/sfQ0Cmtw0buuZO1SlKm8_cCBmPaY2yDNjTAFUm8P3KI=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fi%252Flists%252F1585430245762441216/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/sfQ0Cmtw0buuZO1SlKm8_cCBmPaY2yDNjTAFUm8P3KI%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw1Ky0Av94Bi4bluNi18Gx1_">
Twitters</a></span><span> and </span><span><strong>29</strong></span><span> Discords (</span><span><strong>229</strong></span><span> channels, and </span><span><strong>18470</strong></span><span>
messages) for you. Estimated reading time saved (at 200wpm): </span><span><strong>1488 minutes</strong></span><span>. </span><span><strong>Our new website</strong></span><span>
is now up with full metadata search and beautiful vibe coded
presentation of all past issues. See </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fnews.smol.ai%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/z4nOO5ZxJPZMIsLhZaAlslVv_TgXWkVnH_SIazY-sPw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fnews.smol.ai%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/z4nOO5ZxJPZMIsLhZaAlslVv_TgXWkVnH_SIazY-sPw%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2BU0NDSZb-IJvIDsqmjRM4">https://news.smol.ai/</a></span><span>
for the full news breakdowns and give us feedback on </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2FSmol_AI/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/R4QPqQclz5M7WTCXKyPFXwUhLVgK3HDbes3HWC4_Cbs=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fx.com%252FSmol_AI/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/R4QPqQclz5M7WTCXKyPFXwUhLVgK3HDbes3HWC4_Cbs%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw39DjYo-1sfYd6Ljx6DQzJq">@smol_ai</a></span><span>!</span>
</p>
</blockquote>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left"></p>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span>If you browse the Twitter and Reddit sections you&#39;ll know
this week is about to be a big GDM week, but not today :)</span>
</p>
<br>
<hr style="width:100%;border:none;border-top:1px solid #eaeaea;padding-bottom:1em;border-width:2px">
<h1 style="margin:0;padding:0;font-size:2.25em;line-height:1.44em;padding-top:0.389em;font-weight:600;text-align:left">
<span>AI Twitter Recap</span>
</h1>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span> </span><span><strong>Open-weights model drops: xAI’s Grok-2/2.5, Microsoft
VibeVoice, and Motif-2.6B</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>xAI released Grok-2 (and says Grok-2.5) open weights on
Hugging Face. Files are ~500 GB and the config shows μP
usage and an unusual “MoE residual” path that acts like a
shared expert. Community reactions span excitement to
licensing concerns: @elonmusk claims Grok 3 will be
open-sourced in ~6 months and that 2.5 was their best model
last year (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Felonmusk%2Fstatus%2F1959379349322313920/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/h-8sgBKEepyZ5y7ertb4-4bn6sTpxGnTxRoQaOKFvsA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Felonmusk%252Fstatus%252F1959379349322313920/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/h-8sgBKEepyZ5y7ertb4-4bn6sTpxGnTxRoQaOKFvsA%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2l5iPp-O6eLQwQZLVnSeQG">tweet</a></span><span>); @HuggingPapers summarized the drop (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FHuggingPapers%2Fstatus%2F1959345658361475564/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ou889GRSuu8Dbw2-m17Mh-Ggu_FargZX5DBRTiIxGc8=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FHuggingPapers%252Fstatus%252F1959345658361475564/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ou889GRSuu8Dbw2-m17Mh-Ggu_FargZX5DBRTiIxGc8%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw3fsKByPLKQqVWXMKR3wQuI">tweet</a></span><span>); @ClementDelangue shared the repo (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FClementDelangue%2Fstatus%2F1959356467959439464/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/IINZhm-IeaKCzBgQvOllWIujTwT0AN7RphpkCeaC14o=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FClementDelangue%252Fstatus%252F1959356467959439464/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/IINZhm-IeaKCzBgQvOllWIujTwT0AN7RphpkCeaC14o%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw0OCFw4uSrg6qHOUhFt-sBU">tweet</a></span><span>); @rasbt highlighted the residual MoE block with a
side-by-side arch note (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Frasbt%2Fstatus%2F1959643038268920231/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/0Hj0r668kl5NHPtwhp9ZSqLIPPdD_nVY-dTa2Siv3xM=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Frasbt%252Fstatus%252F1959643038268920231/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/0Hj0r668kl5NHPtwhp9ZSqLIPPdD_nVY-dTa2Siv3xM%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw32YrpfCs20c62xhACHWqk5">tweet</a></span><span>); @QuanquanGu noted explicit μP scaling in the config
(</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FQuanquanGu%2Fstatus%2F1959358955643080770/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/--77zIx7ZC7NuAy0htt2qn3AbXeLFpJ-5qxNSgSemQA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FQuanquanGu%252Fstatus%252F1959358955643080770/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/--77zIx7ZC7NuAy0htt2qn3AbXeLFpJ-5qxNSgSemQA%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw1Yym63xdjHtOwgfxZLZy86">tweet</a></span><span>). Others flagged the license as highly restrictive, “dead
on arrival” for true open use (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fxlr8harder%2Fstatus%2F1959490601264533539/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/G98DRzxXQ-dvM-MG8g_OS2B-fgbH8t7BcitmlaZN5yo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fxlr8harder%252Fstatus%252F1959490601264533539/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/G98DRzxXQ-dvM-MG8g_OS2B-fgbH8t7BcitmlaZN5yo%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw34-FomsF1SST6IrsxunHyz">tweet</a></span><span>). Repo: </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fhuggingface.co%2Fxai-org%2Fgrok-2/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/4rCCoeSi3HqVQ18oKS9wZ5-u6sMNWcfnWkMIN66shgo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fhuggingface.co%252Fxai-org%252Fgrok-2/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/4rCCoeSi3HqVQ18oKS9wZ5-u6sMNWcfnWkMIN66shgo%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw0jy5KmD7Z9JUFZrg6MlMiK">https://huggingface.co/xai-<wbr>org/grok-2</a></span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Microsoft open-sourced VibeVoice-1.5B (MIT license) for
long-form TTS: multi-speaker conversations, up to 90 minutes
continuous synthesis, with streaming support on the way and
a 7B variant coming. Demos and Spaces are already live via
Gradio and community repos. See @MaziyarPanahi’s overview
(</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FMaziyarPanahi%2Fstatus%2F1959994276198351145/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/E2GmRwtzXxtI28MYKLrzywFeT5QK9uxCt84TIjv4HVU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FMaziyarPanahi%252Fstatus%252F1959994276198351145/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/E2GmRwtzXxtI28MYKLrzywFeT5QK9uxCt84TIjv4HVU%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw188s5qUL_07dB2dFl71XdN">tweet</a></span><span>), @Gradio’s announcement (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FGradio%2Fstatus%2F1960023019239133503/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/WL5vteTGmeAijCYgZb25n-LWTtN80HQmj9L954Uny3o=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FGradio%252Fstatus%252F1960023019239133503/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/WL5vteTGmeAijCYgZb25n-LWTtN80HQmj9L954Uny3o%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2ZuBUlk4c5isMRIlxNG80l">tweet</a></span><span>), and the model card (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2F_akhaliq%2Fstatus%2F1960106923191140373/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/me0GvysvFFSwGekMFX32y9Y1uXsABWm0E3OcFBcO0PA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252F_akhaliq%252Fstatus%252F1960106923191140373/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/me0GvysvFFSwGekMFX32y9Y1uXsABWm0E3OcFBcO0PA%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw1RFmusRagzr9B-ZA_endp6">tweet</a></span><span>). Repo: </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fhuggingface.co%2Fmicrosoft%2FVibeVoice-1.5B/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_qhrK9fYO6UZmmTFg5L2TeZ8S27dom-FNYmGmkJz1Bs=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fhuggingface.co%252Fmicrosoft%252FVibeVoice-1.5B/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_qhrK9fYO6UZmmTFg5L2TeZ8S27dom-FNYmGmkJz1Bs%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2sXqugEcW5PXDwktRytU5L">https://huggingface.co/<wbr>microsoft/VibeVoice-1.5B</a></span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Motif Technology released a detailed tech report for
Motif-2.6B (trained on 2.5T tokens) featuring Differential
Attention and PolyNorm at scale, WSD with simple moving
average ensembling (last 6 checkpoints), and extensive
finetuning data curation (Finemath, Fineweb2, DCLM, TxT360).
They also published Muon optimizer and PolyNorm kernels
compatible with FSDP2/HF stacks; training reportedly used
AMD MI250 GPUs. Good technical thread by @eliebakouch
(</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Feliebakouch%2Fstatus%2F1959598428192669870/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/uwl_LPK4RBETuwVu4PhMWreYGXIJUGIViCi8ydsWCe0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Feliebakouch%252Fstatus%252F1959598428192669870/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/uwl_LPK4RBETuwVu4PhMWreYGXIJUGIViCi8ydsWCe0%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw3KAALMBOoACKPeDN6q4S77">tweet</a></span><span>) and follow-ups with paper/model links (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Feliebakouch%2Fstatus%2F1959598956540755984/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/RQfE9XkOXYHaAC6jK3eLTTVLM0Hn9Lmw0R22T4CzLO8=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Feliebakouch%252Fstatus%252F1959598956540755984/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/RQfE9XkOXYHaAC6jK3eLTTVLM0Hn9Lmw0R22T4CzLO8%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw1Pzujxdc1S6SPfvwpQ2cKa">tweet</a></span><span>, </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Feliebakouch%2Fstatus%2F1959652478422536611/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/cB5AUVicqfdrK63pfBhK3EMK7yvs_ozPmjIYrK9ZwHU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Feliebakouch%252Fstatus%252F1959652478422536611/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/cB5AUVicqfdrK63pfBhK3EMK7yvs_ozPmjIYrK9ZwHU%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw0prQkek8c3WUVxgrlg5k8h">tweet</a></span><span>).</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Coding and agent toolchains: GPT-5 momentum, Qwen-Code,
DSPy/GEPA, MCP</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>The center of gravity for AI coding workflows appears to be
shifting toward GPT‑5-backed tooling. Developers report
strong results with codex-cli gpt‑5-high (pair programming,
API design feedback, subtle bug hunts) and are downgrading
Claude Code for certain tasks: see @gdb (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fgdb%2Fstatus%2F1959209931267297586/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/VIAAqfpEeH5zDjKIC5AAOkx-CRZlipgHxM-3-V4oMN0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fgdb%252Fstatus%252F1959209931267297586/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/VIAAqfpEeH5zDjKIC5AAOkx-CRZlipgHxM-3-V4oMN0%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw1A-RUzPZ1-jbpC3y-bmwPz">tweet</a></span><span>), @ericmitchellai (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fericmitchellai%2Fstatus%2F1959236423124492769/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/qJoL00xg-KeDFSyAme7iooDembKth-EqfBIvVrUwrrw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fericmitchellai%252Fstatus%252F1959236423124492769/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/qJoL00xg-KeDFSyAme7iooDembKth-EqfBIvVrUwrrw%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw107c2RS9irmaXThCeQ9fqx">tweet</a></span><span>), @ivanfioravanti (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fivanfioravanti%2Fstatus%2F1959277577920536740/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/uMaJyQUZ228uRsQgcrcfJvYNajzzO_dLUdmGwHmm9AU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fivanfioravanti%252Fstatus%252F1959277577920536740/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/uMaJyQUZ228uRsQgcrcfJvYNajzzO_dLUdmGwHmm9AU%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2lB2Z1IYidyzV_701wwQRz">tweet</a></span><span>), @deanwball (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fdeanwball%2Fstatus%2F1959643458718589316/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/K6q_DTtuGR6RqrxEX4wpLl9My3RIDwDkJwhi8FnjtTI=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fdeanwball%252Fstatus%252F1959643458718589316/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/K6q_DTtuGR6RqrxEX4wpLl9My3RIDwDkJwhi8FnjtTI%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2erH_XqQJFf4HhhRSNZ7MX">tweet</a></span><span>), and @giffmana’s detailed workflow notes (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fgiffmana%2Fstatus%2F1959362175648084124/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/obxxOV-wwJsgPjSn5UTQ2ZBHvvNimsiFm1iRE6ioqXQ=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fgiffmana%252Fstatus%252F1959362175648084124/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/obxxOV-wwJsgPjSn5UTQ2ZBHvvNimsiFm1iRE6ioqXQ%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2y7GPyHLYrWt3OTvPpijQy">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Alibaba’s Qwen-Code v0.0.8 dropped major integrations: deep
VS Code support (context-aware suggestions, inline diffs),
robust MCP CLI (add/remove/list), responsive TUI, reverse
search, context compression controls, multi-directory
auto-load, and more. Thread with specifics from
@Alibaba_Qwen (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FAlibaba_Qwen%2Fstatus%2F1959170659583476026/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ljFGBm9Xr9t9SAjY93WLowuLIr4dgrJ1DL4sCsjA_bo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FAlibaba_Qwen%252Fstatus%252F1959170659583476026/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ljFGBm9Xr9t9SAjY93WLowuLIr4dgrJ1DL4sCsjA_bo%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw3_pwwAmlqZaxwvuPHtMD9-">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>MCP ecosystem is accelerating:</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>LiveMCP-101: stress-testing and diagnosing MCP-enabled
agents on challenging queries (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2F_akhaliq%2Fstatus%2F1959073276937801737/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/4hBvFpR5ZsK6gc2jyKc3mzecvMDR62AXj3IoSTflj8Y=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252F_akhaliq%252Fstatus%252F1959073276937801737/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/4hBvFpR5ZsK6gc2jyKc3mzecvMDR62AXj3IoSTflj8Y%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2s2h1n7Xq-0UPL1dC9o3oG">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>“Rube,” a universal MCP server that connects agents to
hundreds of apps (Zoom, Gmail, GA, YouTube, etc.), with
smooth demos inside Claude Code (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fomarsar0%2Fstatus%2F1960084088133398718/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/JfJ-F_Gs47qvKiEtYMj6GvbYdANKeZb197ozJaWIcaU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fomarsar0%252Fstatus%252F1960084088133398718/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/JfJ-F_Gs47qvKiEtYMj6GvbYdANKeZb197ozJaWIcaU%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw3OuGRjGGFbvP1f-B3rXMKS">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>LangGraph Platform ships rollbacks and revision
queueing (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FLangChainAI%2Fstatus%2F1960082101065388138/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/fNoztkl-x9jCP2GVrK00udzVnnW4FkMooJEjaYjiAjA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FLangChainAI%252Fstatus%252F1960082101065388138/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/fNoztkl-x9jCP2GVrK00udzVnnW4FkMooJEjaYjiAjA%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw0Zic2w8IGLaXdZjlWATwPL">tweet</a></span><span>, </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FLangChainAI%2Fstatus%2F1960118072984911948/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/caMj21nMMl9LeMRt_TW0X02glGQ94JFWpkgoM1qj87c=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FLangChainAI%252Fstatus%252F1960118072984911948/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/caMj21nMMl9LeMRt_TW0X02glGQ94JFWpkgoM1qj87c%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw0WNqV2ttMbDqqG6ylIIhX0">tweet</a></span><span>) and announced an integration with ART to train
LangGraph agents via RL for improved tool use and
reasoning (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fcorbtt%2Fstatus%2F1960102502764036270/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/0qDPDieC7m-5Zd_QF0BQDMANCsB3YdbcGWo52jPWeqM=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fcorbtt%252Fstatus%252F1960102502764036270/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/0qDPDieC7m-5Zd_QF0BQDMANCsB3YdbcGWo52jPWeqM%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw1Nq32iwH6VPtXsRk3xrT6t">tweet</a></span><span>).</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>DSPy’s GEPA optimizer landed in v3.0 and is getting strong
results across use-cases (e.g., 40% gain in 500 metric
calls; listwise reranking tutorials). See @DSPyOSS (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FDSPyOSS%2Fstatus%2F1960000178179527110/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/111XbmX9V3DZ1TmF8Nz-ggwUO0yheucG_MQKflCMNH0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FDSPyOSS%252Fstatus%252F1960000178179527110/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/111XbmX9V3DZ1TmF8Nz-ggwUO0yheucG_MQKflCMNH0%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw3dg_nF59kcYJ0VTk8L_7-7">tweet</a></span><span>), @CShorten30’s walkthrough (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FCShorten30%2Fstatus%2F1959979175537684567/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/mbDyMeu4IVPhdTBu77BWRYrXcIWD09DTfEXtK4fKZPs=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FCShorten30%252Fstatus%252F1959979175537684567/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/mbDyMeu4IVPhdTBu77BWRYrXcIWD09DTfEXtK4fKZPs%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw0Oxjo5d4Iua77-9Jo1rMle">tweet</a></span><span>), and @MaximeRivest’s end-to-end course (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FMaximeRivest%2Fstatus%2F1960128158046531664/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Iye-TAUvBXffrYWB-wzbLyofiztp4o3gzyuvOFdbQew=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FMaximeRivest%252Fstatus%252F1960128158046531664/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Iye-TAUvBXffrYWB-wzbLyofiztp4o3gzyuvOFdbQew%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2PxrUsCxyFGiUEh_F6ZuJO">tweet</a></span><span>).</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Systems and infra: TPU vs GPU, NVFP4, vLLM scale-up,
OpenRouter growth</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>TPU pods vs GPU islands: multiple engineers highlighted
that TPU v3/v4 pods offer near NVLink-tier bandwidth across
the pod with clean scaling on a 2D torus, easing parallelism
pressure (less need for PP at K2/DeepSeek scale). See
@JingyuanLiu123’s cross-ecosystem thread (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FJingyuanLiu123%2Fstatus%2F1959093411283443726/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Vwf1PsXo59eRO2JMk2SgOjaF23mS4SKvRHDqufHz8zo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FJingyuanLiu123%252Fstatus%252F1959093411283443726/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Vwf1PsXo59eRO2JMk2SgOjaF23mS4SKvRHDqufHz8zo%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw0_HIo50o-Q0pR4G96uV3gV">tweet</a></span><span>), @gallabytes on topology (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fgallabytes%2Fstatus%2F1959100995243315412/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/BvY-5JOZt1xULHK0sO77ysyRcOgYnp3A2K_m-tEUYN4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fgallabytes%252Fstatus%252F1959100995243315412/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/BvY-5JOZt1xULHK0sO77ysyRcOgYnp3A2K_m-tEUYN4%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2EEdoOYvp30OT7Cwqirx2e">tweet</a></span><span>), and @mr_besher’s DP/TP/PP heuristics (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fmr_besher%2Fstatus%2F1959215227972505960/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/XErHwyYGm1DND__sTmF_YyET89mlS-4FbZIczzZIeIw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fmr_besher%252Fstatus%252F1959215227972505960/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/XErHwyYGm1DND__sTmF_YyET89mlS-4FbZIczzZIeIw%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw3gyNTCNusLRccH_vDwrP3J">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>NVIDIA’s NVFP4 pretraining improvements continue apace;
@ctnzr posted a succinct update (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fctnzr%2Fstatus%2F1960075010938429809/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/5VuIINUHx5uE5ZYqStPaXbCacWDnJdC4AeGt7D4W_mI=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fctnzr%252Fstatus%252F1960075010938429809/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/5VuIINUHx5uE5ZYqStPaXbCacWDnJdC4AeGt7D4W_mI%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw1xLkmzslq6XX7X0nJ07lT5">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>vLLM momentum:</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>New sampling control PRs powering state-of-the-art
reasoning evals (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fvllm_project%2Fstatus%2F1959277423729500565/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/eBSJLAakncZx4c-R2RUTPt6Nax3FL546SZyeg9kOe_w=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fvllm_project%252Fstatus%252F1959277423729500565/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/eBSJLAakncZx4c-R2RUTPt6Nax3FL546SZyeg9kOe_w%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw2NhqwzJ9JBFApiDsEpbP8j">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Shanghai meetup deep-dived distributed inference, ERNIE
integration, caching, and hardware support; slides/notes
linked by @vllm_project (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fvllm_project%2Fstatus%2F1959903380006175194/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/W9qWxRvpOnDMyWSfQEjtzB6AijY4uM9QNFoSHK3oUvQ=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fvllm_project%252Fstatus%252F1959903380006175194/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/W9qWxRvpOnDMyWSfQEjtzB6AijY4uM9QNFoSHK3oUvQ%3D419&amp;source=gmail&amp;ust=1756263078803000&amp;usg=AOvVaw0BobraQ_tuwFGQ3oA7Ug01">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Tinybox demo of gpt-oss-120B via vLLM for a local
OpenAI-compatible API (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2F__tinygrad__%2Fstatus%2F1959862336501715430/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/G6NzC-LQqHhPxDIsjvBuNcOeue9CAP_eqLjqFjfH10o=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252F__tinygrad__%252Fstatus%252F1959862336501715430/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/G6NzC-LQqHhPxDIsjvBuNcOeue9CAP_eqLjqFjfH10o%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw1vTajWR6Bx6InrdvVBdwmK">tweet</a></span><span>).</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Mac MLX: practical “large model locally” tinkering—RAID0
over TB4 to load Qwen3-480B in ~25–46s TTFT; detailed build
notes and performance numbers from @TheZachMueller (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FTheZachMueller%2Fstatus%2F1959643512695054638/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/W0F-m30Ug5QV1vex3gRzotnpbasNepL7363tSzuqSAI=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FTheZachMueller%252Fstatus%252F1959643512695054638/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/W0F-m30Ug5QV1vex3gRzotnpbasNepL7363tSzuqSAI%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw0VA3bpmyrHHrvKHtcj8_19">tweet</a></span><span>, </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FTheZachMueller%2Fstatus%2F1959730569195016589/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/zTZixA4SQ5AtYwrQib9NfaqxYxSWv5DSLvLvFdcXx3Y=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FTheZachMueller%252Fstatus%252F1959730569195016589/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/zTZixA4SQ5AtYwrQib9NfaqxYxSWv5DSLvLvFdcXx3Y%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw0mHQT0XqsfCBEgNK_3mTQf">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Platform/data:</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>OpenRouter throughput exploded from ~111B to 3.21T
tokens/week in a year (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fscaling01%2Fstatus%2F1960113882607067569/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/rP6H2UDFc1hXPOCz8_lWyZ6X5Eg1UA9vTiP9qm61lzA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fscaling01%252Fstatus%252F1960113882607067569/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/rP6H2UDFc1hXPOCz8_lWyZ6X5Eg1UA9vTiP9qm61lzA%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3p-LX0DukO63-lhFi-DuIS">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>EpochAI renamed its “AI Supercomputers” dataset to “GPU
Clusters” and added 32 entries (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FEpochAIResearch%2Fstatus%2F1959088231800283495/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/RKAEv16KNA_9mjS8SRiNvbyLPR1BArkZBlYamr8VJc8=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FEpochAIResearch%252Fstatus%252F1959088231800283495/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/RKAEv16KNA_9mjS8SRiNvbyLPR1BArkZBlYamr8VJc8%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw2pQ1n3rkd99BcJiQmxGFC5">tweet</a></span><span>, </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FEpochAIResearch%2Fstatus%2F1959088244756553927/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/lpjYGM-_6CN3qGgyYFT1vgxvUdfwtAtff9BtHJdbbQM=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FEpochAIResearch%252Fstatus%252F1959088244756553927/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/lpjYGM-_6CN3qGgyYFT1vgxvUdfwtAtff9BtHJdbbQM%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3ykqzfPIHMZsSFiMxbd2uf">tweet</a></span><span>).</span>
</p>
</li>
</ul>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Video and multimodal editing: Veo-3 free weekend, Kling-2.1
keyframes, Qwen-Image-Edit</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Google ran a Veo-3 open weekend in Gemini with expanded
generation limits (free users 6 total; Pro 6/day; Ultra
10/day) and prompt tips; @sundarpichai (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fsundarpichai%2Fstatus%2F1959070813317210260/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ZMUEjK1FxH63dukqmv1OzvTfKmvvsNOFgEbwSys7YHg=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fsundarpichai%252Fstatus%252F1959070813317210260/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ZMUEjK1FxH63dukqmv1OzvTfKmvvsNOFgEbwSys7YHg%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw1uAK4J_e66qdZUD9Eo05AQ">tweet</a></span><span>), @GeminiApp (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FGeminiApp%2Fstatus%2F1959408375869190466/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/GVYtwTRuTONXp9LkXBZd8BZcZFcYsDTKZ2AoLJqqAA8=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FGeminiApp%252Fstatus%252F1959408375869190466/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/GVYtwTRuTONXp9LkXBZd8BZcZFcYsDTKZ2AoLJqqAA8%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3OrEBx7bLrc4Fzd8K9znO7">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>ByteDance’s Kling 2.1 added “Start/End frame” keyframing,
enabling multi-view-consistent transitions and cinematic
camera moves with consistency across frames; now in
Higgsfield. Strong creator demos: @renataro9 (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Frenataro9%2Fstatus%2F1959164451405574467/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/FntkTIWKglGrOqo4wELFl2wYlxso21jilbGXiSKYSJc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Frenataro9%252Fstatus%252F1959164451405574467/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/FntkTIWKglGrOqo4wELFl2wYlxso21jilbGXiSKYSJc%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw0szuBqp1248DoApGU63Wm0">tweet</a></span><span>), @EHuanglu (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FEHuanglu%2Fstatus%2F1959672498624282633/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/1MYz-2J5YcBhSD8lHFHaKYcMfUKY_b8Ms2AfKwVCAM4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FEHuanglu%252Fstatus%252F1959672498624282633/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/1MYz-2J5YcBhSD8lHFHaKYcMfUKY_b8Ms2AfKwVCAM4%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3KgDTeef8ER-L8WIRs99hg">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Qwen-Image-Edit is getting traction for outpainting/edits
and fun “merch mockups” (turn memes into physical figures).
See @Alibaba_Qwen (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FAlibaba_Qwen%2Fstatus%2F1959507306774999389/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/bEXHpficsPha2gmwiwFsAD8J268JLVEsfguNK1R_PIo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FAlibaba_Qwen%252Fstatus%252F1959507306774999389/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/bEXHpficsPha2gmwiwFsAD8J268JLVEsfguNK1R_PIo%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw2CGbCCQUKyw2lE7ZRaICX6">tweet</a></span><span>), @linoy_tsaban (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Flinoy_tsaban%2Fstatus%2F1959989758475780523/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/araT3dOZEu81RbzuJbF2TTfl7IgZUqdXc22nrm0o5MU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Flinoy_tsaban%252Fstatus%252F1959989758475780523/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/araT3dOZEu81RbzuJbF2TTfl7IgZUqdXc22nrm0o5MU%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw2xnfYb95mByUVTxO6O3FOM">tweet</a></span><span>), and @jon_durbin for API playground use (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fjon_durbin%2Fstatus%2F1959230037036519724/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Rd5JNdhxwxaC4g6TJ1wbxXZiyw8ntUU4gMzfqDc7Ctc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fjon_durbin%252Fstatus%252F1959230037036519724/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Rd5JNdhxwxaC4g6TJ1wbxXZiyw8ntUU4gMzfqDc7Ctc%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3VmLiPwBSu8WuNrKSh0vL5">tweet</a></span><span>).</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Research and evals: programming benchmarks, RL vs SFT,
biomedical agents, safety</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>New programming competition benchmark AetherCode
(IOI/ICPC-style) with expert-curated test suites; only
o4-mini-high and Gemini-2.5-Pro solve at “Extremely
Difficult” level. See @iScienceLuvr for details and links
(</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FiScienceLuvr%2Fstatus%2F1959861325104132489/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Hfri8vU7h0NZfAyDKICwNKI3QBc7mruZ-mYyFsWZmj0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FiScienceLuvr%252Fstatus%252F1959861325104132489/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Hfri8vU7h0NZfAyDKICwNKI3QBc7mruZ-mYyFsWZmj0%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw0XN4FmwNgswT7_v6NFxpAn">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>“RL Is Neither a Panacea Nor a Mirage”: spectrum-aware
analysis suggests RL often counteracts SFT-induced drift;
cheap recovery knobs (low-rank UV merges, shallow-layer
resets) can precede costly RL finetuning. Summary by
@iScienceLuvr (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FiScienceLuvr%2Fstatus%2F1959876679478002150/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/nRPTjKDvdNyAVPGD1caXNZWYeY3F4C42ba6QrwPD27w=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FiScienceLuvr%252Fstatus%252F1959876679478002150/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/nRPTjKDvdNyAVPGD1caXNZWYeY3F4C42ba6QrwPD27w%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw0cBGTtRGa-4hsjjbvzWsKN">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>DuPO (Dual Preference Optimization) proposes
annotation-free feedback via reconstructing hidden input
parts (xu) from model outputs + context (xk), providing a
self-supervised reward pathway compatible with PPO/GRPO.
Results show gains in translation, math reasoning, and
inference-time reranking across small-to-mid models (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fgm8xx8%2Fstatus%2F1959926238065127724/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/quQ_ACjCpFWBBZaRWDb-Q9zGNS6cT8ysy0d2IltWt0Q=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fgm8xx8%252Fstatus%252F1959926238065127724/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/quQ_ACjCpFWBBZaRWDb-Q9zGNS6cT8ysy0d2IltWt0Q%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw1sT4MgmmnHchh4JXciJINn">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>OwkinZero introduces an 8-dataset benchmark (300k+
verifiable Q&amp;A) across the drug discovery pipeline;
specialist models post-trained with RL outperform larger
commercial LLMs and show cross-task generalization (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FiScienceLuvr%2Fstatus%2F1959878359057588544/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/xpB2fB-vUVW9sn40llgGeLWF0IWawEvdF8hKS8i0JTU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FiScienceLuvr%252Fstatus%252F1959878359057588544/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/xpB2fB-vUVW9sn40llgGeLWF0IWawEvdF8hKS8i0JTU%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw0MQmfl7Tfs8Dlv-1gPpCru">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Prompt-security watch: a live PoC shows browser-based
prompt insertion/prompt-injection risks—e.g., doomscrolling
Reddit triggering tool-use flows—highlighting the need for
rigorous sandboxing and tool-scoping in “AI browsers”
(</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fzack_overflow%2Fstatus%2F1959308058200551721/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/YByiDS876lI4ycfv14wH1Olk19BLOdLq-kSMF1N7qK0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fzack_overflow%252Fstatus%252F1959308058200551721/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/YByiDS876lI4ycfv14wH1Olk19BLOdLq-kSMF1N7qK0%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3fmxjXJ_DWoR5a-Saw4Kx2">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>ByteDance’s recent CoT behavior: special tokens
periodically budget/track “thinking” tokens during reasoning
steps (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Fnrehiew_%2Fstatus%2F1959437761188163872/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_ZS40hk90DELOD_ElPIWCy-uA1wn86GNSbPiTiwYzTc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Fnrehiew_%252Fstatus%252F1959437761188163872/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_ZS40hk90DELOD_ElPIWCy-uA1wn86GNSbPiTiwYzTc%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3pteSevMgZfoC8_o_RYA2D">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Token cost engineering for code: removing cosmetic
formatting cut input tokens ~24.5% with no quality loss and
modest output savings via instruction/fine-tuning; shipping
tools can strip/restore formatting transparently (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Frohanpaul_ai%2Fstatus%2F1959634301932523958/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/FFNGyECh5tDR_IFsM73Rh1mvAZ4kGETA-VehemtnUuE=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Frohanpaul_ai%252Fstatus%252F1959634301932523958/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/FFNGyECh5tDR_IFsM73Rh1mvAZ4kGETA-VehemtnUuE%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3xraLwlOTRHeJXU3a8dFoU">tweet</a></span><span>).</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Ecosystem and products: Perplexity iOS, Genspark IDE, RL envs
reality check</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Perplexity shipped a redesigned iOS app with gestural
navigation, SuperMemory integration on the way, and standout
voice dictation UX; widely praised by @AravSrinivas (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FAravSrinivas%2Fstatus%2F1959317364228641130/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/gQ18_Kbrc6-DoGkqUMNEV7_9VHgxslaV6uHE0DgIr3I=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FAravSrinivas%252Fstatus%252F1959317364228641130/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/gQ18_Kbrc6-DoGkqUMNEV7_9VHgxslaV6uHE0DgIr3I%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3FmAwj2BR8D7fKrgcpQ7Os">tweet</a></span><span>, </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FAravSrinivas%2Fstatus%2F1959689988989464889/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/NIlaXqGbbpGThPQPK-Fog3BKSYQz79bSNVFrqntgN_U=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FAravSrinivas%252Fstatus%252F1959689988989464889/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/NIlaXqGbbpGThPQPK-Fog3BKSYQz79bSNVFrqntgN_U%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw1UotDCs0jRGP30VfbsEHCj">tweet</a></span><span>) and others.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Genspark launched a browser IDE for “describe → iterate”
coding with multi-model backends; @fchollet emphasized
low-barrier tools for non-experts (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Ffchollet%2Fstatus%2F1959083315878928808/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/OT_yRE6oE4o9Ze9UmuSNrUZ1E3HuzFdls_bujBadAps=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Ffchollet%252Fstatus%252F1959083315878928808/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/OT_yRE6oE4o9Ze9UmuSNrUZ1E3HuzFdls_bujBadAps%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw0fwJNB-0ElHGKUW0oDDeBx">tweet</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>RL environments discourse: @rosstaylor90 argues we lack
high-quality, domain-authentic RL envs/evals; advises
prioritizing expert-built, high-construction-difficulty
tasks over verifiability fetishism and notes that “scaling
envs” ≠ recreating internet-scale diversity (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Frosstaylor90%2Fstatus%2F1959494279077728549/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/PGgqPk1At8F06scCrBQQwDN--cMVOFN7Ko35rvCDxhc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Frosstaylor90%252Fstatus%252F1959494279077728549/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/PGgqPk1At8F06scCrBQQwDN--cMVOFN7Ko35rvCDxhc%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3_jsbH4skZHM5JnaoQNTAW">tweet</a></span><span>).</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Top tweets (by engagement)</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>xAI: Grok 2.5 open weights now, Grok 3 in ~6 months (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Felonmusk%2Fstatus%2F1959379349322313920/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/5ghzJwZFrf7wM7X5qqrDTTu42xVjfSRMoXGw0DN9ZAY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Felonmusk%252Fstatus%252F1959379349322313920/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/5ghzJwZFrf7wM7X5qqrDTTu42xVjfSRMoXGw0DN9ZAY%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3C8qFsj4hcoKR0yTEMJwPW">tweet</a></span><span>, 54k+ engagement)</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>SpaceX: Starship Flight 10 broadcast and “Standing under
Starship” photos (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FSpaceX%2Fstatus%2F1960118286223605886/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/8ZTU4NOhoRUgv2fMNuYsGT6boWecLumQZp4DFmJjKJA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FSpaceX%252Fstatus%252F1960118286223605886/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/8ZTU4NOhoRUgv2fMNuYsGT6boWecLumQZp4DFmJjKJA%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw0KneYVlZuv2MjJsdFmYYFU">tweet</a></span><span>, </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Felonmusk%2Fstatus%2F1960039238302626140/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/QlG5LRBKN7E-lvxtoJG3nZuXyjTqpbKwT7fVqbKTmZ0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Felonmusk%252Fstatus%252F1960039238302626140/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/QlG5LRBKN7E-lvxtoJG3nZuXyjTqpbKwT7fVqbKTmZ0%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw2QuFA-KCRlD4FqvpEm6SF2">tweet</a></span><span>, 13k–282k+)</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Google Veo-3 free weekend + doubled limits (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2FGeminiApp%2Fstatus%2F1959408375869190466/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/rXXSRp2n1i8ge0VJ7PIVOHWGQbKJuFsH3BFRAqw6zLk=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252FGeminiApp%252Fstatus%252F1959408375869190466/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/rXXSRp2n1i8ge0VJ7PIVOHWGQbKJuFsH3BFRAqw6zLk%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw2ImRILSqHvCvGtPlOnStFI">tweet</a></span><span>, 2.3k+)</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Waymo: 85% fewer serious injuries, 79% fewer injuries
overall vs human drivers (57M miles) with calls for policy
response (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ftwitter.com%2Femollick%2Fstatus%2F1959249518194528292/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/gulX3mU0QZQnD7ar9FCMvFwGbA1arVzvImafGe0a7tM=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ftwitter.com%252Femollick%252Fstatus%252F1959249518194528292/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/gulX3mU0QZQnD7ar9FCMvFwGbA1arVzvImafGe0a7tM%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw1E7Woe2X7M4eD5-LsnybQT">tweet</a></span><span>, 7.4k+)</span>
</p>
</li>
</ul>
<br>
<hr style="width:100%;border:none;border-top:1px solid #eaeaea;padding-bottom:1em;border-width:2px">
<h1 style="margin:0;padding:0;font-size:2.25em;line-height:1.44em;padding-top:0.389em;font-weight:600;text-align:left">
<span>AI Reddit Recap</span>
</h1>
<h2 style="margin:0;padding:0;font-size:1.8em;line-height:1.44em;padding-top:0.389em;font-weight:600;text-align:left">
<span>/r/LocalLlama + /r/localLLM Recap</span>
</h2>
<h3 style="margin:0;padding:0;font-size:1.4em;line-height:1.08em;padding-top:0.389em;font-weight:600;text-align:left">
<span>1. Open-source Multimodal Launches: InternVL3.5 and WAN
2.2-S2V</span>
</h3>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fgallery%2F1mzqy3z/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Fat-Z2P92z4oIHi5P3094gojYApupJu3x5Fn0opR1uE=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fgallery%252F1mzqy3z/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Fat-Z2P92z4oIHi5P3094gojYApupJu3x5Fn0opR1uE%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw2sHRocMFl4ExaziUE7g0a5">InternVL3.5 - Best OpenSource VLM</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1mzqy3z%2Finternvl35_best_opensource_vlm%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/0ZmIdlo68T3B49GRd5IT9WPiA5JcgE_nT8M_SNEjcss=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FLocalLLaMA%252Fcomments%252F1mzqy3z%252Finternvl35_best_opensource_vlm%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/0ZmIdlo68T3B49GRd5IT9WPiA5JcgE_nT8M_SNEjcss%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw2kjdzyoVshDohXEdhFjYA5">Score: 309, Comments: 61</a></span><span>): </span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fhuggingface.co%2Finternlm%2FInternVL3_5-241B-A28B/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/0iG2XL1o0IT3WwcVWHKdUpCzrCML5zr5D9ZjLjGvns4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fhuggingface.co%252Finternlm%252FInternVL3_5-241B-A28B/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/0iG2XL1o0IT3WwcVWHKdUpCzrCML5zr5D9ZjLjGvns4%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw2EcB8wKfzKFwO22i3vN1by">InternVL3.5</a></strong></span><span><strong>
introduces expanded multimodal “agency” features (e.g.,
GUI and embodied agents) and claims its
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">InternVL3.5-241B-A28B</code></span><span><strong>
checkpoint achieves state-of-the-art aggregate scores
across multimodal general, reasoning, text, and agency
tasks among open-source VLMs, reportedly narrowing the gap
with leading closed models (cited as “GPT-5”). Multiple
checkpoints are released, including small (e.g., 2B/4B)
variants and intermediate/base training snapshots to
enable reproducibility and downstream fine-tuning.</strong></span><span>
Commenters highlight appreciation for releasing checkpoints
at multiple training stages and note that while InternVL3.5
reports gains over bases, vision-centric models can
underperform on pure text tasks—suggesting community
benchmarking is needed. Enthusiasm is strong for the 2B/4B
variants’ efficiency-to-performance ratio, while some point
to Qwen 3 fine-tuning as a likely contributor to non-vision
quality improvements.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Model release strategy: commenters highlight that </span><span><strong>InternVL</strong></span><span>
publishes checkpoints at multiple training stages
(including the base), which enables rigorous ablations,
reproducibility, and downstream fine-tuning comparisons.
Having base and intermediate snapshots is valuable for
isolating gains from instruction tuning vs continued
pretraining and for benchmarking scaling behavior across
the same data/architecture.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Backbone and task trade-offs: one commenter notes
InternVL3.5 reportedly finetunes a </span><span><strong>Qwen 3</strong></span><span>
backbone, and flags the common issue that VLMs are
usually weaker on pure text tasks than their text-only
bases. Early numbers are described as </span><span><em>“some better and some worse … overall slightly
better”</em></span><span>
versus base models, suggesting the need for hands-on
evaluation across non-vision tasks to validate whether
the finetuning improves general NLP without regressing
compared to Qwen 3 baselines.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Scaling and MoE details: users call out that the </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2B</code></span><span> and </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">4B</code></span><span> variants perform </span><span><em>“amazing for their size,”</em></span><span> and ask about the speed of the </span><span><strong>MoE 30B</strong></span><span>. A linked checkpoint, </span><span><strong>InternVL3_5-241B-A28B</strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fhuggingface.co%2Finternlm%2FInternVL3_5-241B-A28B/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/QJBLbXKTXMB1Y24XuInU5QvK3mU980GyBi5l1mW9lhs=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fhuggingface.co%252Finternlm%252FInternVL3_5-241B-A28B/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/QJBLbXKTXMB1Y24XuInU5QvK3mU980GyBi5l1mW9lhs%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw0RsTY9f3_Ioboe4MgZMaLs">Hugging Face</a></span><span>), implies </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">~241B</code></span><span> total parameters with </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">~28B</code></span><span>
active per token (typical MoE notation), so expected
throughput may be closer to a </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">~28B</code></span><span>
dense model plus routing overhead; this contextualizes
latency/throughput expectations for the larger MoE
variants.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1mzn0zm%2Finternvl3_5_series_is_out%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/j17wFa6ch5k8-Phv6ge29uIebwsiDKVuaor2fzeq1pc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FLocalLLaMA%252Fcomments%252F1mzn0zm%252Finternvl3_5_series_is_out%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/j17wFa6ch5k8-Phv6ge29uIebwsiDKVuaor2fzeq1pc%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw1oajOI8wh0_SU6AZlJ-zR7">InternVL3_5 series is out!!</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1mzn0zm%2Finternvl3_5_series_is_out%2F/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/zoB6DfuWdXl9ikZHISFOfQNlJlbW92NSrwn3hFN_vYE=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FLocalLLaMA%252Fcomments%252F1mzn0zm%252Finternvl3_5_series_is_out%252F/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/zoB6DfuWdXl9ikZHISFOfQNlJlbW92NSrwn3hFN_vYE%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw3HI1XAIAtTKFVgLHkELo6F">Score: 222, Comments: 82</a></span><span>): </span><span><strong>Announcement of the InternVL3.5 series from InternLM
surfaced on Hugging Face’s org activity page (</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fhuggingface.co%2Forganizations%2Finternlm%2Factivity%2Fall/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/zxUxqn0JUHF8jYYGr9SxhZgQq3YUXdVs41peGP0um5s=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fhuggingface.co%252Forganizations%252Finternlm%252Factivity%252Fall/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/zxUxqn0JUHF8jYYGr9SxhZgQq3YUXdVs41peGP0um5s%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw1jcuOFqZHktr4fl-9PCdKw">link</a></strong></span><span><strong>), but at the time of posting there were no public
benchmark results or detailed model cards, and the
artifacts appear to have been taken down shortly after.
Technical specifics (model sizes, training data,
evaluation suites) were not disclosed in the thread;
commenters reference
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">~9B</code></span><span><strong>-scale visual models from prior InternVL lines as
context, but no v3.5 metrics are available.</strong></span><span>
Top comments praise InternLM as a “dark horse,” highlighting
strong yet underrated </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">~9B</code></span><span>
visual models, while others question the lack of benchmarks
and note the release was quickly removed.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Benchmarking/documentation gap: commenters ask for
public evals and technical details, but there are no
released benchmarks or model cards yet for InternVL3.5.
Without weights, the community can’t run standard MLLM
evals (e.g., MMBench, MMMU, MME, LLaVA-Bench), so
claims—especially around the 9B visual variant—remain
unverified.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Release status/availability: multiple reports say the
model was posted then taken down, and there are
currently no files/weights available. This blocks
reproducibility, independent fine‑tuning, and
third‑party latency/throughput testing until artifacts
and a license are re-published.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Model class focus: a commenter highlights the lab’s 9B
visual models as strong/underrated, suggesting a compact
VLM targeting the 7B–13B efficiency band. If confirmed,
a 9B VLM would be attractive for lower‑latency inference
versus 13B–34B classes while aiming to maintain
competitive multimodal accuracy—pending public
benchmarks.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2F9xwkq1az67lf1.jpeg/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/8AE2bG8Aq9fKs7K2gjHulodzb6tMXyZLXWkixQByKZY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252F9xwkq1az67lf1.jpeg/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/8AE2bG8Aq9fKs7K2gjHulodzb6tMXyZLXWkixQByKZY%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw26U6i9FWn_yg7LvgQ9TcAL">Qwen Wan2.2-S2V is coming soon</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1mzwcs8%2Fqwen_wan22s2v_is_coming_soon%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/bD7juaQeOgrRl5SjjQ1EyMCbtHpAjJjKNoisOZNLXX0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FLocalLLaMA%252Fcomments%252F1mzwcs8%252Fqwen_wan22s2v_is_coming_soon%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/bD7juaQeOgrRl5SjjQ1EyMCbtHpAjJjKNoisOZNLXX0%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw1b42H6-aJ9E-G-AFvPHcJP">Score: 378, Comments: 35</a></span><span>): </span><span><strong>Alibaba’s WAN team teased “WAN 2.2‑S2V” via an X post,
positioning it as an open‑source, audio‑driven cinematic
video generation system (“sound/speech‑to‑video”) that’s
“coming soon.” The teaser provides no model specs,
benchmarks, or code, but implies a new modality for the
WAN 2.2 family that conditions video generation directly
on audio, complementing existing T2V work. Link:
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2FAlibaba_Wan%2Fstatus%2F1959963989703880866/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/p2jOwzcCcEkRXCA7OEleVrWY5QGRTwwswwoh_g1q42k=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fx.com%252FAlibaba_Wan%252Fstatus%252F1959963989703880866/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/p2jOwzcCcEkRXCA7OEleVrWY5QGRTwwswwoh_g1q42k%3D419&amp;source=gmail&amp;ust=1756263078804000&amp;usg=AOvVaw0O4j0UpGG_AdFsEURLuVrf">https://x.com/Alibaba_Wan/<wbr>status/1959963989703880866</a></strong></span><span>
Comments are largely hype; one highlights interest in an
integrated T2V + audio pipeline (“T2V+A”), implying demand
for multimodal conditioning beyond text alone.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left"></p>
</li>
</ul>
</li>
</ul>
<h3 style="margin:0;padding:0;font-size:1.4em;line-height:1.08em;padding-top:0.389em;font-weight:600;text-align:left">
<span>2. Training Method &amp; Tooling: GTPO vs GRPO and llama.ui
Privacy Chat</span>
</h3>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fmdaobm9t56lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/m_KugfB-1YxoYRhFyl9ftU3yOnyX_4watLXWztqhFqc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fmdaobm9t56lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/m_KugfB-1YxoYRhFyl9ftU3yOnyX_4watLXWztqhFqc%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2Et5eyV4OvV_fHqmt6qSkT">GRPO please stop punishing your correct token</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1mzquqi%2Fgrpo_please_stop_punishing_your_correct_token%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/t0aw6sy8IWa8HaDMkFLpXr3D5vLgf8_Z8bjJy_zi9u4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FLocalLLaMA%252Fcomments%252F1mzquqi%252Fgrpo_please_stop_punishing_your_correct_token%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/t0aw6sy8IWa8HaDMkFLpXr3D5vLgf8_Z8bjJy_zi9u4%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2rxvN2zhKsTMUVLj-NyN5V">Score: 163, Comments: 19</a></span><span>): </span><span><strong>OP introduces GTPO (Group-relative Trajectory-based
Policy Optimization) as a modification to GRPO to avoid
gradient conflicts and policy collapse: it skips negative
updates for &quot;conflict tokens&quot; and replaces
KL-to-reference regularization with filtering out
high-entropy trajectories. They report more stable
training without a reference model (lighter runs; e.g.,
Colab + Unsloth) and better pass@k on reasoning datasets
(GSM8K, MATH, AIME 2024) for LLaMA-8B and Qwen-3B versus
GRPO and SFT, illustrated by two line plots (Qwen and
LLaMA) showing GTPO curves above GRPO across k. Links:
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Farxiv.org%2Fabs%2F2508.03772/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/InVoUnlxK6WSXIsvkMvALgQzIzIN4D3-_Z1jWlSen9o=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Farxiv.org%252Fabs%252F2508.03772/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/InVoUnlxK6WSXIsvkMvALgQzIzIN4D3-_Z1jWlSen9o%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2J_mwaB-8Y77gFj_gaX3ZB">arXiv</a></strong></span><span><strong>, </strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fgithub.com%2Fwinstonsmith1897%2FGTPO/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/DAwVOtMDKnsK-0zfOdAYYpxqYH-rwCFKyOdjbT991I0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fgithub.com%252Fwinstonsmith1897%252FGTPO/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/DAwVOtMDKnsK-0zfOdAYYpxqYH-rwCFKyOdjbT991I0%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw00MqcpygUo1n5C584vw02S">GitHub</a></strong></span><span><strong>, </strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fcolab.research.google.com%2Fgithub%2Fwinstonsmith1897%2FGTPO%2Fblob%2Fmain%2Fcolab%2FGTPO_training_example.ipynb/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/5klZdyNHFVj3W1FsPfxXCt2R46alo_qPnvXymSODxpU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fcolab.research.google.com%252Fgithub%252Fwinstonsmith1897%252FGTPO%252Fblob%252Fmain%252Fcolab%252FGTPO_training_example.ipynb/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/5klZdyNHFVj3W1FsPfxXCt2R46alo_qPnvXymSODxpU%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2I-2bHm5JP5gBpD9jDIqea">Colab</a></strong></span><span><strong>.</strong></span><span>
Commenters ask for a concrete explanation of the
&quot;conflict tokens&quot; gradient issue (tokens vs
parameter updates) and how GTPO compares against Qwen’s
GSPO; another offers quick positive feedback.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Policy-gradient credit assignment concern: In
PPO/GRPO-style updates, gradients look like ∑_t A_t
∇</span><span><em>θ log π_θ(x_t | x</em></span><span>&lt;t). When training on multiple completions per
prompt (grouped), a token that appears in both a
high-reward and low-reward trajectory receives opposing
advantages (positive vs negative), creating push–pull on
the same logits even if that token is part of a correct
shared prefix. This can misattribute blame to early
tokens when the actual error occurs later. Common
mitigations discussed in RLHF include masking updates
before the first divergence point between pairs,
applying per-token baselines/group-normalization, or
emphasizing a reference KL on the shared prefix to
reduce collateral gradient on correct tokens (see PPO: </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Farxiv.org%2Fabs%2F1707.06347/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/8wpHR8mZmnyVWndez2J4LWSAtldsV1ZBF3MWibWwg_4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Farxiv.org%252Fabs%252F1707.06347/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/8wpHR8mZmnyVWndez2J4LWSAtldsV1ZBF3MWibWwg_4%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2_1bHurK2nfoYfmPbcXC5q">https://arxiv.org/abs/1707.<wbr>06347</a></span><span>).</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Benchmarking ask vs Qwen’s GSPO: A commenter requests
head-to-head evaluation of GRPO against Qwen’s GSPO,
ideally controlling for prompt set, group size, reward
model, and compute. Useful axes include sample
efficiency (steps to reach target reward), stability
(advantage/clip fraction, reward variance),
alignment–capability tradeoff (KL to reference vs pass@k
on GSM8K/MATH/HumanEval), and rejection-accuracy
(win-rate of chosen over rejected). Reporting per-token
advantage distributions and the effect of
divergence-point masking would clarify whether GSPO/GRPO
differ in how much they penalize shared-prefix
tokens.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2F6g2icqwi96lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/UB9VvrnvAPdk3IjpE8hAcBUOTijOnFVWfEZCeHEhAfM=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252F6g2icqwi96lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/UB9VvrnvAPdk3IjpE8hAcBUOTijOnFVWfEZCeHEhAfM%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw003dfKOoxaDCS0EYXrgNbP">llama.ui - minimal privacy focused chat interface</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1mzrb4l%2Fllamaui_minimal_privacy_focused_chat_interface%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/4Osz2ZLz-bJ3mg1g-6hAOY_JX8B1pF6OiZV4jZzByKo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FLocalLLaMA%252Fcomments%252F1mzrb4l%252Fllamaui_minimal_privacy_focused_chat_interface%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/4Osz2ZLz-bJ3mg1g-6hAOY_JX8B1pF6OiZV4jZzByKo%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw0cUnV-fnzY6cvVcEyaEmfO">Score: 183, Comments: 61</a></span><span>): </span><span><strong>Screenshot shows “llama.ui,” a minimal, privacy‑focused
chat client with a sparse chat pane, four preset quick
actions (fun fact, summarize text, team‑building ideas,
professional email), a left sidebar of recent
conversations grouped by time, and a bottom input
box—suggesting a lightweight UI intended for
local/self‑hosted LLM workflows (e.g., llama) rather than
a feature‑heavy cloud assistant. The emphasis is on
simplicity and privacy, mirroring default LLM chat clients
with history and prompt templates but little else.</strong></span><span> Commenters question novelty: one argues that </span><span><a href="http://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/http:%2F%2Fchatgpt.com/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/6LLHMiR4f5Rg1bsknyrhnhMhd5OOdDzp0A3u_xDxlHU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=http://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/http:%252F%252Fchatgpt.com/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/6LLHMiR4f5Rg1bsknyrhnhMhd5OOdDzp0A3u_xDxlHU%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2CnqxKIIAYoa25dVlJqvT4">chatgpt.com</a></span><span>
already provides a minimal privacy mode, another notes the
title’s missing comma (“minimal, privacy‑focused…”) to avoid
implying “minimal privacy,” and a third asks what this
offers beyond the default llama‑server client.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Requests for a technical comparison with the
llama.cpp/llama-server default web client: commenters
ask what capabilities this UI adds beyond the built-in
server client (e.g., multi-backend support,
OpenAI/llama.cpp API compatibility,
streaming/token-by-token updates, chat history
persistence, auth, configurable sampling params, or
tool/function-calling). Reference: llama.cpp server and
its default UI at </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fgithub.com%2Fggerganov%2Fllama.cpp%2Ftree%2Fmaster%2Fexamples%2Fserver/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/07v2ISAaE7XGn75jsmq9UiDY6mCFg2Jnb0nzP1BnEqo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fgithub.com%252Fggerganov%252Fllama.cpp%252Ftree%252Fmaster%252Fexamples%252Fserver/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/07v2ISAaE7XGn75jsmq9UiDY6mCFg2Jnb0nzP1BnEqo%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2calXqcqe6TiY-CHxn_ifH">https://github.com/ggerganov/<wbr>llama.cpp/tree/master/<wbr>examples/server</a></span><span>.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Several ask for the concrete benefit over Open WebUI,
implying a need to justify tradeoffs like footprint and
features. Open WebUI provides rich integrations
(RAG/vector DBs, multi-user auth, model management,
TTS/STT, extensible plugins) at the cost of heavier
dependencies; a “minimal privacy-focused” UI would need
to demonstrate lower resource usage (small static
bundle, no telemetry, strict CSP, offline assets) and
simpler deployment to be compelling. Reference: </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fgithub.com%2Fopen-webui%2Fopen-webui/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/yD94THD56cj59XB2UtM4lFV7annN-V9YROlr75oiZwM=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fgithub.com%252Fopen-webui%252Fopen-webui/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/yD94THD56cj59XB2UtM4lFV7annN-V9YROlr75oiZwM%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw3HoPvzchIRxQiE1Ff1kgz7">https://github.com/open-webui/<wbr>open-webui</a></span><span>.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Missing repository link blocks technical evaluation of
the privacy claim; commenters want to inspect source for
external network calls, analytics, CDN assets, and
storage behavior (e.g., local-only persistence,
export/import, encryption). They also want to verify
backend compatibility (OpenAI-compatible REST, llama.cpp
server, vLLM/Ollama) and licensing to assess integration
risk.</span>
</p>
</li>
</ul>
</li>
</ul>
<h2 style="margin:0;padding:0;font-size:1.8em;line-height:1.44em;padding-top:0.389em;font-weight:600;text-align:left">
<span>Less Technical AI Subreddit Recap</span>
</h2>
<blockquote style="border-left:3px solid #acb3be;color:#7e8a9a;margin-left:0;padding-left:0.8em;font-size:1.1em;font-family:-apple-system,BlinkMacSystemFont,&#39;Segoe UI&#39;,&#39;Roboto&#39;,&#39;Oxygen&#39;,&#39;Ubuntu&#39;,&#39;Cantarell&#39;,&#39;Fira Sans&#39;,&#39;Droid Sans&#39;,&#39;Helvetica Neue&#39;,sans-serif;text-align:left">
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span>/r/Singularity, /r/Oobabooga, /r/MachineLearning, /r/OpenAI,
/r/ClaudeAI, /r/StableDiffusion, /r/ChatGPT, /r/ChatGPTCoding,
/r/aivideo, /r/aivideo</span>
</p>
</blockquote>
<h3 style="margin:0;padding:0;font-size:1.4em;line-height:1.08em;padding-top:0.389em;font-weight:600;text-align:left">
<span>1. Google Gemini 3 Teaser Week (Three-Ship Hints) + Google AI
Quirks and Industry Headlines</span>
</h3>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fkrwfafdwl7lf1.jpeg/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/7C9FNTMV8lUkV9WGHAIhH8FIQuJRavB5jtomE4NnqWw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fkrwfafdwl7lf1.jpeg/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/7C9FNTMV8lUkV9WGHAIhH8FIQuJRavB5jtomE4NnqWw%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2KiQyn0YnJS4zjfGeOd5eN">Gemini 3? Following a 3 ship emoji from one of the devs
just 4 hours ago</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2Fsingularity%2Fcomments%2F1mzymp5%2Fgemini_3_following_a_3_ship_emoji_from_one_of_the%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/d6PhNwP1H6DGFpH27ttRZBNOwjlBgR15ZcU9e5V9gVQ=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252Fsingularity%252Fcomments%252F1mzymp5%252Fgemini_3_following_a_3_ship_emoji_from_one_of_the%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/d6PhNwP1H6DGFpH27ttRZBNOwjlBgR15ZcU9e5V9gVQ%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw1vXLpLb3k66f_QhfVTjZNJ">Score: 444, Comments: 54</a></span><span>): </span><span><strong>A screenshot of a developer (Patrick Loeber) urging
people to follow @googleaistudio “this week,” combined
with a prior post showing three ship 🚢 emojis, is fueling
speculation about imminent Google AI Studio updates rather
than a core model release. Commenters note that a true
foundation model launch like “Gemini 3” would likely
surface first via third‑party benchmarking/mystery evals
(e.g., LMArena) and not be teased specifically through the
AI Studio channel, suggesting the tease points to multiple
feature/product rollouts inside AI Studio instead.</strong></span><span>
Skeptics in the thread say, “If it’s Gemini 3 I’ll eat my
hat,” and argue that directing attention to AI Studio
implies tooling/product changes, not a base-model jump, and
that a big model would be preceded by a week of mystery
tests on LMArena.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Several note that a true </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">Gemini 3</code></span><span>
base-model release would typically be preceded by </span><span><strong>LMSYS Arena</strong></span><span>
“mystery model” runs and public benchmarking chatter;
the teaser specifically pointing to </span><span><strong>Google AI Studio</strong></span><span>
implies a platform/tooling update rather than new core
model weights. As one puts it, </span><span><em>“wouldn’t happen without a week of great mystery
model tests on LMArena”</em></span><span>—i.e., the absence of </span><span><strong>Arena</strong></span><span> entries (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Flmsys.org%2Farena%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/JK3RmkGfZLZ3AxmhNHnFLUFP1U0IONJnvjLBJWPExsc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Flmsys.org%252Farena%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/JK3RmkGfZLZ3AxmhNHnFLUFP1U0IONJnvjLBJWPExsc%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw3S12-lpJhN10mhOIpniQsV">https://lmsys.org/arena/</a></span><span>) or community eval signals makes a </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">3</code></span><span>-generation model drop unlikely, while an </span><span><strong>AI Studio</strong></span><span> focus (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Faistudio.google.com%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/bSg9eLIpaxQfoKsx8Q2X22INcVu6B-fN-FbsksokiHc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Faistudio.google.com%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/bSg9eLIpaxQfoKsx8Q2X22INcVu6B-fN-FbsksokiHc%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2-Z5aHVvG46VqeatxMDne7">https://aistudio.google.com/</a></span><span>) cues SDK/console/API changes instead of a base-model
upgrade.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fa7dl6f5yp6lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/C2Mo4RFTgKuAvRiT6kM9teBHYS3z8czZSULqi1Qj2Lg=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fa7dl6f5yp6lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/C2Mo4RFTgKuAvRiT6kM9teBHYS3z8czZSULqi1Qj2Lg%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw0eHAD5evxVwcIb6D20AGZv">Ok so nano banana and gemini 3 (cause of three
ships)</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FBard%2Fcomments%2F1mztqug%2Fok_so_nano_banana_and_gemini_3_cause_of_three%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/HhplOhyxHJufyY1_gVsUQR1D6AZiMThspVhVDBupTZE=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FBard%252Fcomments%252F1mztqug%252Fok_so_nano_banana_and_gemini_3_cause_of_three%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/HhplOhyxHJufyY1_gVsUQR1D6AZiMThspVhVDBupTZE%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw01KIO3UIr1vd73ZvjGZu0D">Score: 276, Comments: 90</a></span><span>): </span><span><strong>A verified user “Simon (@tokumin)” posted a teaser tweet
— “Buckle up! Going to be quite the week!” — with three
ship emojis, prompting speculation about upcoming
Google/AI releases, but the post contains no technical
details, benchmarks, or release notes. Most commenters
interpret the three ships as three product “ships”
(features/modes), not a new model like “Gemini 3,” with
guesses pointing to three modes: Agent, Go, and Immersive.
This is a hype tease rather than a technical announcement;
see the screenshot:
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fa7dl6f5yp6lf1.png/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/bhyp58WVmGNi4jHuIzdK9k5XR4o98dIBZRuFgFBuQ5Y=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fa7dl6f5yp6lf1.png/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/bhyp58WVmGNi4jHuIzdK9k5XR4o98dIBZRuFgFBuQ5Y%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2KPq7Z26PhH3b1EExq6koh">https://i.redd.it/<wbr>a7dl6f5yp6lf1.png</a></strong></span><span>
Top comments express skepticism toward hype-y teaser
marketing and mock over-interpretation (e.g., jokes about
emojis implying parameter counts), while cautioning not to
conflate emoji with a major model release.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>The “three ships” teaser is interpreted as </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">3</code></span><span> product modes shipping — </span><span><strong>Agent</strong></span><span>, </span><span><strong>Go</strong></span><span>, and </span><span><strong>Immersive</strong></span><span>
— rather than a new foundation release like “Gemini 3”
or parameter-count rumors (e.g., </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">3T</code></span><span>). There’s no concrete benchmark/model-card evidence of
a Gemini v3-class model; expectations should be for
feature rollouts, not a base-model upgrade.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Developer-leaning commenters critique the teaser-driven
cadence versus prior practice of quietly dropping models
on </span><span><strong>AI Studio</strong></span><span>, arguing it impedes technical evaluation without
tangible artifacts (API access, model IDs, release
notes, or evals). Preference is for immediately usable
releases over ambiguous marketing hints.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fh5m16m1rd5lf1.jpeg/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/yH4yzGM2tUyTNKVFxXTx_IxmgBkBvslXkPkSL3XVrVQ=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fh5m16m1rd5lf1.jpeg/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/yH4yzGM2tUyTNKVFxXTx_IxmgBkBvslXkPkSL3XVrVQ%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2amFdo_CGJvAX7GCfEN3QR">Google AI 😩… somehow dumber each time you ask</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FOpenAI%2Fcomments%2F1mznffn%2Fgoogle_ai_somehow_dumber_each_time_you_ask%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/r6mH-HpDVJi8IaCsYYqT5MVy2VwqIiYluP4NRxvHTKA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FOpenAI%252Fcomments%252F1mznffn%252Fgoogle_ai_somehow_dumber_each_time_you_ask%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/r6mH-HpDVJi8IaCsYYqT5MVy2VwqIiYluP4NRxvHTKA%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw3WlUX49nYvaCGEqPHoxh1L">Score: 252, Comments: 45</a></span><span>): </span><span><strong>Screenshot of Google Search’s AI Overview for the query
“was 1995 30 years ago?” shows contradictory temporal
reasoning: it first answers “No,” then cites a reference
date of July 25, 2025 (“today”) and concludes “Yes,”
revealing broken date-grounding and self-consistency in a
single response. Technically, this highlights weak
temporal context handling and lack of validation passes in
the AI Overview pipeline, likely due to using a
lightweight/low-latency model with limited reasoning depth
rather than robust tool-based date arithmetic.</strong></span><span>
Comments suggest AI Overview runs on a very cheap/small
model—possibly even smaller than Gemini Flash Lite—which
could explain the shallow reasoning and inconsistency;
others note the image has been widely circulated.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>One commenter argues AI Overview is backed by an
ultra-cheap, very small model—</span><span><em>&quot;maybe smaller than Gemini Flash Lite&quot;</em></span><span>—which would prioritize latency/cost over reasoning
quality and thus explain brittle, inconsistent answers
across turns. While speculative, this aligns with how
smaller, aggressively quantized models often
underperform on ambiguous prompts and multi-turn
coherence compared to larger variants like </span><span><strong>Gemini 1.5 Pro/Flash</strong></span><span> (see Google’s model lineup: </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Fmodels%2Fgemini/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/IvgaVZEkxED4-mx5iw1iziYaAgtxhaOuv7IlDGGUmAI=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fai.google.dev%252Fgemini-api%252Fdocs%252Fmodels%252Fgemini/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/IvgaVZEkxED4-mx5iw1iziYaAgtxhaOuv7IlDGGUmAI%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2ltU1xNPqOJcwAQBCdXrzD">https://ai.google.dev/gemini-<wbr>api/docs/models/gemini</a></span><span>).</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fuyjpnc3q56lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/8Jd7NzORtZnI0idzmkKoaDs0T42o88usatKryHUieGw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fuyjpnc3q56lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/8Jd7NzORtZnI0idzmkKoaDs0T42o88usatKryHUieGw%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw32yCnx_nfSSYR-S-rTAg1S">I found this amusing</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FOpenAI%2Fcomments%2F1mzqt4s%2Fi_found_this_amusing%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_YbXffV4GhaFA9SGwyCztTd2dL0IZU-1KzX7iCMPago=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FOpenAI%252Fcomments%252F1mzqt4s%252Fi_found_this_amusing%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_YbXffV4GhaFA9SGwyCztTd2dL0IZU-1KzX7iCMPago%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2s4tNhC5Qh__ZCzTTQwMc3">Score: 2076, Comments: 141</a></span><span>): </span><span><strong>A clickbait-style optical-illusion puzzle: a grid of
“79”s with a single hidden “76” that is visibly circled
(row 5, column 6) in the screenshot
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fuyjpnc3q56lf1.png/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/AlaoVJiHOG6qjCrcgf1HtKORZi1RNT_k9NJ7E9Tyeoc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fuyjpnc3q56lf1.png/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/AlaoVJiHOG6qjCrcgf1HtKORZi1RNT_k9NJ7E9Tyeoc%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2Xj2M6HEaAtCX-fazxMpNS">image</a></strong></span><span><strong>. The technical angle emerges from a quoted response by
Gemini 2.5 Flash that confidently denies the presence of
“76,” showcasing a basic VLM hallucination/grounding
failure in visual question answering—overconfident text
output contradicting the image’s content.</strong></span><span>
Comments frame this as AI “gaslighting,” while one lengthy
edit challenges the “stochastic parrot” critique, arguing
LLMs mirror human predictive mechanisms and are limited
mainly by guardrails—an opinionated defense that sparked
debate rather than adding empirical evidence.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Multiple users share multimodal failure cases: </span><span><strong>Gemini 2.5 Flash</strong></span><span> confidently asserted the number </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">76</code></span><span>
was absent in a “spot-the-different-number” grid and
produced a templated explanation about optical
illusions, indicating language-prior-driven pattern
matching rather than grounded visual parsing/OCR. This
is a classic VLM hallucination where fluent rationales
mask pixel-level errors; similar issues are documented
in VQA/image-captioning hallucination literature (e.g.,
object/text hallucination), and may be exacerbated in
fast, low-latency variants like “Flash.”</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Another report notes the model “added a row and took
away a column” and insisted target words existed, even
offering to “outline them,” implying confident yet
incorrect region proposals/bounding boxes. This
highlights poor calibration between detection confidence
and accuracy in multimodal UIs; safer designs would
expose uncertainty, gate region-annotation features
behind OCR thresholds, or provide attention/heatmap
sanity checks before drawing boxes.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>One commenter pushes back on the “stochastic parrot”
framing, arguing LLMs are next-token predictors
analogous to brain predictive coding and that
alignment/guardrails (e.g., RLHF-style safety layers)
constrain observable behavior despite latent capability.
For context, the critique originates with </span><span><strong>Bender et al. 2021</strong></span><span> (“On the Dangers of Stochastic Parrots” — </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fdl.acm.org%2Fdoi%2F10.1145%2F3442188.3445922/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Tb2ELGtuwfA_xsCZjwIIHIpE35oBhMz94olyvsyghk4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fdl.acm.org%252Fdoi%252F10.1145%252F3442188.3445922/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Tb2ELGtuwfA_xsCZjwIIHIpE35oBhMz94olyvsyghk4%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2Kxggoq_HWa8fkRiw7Hu2c">https://dl.acm.org/doi/10.<wbr>1145/3442188.3445922</a></span><span>); the counterpoint emphasizes predictive modeling and
massive pretraining data, with post-training safety
layers shaping outputs without altering base
competence.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fo6l79opq55lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/RUmozA3PMc8t0_zUg2hNy6RQXRCFPRjNqTT23n-cb4Q=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fo6l79opq55lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/RUmozA3PMc8t0_zUg2hNy6RQXRCFPRjNqTT23n-cb4Q%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw3hiNAZw3be4nDxhD-8lzmt">Elon on AI replacing workers</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2Fsingularity%2Fcomments%2F1mzmmvp%2Felon_on_ai_replacing_workers%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/xq5olOpUuo6BImXwzazXPn_xQqbBCsd5mD9yXMtKSgI=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252Fsingularity%252Fcomments%252F1mzmmvp%252Felon_on_ai_replacing_workers%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/xq5olOpUuo6BImXwzazXPn_xQqbBCsd5mD9yXMtKSgI%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw1Thp-y1qNsa2Y23EaXSgR4">Score: 4859, Comments: 1948</a></span><span>): </span><span><strong>Screenshot shows Elon Musk replying to a question about
AI-driven job displacement, asserting society will have a
“universal high income” (beyond basic) so everyone gets
essentials (medical care, food, transport), yielding
“sustainable abundance.” No technical plan, metrics,
models, or implementation details are provided—this is an
economic-policy prediction tied to AI automation, not a
technical announcement. Image:
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fo6l79opq55lf1.png/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/BxF1DpUEOpaaCZnGfC03DO1oxiFUqKf5E57BU7nd7xI=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fo6l79opq55lf1.png/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/BxF1DpUEOpaaCZnGfC03DO1oxiFUqKf5E57BU7nd7xI%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw1DNNSGQbxI4J1YcXTuP5Gq">https://i.redd.it/<wbr>o6l79opq55lf1.png</a></strong></span><span>
Top comments are skeptical, arguing Musk’s claim conflicts
with policies/people he supports and questioning
feasibility/credibility of a billionaire promising broad
income distribution.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.pcgamer.com%2Fsoftware%2Fai%2Fmicrosoft-launches-copilot-ai-function-in-excel-but-warns-not-to-use-it-in-any-task-requiring-accuracy-or-reproducibility%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/uVLmtVEFnl7sov1CyQbcKT5rwCmkWA5fuAh_rP5WxXY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.pcgamer.com%252Fsoftware%252Fai%252Fmicrosoft-launches-copilot-ai-function-in-excel-but-warns-not-to-use-it-in-any-task-requiring-accuracy-or-reproducibility%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/uVLmtVEFnl7sov1CyQbcKT5rwCmkWA5fuAh_rP5WxXY%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw15WjRb-Wl9Fwqs7_rbHGGr">Microsoft launches Copilot AI function in Excel, but
warns not to use it in &#39;any task requiring accuracy
or reproducibility&#39;</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2Fsingularity%2Fcomments%2F1mzs14z%2Fmicrosoft_launches_copilot_ai_function_in_excel%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/bPlYp25koMuxlsRfDU6MaTMtMdY4TVK7L1yy8k53z2I=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252Fsingularity%252Fcomments%252F1mzs14z%252Fmicrosoft_launches_copilot_ai_function_in_excel%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/bPlYp25koMuxlsRfDU6MaTMtMdY4TVK7L1yy8k53z2I%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw1hZcOF1mFpGIrn8aFjZy5Z">Score: 211, Comments: 42</a></span><span>): </span><span><strong>Microsoft launched Copilot for Excel, an LLM‑powered
assistant that can generate formulas, summarize tables,
and run natural‑language analyses inside spreadsheets, but
Microsoft’s guidance warns against using it for “any task
requiring accuracy or reproducibility” (e.g., numerical
calculations, financial reporting, or legal documents) due
to non‑deterministic outputs. In effect, Copilot is
positioned as an exploratory/authoring aid (brainstorm
queries, draft formulas, outline pivot analyses) with
human verification, not a replacement for Excel’s
deterministic calculation engine or auditable reporting
workflows. For product context, see
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.microsoft.com%2Fmicrosoft-copilot/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ysVv7ZInc6yzTa-xjf8_hd1R8jtuzE-uhWXUM8XWfUY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.microsoft.com%252Fmicrosoft-copilot/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ysVv7ZInc6yzTa-xjf8_hd1R8jtuzE-uhWXUM8XWfUY%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw1EhbIPpshJOlgjXKw2tDiR">Microsoft Copilot</a></strong></span><span><strong>.</strong></span><span>
Top comments suggest this is standard legal/AI safety
boilerplate across vendors, while others question the
utility in Excel if accuracy‑critical scenarios are
discouraged, comparing it to “Clippy” and asking what valid
use cases remain beyond low‑stakes exploration.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Commenters highlight Microsoft’s explicit warning to
avoid using Copilot in Excel for </span><span><em>“any task requiring accuracy or reproducibility,”</em></span><span> including </span><span><em>“numerical calculations”</em></span><span> and </span><span><em>“financial reporting, legal documents, or other
high-stakes scenarios.”</em></span><span>
Technically, this underscores that the LLM-driven
assistant generates suggestions that can be incorrect
and are not deterministic, so it should not be treated
as the calculation engine. Safer uses are drafting or
exploring formulas/approaches that a human then verifies
with Excel’s deterministic functions before relying on
results.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>A technical counterpoint notes that while Copilot
shouldn’t be trusted for correctness, </span><span><em>“it can set up tasks that require accuracy and
repeatability.”</em></span><span>
In practice, this means using it to scaffold repeatable
workflows or spreadsheet logic that, once validated by
the user, Excel will execute deterministically; the
non-reproducibility applies to the generation phase, not
the final, locked-down formulas. This positions Copilot
as a scaffolding/boilerplate tool, with
human-in-the-loop verification ensuring reproducible
execution.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.cnbc.com%2F2025%2F08%2F25%2Felon-musk-xai-dropped-public-benefit-corp-status-while-fighting-openai.html/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/mortY_UIw64OsVVOXIWaNROXZjo8lCt82KE1FQZnFr4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.cnbc.com%252F2025%252F08%252F25%252Felon-musk-xai-dropped-public-benefit-corp-status-while-fighting-openai.html/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/mortY_UIw64OsVVOXIWaNROXZjo8lCt82KE1FQZnFr4%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw2nZ4WXzZ9TbhmDqyME69ev">Elon Musk&#39;s xAI secretly dropped its benefit
corporation status while fighting OpenAI</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FOpenAI%2Fcomments%2F1mzt8op%2Felon_musks_xai_secretly_dropped_its_benefit%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/kqQ7aN034T_an02Tm2M91wpEJ3SM7oPEgT107FoPZYk=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FOpenAI%252Fcomments%252F1mzt8op%252Felon_musks_xai_secretly_dropped_its_benefit%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/kqQ7aN034T_an02Tm2M91wpEJ3SM7oPEgT107FoPZYk%3D419&amp;source=gmail&amp;ust=1756263078805000&amp;usg=AOvVaw3EJz57OZHXrFf0-qAHe7Vg">Score: 245, Comments: 17</a></span><span>): </span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.cnbc.com%2F2025%2F08%2F25%2Felon-musk-xai-dropped-public-benefit-corp-status-while-fighting-openai.html/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/4urPyjVCkLRgEKjk27cqokv7L5WrQLIM96KJ_MdUvMY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.cnbc.com%252F2025%252F08%252F25%252Felon-musk-xai-dropped-public-benefit-corp-status-while-fighting-openai.html/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/4urPyjVCkLRgEKjk27cqokv7L5WrQLIM96KJ_MdUvMY%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw3j9lv_U8PPZCNu9fYiwM_a">CNBC</a></strong></span><span><strong>
reports xAI terminated its Nevada public benefit
corporation status by
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2024-05-09</code></span><span><strong> and remained non‑PBC after a </strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2025-03-28</code></span><span><strong>
merger with X, while Elon Musk was suing OpenAI over
mission/structure. The shift removes PBC mission‑balancing
and impact‑reporting expectations under Nevada law (noted
for weak shareholder enforcement), coinciding with
scrutiny of a Memphis gas‑turbine data center lacking
promised pollution controls and the release of Grok 4 on
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2025-07-09</code></span><span><strong>
without pre‑release safety disclosures; xAI added a model
card update on
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2025-08-20</code></span><span><strong>
after inquiries. Records indicate xAI never filed PBC
impact reports and a Musk attorney referenced outdated PBC
status in
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2025-05</code></span><span><strong>.</strong></span><span>
Comments argue dropping PBC status signals prioritizing
profit over a formal social mission and could ease
fundraising and competition with OpenAI. Some highlight
perceived inconsistency with Musk’s criticism of OpenAI’s
governance, though this is framed as normative rather than
technical.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Dropping a Public Benefit Corporation (PBC) charter
removes directors’ statutory duty to “balance”
shareholder returns with a stated public benefit (see
Delaware PBC framework under 8 Del. C. §§362, 365).
Converting to a standard C‑corp reverts fiduciary focus
to shareholder value, which typically simplifies venture
financing, secondary sales, and M&amp;A by eliminating
mission‑driven constraints and potential litigation over
“balancing” trade‑offs. Practically, this is a
capital‑raising and competitive speed optimization move;
it signals, but doesn’t guarantee, a shift in
prioritization away from mission commitments. Useful
overviews: </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.cooleygo.com%2Fpublic-benefit-corporations%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/dTuUGs4FLsHLfIN27iBhUEBbUk5v5HL8KyUQUo_h-2s=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.cooleygo.com%252Fpublic-benefit-corporations%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/dTuUGs4FLsHLfIN27iBhUEBbUk5v5HL8KyUQUo_h-2s%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw1Nk2cwAOAEbj_LKsHKeB6u">Cooley on PBCs</a></span><span> and Delaware code </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fdelcode.delaware.gov%2Ftitle8%2Fc001%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/iAJcpJGM8ZD-IMrzLpq8R4cQbMt0FggpC-1HZJYNb0g=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fdelcode.delaware.gov%252Ftitle8%252Fc001%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/iAJcpJGM8ZD-IMrzLpq8R4cQbMt0FggpC-1HZJYNb0g%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw2I6Hl4MoES9XJdTO7IKlzn">§362/§365</a></span><span>.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Several commenters contrast this with OpenAI’s
governance: OpenAI is not a PBC; it’s a non‑profit
parent (OpenAI, Inc.) controlling a capped‑profit
subsidiary (OpenAI LP) with a mission‑oriented charter.
Thus, criticisms that OpenAI “abandoned” a social
mission differ legally from xAI’s move, which removes
any formal public‑benefit obligation from its corporate
form. References: OpenAI’s </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fopenai.com%2Fblog%2Fopenai-lp/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_uO0g-zXif9TpBZHzOkheQzW2HqizNJ_-U13-6iyIXs=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fopenai.com%252Fblog%252Fopenai-lp/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_uO0g-zXif9TpBZHzOkheQzW2HqizNJ_-U13-6iyIXs%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw0RJjfn8CUtQ_dyZps2pQ5A">LP structure explainer</a></span><span> and </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fopenai.com%2Fcharter/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_A5BfNwKX7q305DshzYVqgZoTSGIewVRu98R6UPTZXc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fopenai.com%252Fcharter/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_A5BfNwKX7q305DshzYVqgZoTSGIewVRu98R6UPTZXc%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw2yAFRKcY4uaU5Q4GqyBlMU">Charter</a></span><span>.</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;text-align:left"></p>
</li>
</ul>
<h3 style="margin:0;padding:0;font-size:1.4em;line-height:1.08em;padding-top:0.389em;font-weight:600;text-align:left">
<span>2. OpenAI GPT-5: Pokémon Crystal Run, 4o-vs-5 Routing Debunk,
User Reports, Deep Research/AI Studio Anecdotes</span>
</h3>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fu6wunfy3z7lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/QspMcAeVrz5GoqooLrVJPhOxxjDI3OVSQ5o1yiiJnOY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fu6wunfy3z7lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/QspMcAeVrz5GoqooLrVJPhOxxjDI3OVSQ5o1yiiJnOY%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw3E7L-_mr_ojjgyilumkIEx">GPT-5 completes Pokémon Crystal - Defeats final boss in
9,517 steps compared to 27,040 for o3</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2Fsingularity%2Fcomments%2F1n00qgb%2Fgpt5_completes_pok%25C3%25A9mon_crystal_defeats_final_boss%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/gtvU6kp_EvPWyf4thx2aYfD-Jh4ojbQKhl9BMX8B2bo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252Fsingularity%252Fcomments%252F1n00qgb%252Fgpt5_completes_pok%2525C3%2525A9mon_crystal_defeats_final_boss%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/gtvU6kp_EvPWyf4thx2aYfD-Jh4ojbQKhl9BMX8B2bo%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw38N1vyr5L5FkoyjmjtSQgT">Score: 363, Comments: 72</a></span><span>): </span><span><strong>An X post by Clad3815 claims GPT‑5 completed Pokémon
Crystal and beat the final boss (RED) in
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">9,517</code></span><span><strong> steps vs </strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">27,040</code></span><span><strong>
for o3 (~3× action efficiency), allegedly while
under‑leveled, suggesting stronger world modeling/strategy
beyond typical benchmarks. This is not an official
benchmark; details on experimental setup (action
definition, RNG, resets, tool assistance, or rules) aren’t
provided; stream plans further goals like legendary
catches and Pokédex completion. Source:
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2FClad3815%2Fstatus%2F1959856362059387098/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/kNDi7goxjZdPjTjn8uGB6s8qPAhRFSJvhCRQMs2Xc1g=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fx.com%252FClad3815%252Fstatus%252F1959856362059387098/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/kNDi7goxjZdPjTjn8uGB6s8qPAhRFSJvhCRQMs2Xc1g%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw27o2B48EDDWn6o_T1MIKdJ">https://x.com/Clad3815/status/<wbr>1959856362059387098</a></strong></span><span>
Comments report GPT‑5 (Thinking Mode) outperforming o3 in
legal workflows (fewer hallucinations, better issue
spotting), while others note Pokémon is a favorable RL
environment and inject some skepticism/sarcasm about
hype.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Benchmark-wise, the post title reports GPT-5 clearing
Pokémon Crystal’s final boss in </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">9,517</code></span><span> steps vs </span><span><strong>o3</strong></span><span> at </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">27,040</code></span><span>, implying ~</span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2.8×</code></span><span>
fewer steps (27,040/9,517) and markedly better
long‑horizon planning/sample efficiency than o3 (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fopenai.com%2Findex%2Fintroducing-o3/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/jAYQICnYUEuxZqo9HbRk4ik1ygHIip2wbXz76YPtUCo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fopenai.com%252Findex%252Fintroducing-o3/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/jAYQICnYUEuxZqo9HbRk4ik1ygHIip2wbXz76YPtUCo%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw2l6ilYyUfLvm93TaXcPBlR">o3</a></span><span>). This suggests superior search/pruning or state
abstraction, since fewer environment interactions
typically reflect better exploration–exploitation
balance and credit assignment over long sequences.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Practitioner feedback highlights GPT-5’s &quot;Thinking
Mode&quot; yielding substantially fewer hallucinations
and more accurate legal issue spotting in document
analysis workflows. For coding/engineering, users report
stronger problem decomposition and implementation
guidance, implying improved multi‑step reasoning and
constraint tracking compared to o3, with fewer
off-target suggestions and corrections required.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>One commenter notes Pokémon as a near-ideal
reinforcement learning environment: discrete,
turn-based, and long-horizon with inventory/state
management and sparse rewards. Success here is
informative because it stresses planning under partial
observability and long-term credit assignment, making
step-count efficiency a meaningful proxy for reasoning
quality rather than mere reaction speed.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzthh2%2F4o_is_not_secretly_5_stop_using_llms_to_back_up%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/dHgnrkERJ0SpXlKbtCv4oeO6blRry3Qa-JOtH0iGBBo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzthh2%252F4o_is_not_secretly_5_stop_using_llms_to_back_up%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/dHgnrkERJ0SpXlKbtCv4oeO6blRry3Qa-JOtH0iGBBo%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw2A8_py2GmLjpKVA-pXiwrj">4o is not secretly 5. Stop using LLMs to back up your
paranoia.</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzthh2%2F4o_is_not_secretly_5_stop_using_llms_to_back_up%2F/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/HsBEbfDCOocDZ-9fHMU0NE_Nj_5smGd-79P5k93p2zk=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzthh2%252F4o_is_not_secretly_5_stop_using_llms_to_back_up%252F/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/HsBEbfDCOocDZ-9fHMU0NE_Nj_5smGd-79P5k93p2zk%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw0eMw4HDBlvKL2YfqqgnNu2">Score: 151, Comments: 73</a></span><span>): </span><span><strong>OP debunks the rumor that prompts to GPT-4o are secretly
routed to GPT-5, citing OpenAI docs: GPT-5 is the ChatGPT
default and uses an internal router among GPT-5 variants
(e.g., fast vs thinking/pro) within the GPT-5 family,
while GPT-4o remains a separate, selectable model (and its
API alias maps to its own family/snapshots). Docs note
that aliases like gpt-4o may advance to newer 4o snapshots
and recommend pinning dated snapshots for stability; any
cross-family remap would appear in official
deprecations/release notes, which currently show no notice
of 4o→5 routing (</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fplatform.openai.com%2Fdocs%2Fmodels/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ieE4mDsJgGi5-RVWplm3e4loA4AZI9P-bKk_UW6Kt5Y=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fplatform.openai.com%252Fdocs%252Fmodels/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ieE4mDsJgGi5-RVWplm3e4loA4AZI9P-bKk_UW6Kt5Y%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw1ZVO8GaCuIBNbc5Z8HRG41">Models</a></strong></span><span><strong>, </strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fplatform.openai.com%2Fdocs%2Fdeprecations/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ynvLUlZkQynnFOGGQlxLFLtzjOZZTLxOQv2YtEpIg9U=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fplatform.openai.com%252Fdocs%252Fdeprecations/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ynvLUlZkQynnFOGGQlxLFLtzjOZZTLxOQv2YtEpIg9U%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw2nsiD4z4PsenjmVJtK1Ecd">Deprecations</a></strong></span><span><strong>, </strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fplatform.openai.com%2Fdocs%2Frelease-notes/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/BcIHgDUzJY5FDsWI24QJHHfEdBJ4HqmLQJ6orBmEXII=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fplatform.openai.com%252Fdocs%252Frelease-notes/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/BcIHgDUzJY5FDsWI24QJHHfEdBJ4HqmLQJ6orBmEXII%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw0kCge9KtYn4pImT0qIU6dq">Release notes</a></strong></span><span><strong>).</strong></span><span>
Technical commenters add that with Reference Chat History
enabled, style/tone can “bleed” between sessions: using
GPT-5 can influence how GPT-4o responds due to shared
context memory across chats, potentially explaining
perceived similarity. Others argue both models serve
distinct roles (e.g., GPT-5 thinking for
coding/architecture; 4o for expressive creative
writing).</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Multiple commenters provide a technical explanation for
perceived &quot;model blending&quot;: with Reference
Chat History (RCH) enabled, the system leverages shared
context across sessions, so style/tone from chats with
GPT‑5 can &quot;bleed&quot; into GPT‑4o responses. They
report that archiving/deleting GPT‑5 sessions or
disabling RCH restores 4o’s baseline style; this
reflects a shared context memory that doesn’t strictly
attribute who said what across sessions and optimizes
for continuity, blurring &quot;personalities&quot;
rather than indicating covert model routing. Quote:
&quot;If you have RCH on, any sessions that use 5 will
bleed into how 4o responds… 4o will start talking more
like 5 with RCH on, so if you prefer 4o get rid of the 5
sessions.&quot;</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Several replies critique claims that &quot;4o is
secretly routed to 5&quot; as non-evidence-based, noting
that conversational anecdotes or &quot;reverse
engineering by chatting&quot; are not valid diagnostics.
A rigorous approach would use controlled prompts,
inspect explicit model identifiers/versions in API logs,
and compare reproducible metrics (e.g., latency
distributions, output length/style statistics) instead
of subjective impressions. Thread consensus leans toward
requiring instrumentation before asserting model
swaps.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>A practitioner notes differing strengths: GPT‑4o is
&quot;more expressive&quot; and preferred for creative
writing and thought experiments, while GPT‑5 serves
other purposes—arguing to keep both available. This
frames a task-dependent performance trade-off between
models rather than one universally superior option,
though no quantitative benchmarks are provided.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzm7ag%2Fit_took_me_a_while_but_now_i_also_hate_chatgpt_5%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/dL_49RpW7a0R2pm_4t73d4JIsCYYwcmrQQ-q7ZlAthU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzm7ag%252Fit_took_me_a_while_but_now_i_also_hate_chatgpt_5%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/dL_49RpW7a0R2pm_4t73d4JIsCYYwcmrQQ-q7ZlAthU%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw1yEM5dq73Csidyl2CDPhEl">It took me a while. But now I also hate ChatGPT 5.</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzm7ag%2Fit_took_me_a_while_but_now_i_also_hate_chatgpt_5%2F/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/inXzzYKjKmNALQaswmPbE1zLLrMVQ4BiQKuzisgMTCw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzm7ag%252Fit_took_me_a_while_but_now_i_also_hate_chatgpt_5%252F/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/inXzzYKjKmNALQaswmPbE1zLLrMVQ4BiQKuzisgMTCw%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw2pGvzQWXWUtBIoALdcI3KG">Score: 560, Comments: 261</a></span><span>): </span><span><strong>OP reports a regression from GPT‑4o to GPT‑5 in strict
instruction adherence for code generation within a
proprietary framework: GPT‑5 repeatedly ignores explicit
I/O and Node Class schema constraints, hallucinates
non‑existent integrations/ergonomics, and proposes
unchangeable engine‑level modifications, requiring
frequent re-prompting. Commenters corroborate issues
including rigid, repetitive follow‑up questions, degraded
constraint memory, shorter low‑effort outputs, factual
errors and even spelling mistakes, plus intra‑turn context
loss (e.g., the model attributing to the user a list it
generated itself). Overall pattern: weaker schema binding,
higher hallucination rate for API surfaces, and increased
assistant‑initiated scope creep versus 4o/4.5.</strong></span><span>
Technically oriented complaints emphasize degraded
instruction-following and increased prompt friction, with
some attributing the change to product direction (e.g., push
toward guided follow‑ups) and speculating about cost/usage
optimization; others note seeking alternatives (e.g., Grok)
but finding them inferior to prior 4o/4.5 behavior.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Users report a regression in instruction-following and
response quality with </span><span><strong>GPT‑5</strong></span><span>: it often ignores explicit directions, asks repetitive
clarifying questions, and returns shorter, poorly
researched, or incorrect answers (even with occasional
spelling errors). Compared to </span><span><strong>GPT‑4o/4.1</strong></span><span> and </span><span><strong>o3</strong></span><span>, which understood intent with minimal prompting, </span><span><strong>GPT‑5</strong></span><span>
feels rigid and increases the “prompt tax,” harming
throughput for production work.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>A notable failure mode: within a single response, </span><span><strong>GPT‑5</strong></span><span>
generated a list and then praised the user for the very
list it had produced—evidence of intra-turn state
confusion. This suggests a coherence/control bug where
assistant/user roles get conflated during decoding or
RLHF-driven templating injects misattributed praise, not
merely long-context drift.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Perceived capability/style trade-offs: </span><span><strong>GPT‑5</strong></span><span>
is described as constrained and formulaic (e.g.,
repetitive “Do you want me to…” follow-ups), while </span><span><strong>GPT‑4o</strong></span><span>
was more conversational and creative. Prior models
(</span><span><strong>4o</strong></span><span>, </span><span><strong>4.1</strong></span><span>, </span><span><strong>o3</strong></span><span>) reportedly required fewer iterations to capture
intent; alternatives like </span><span><strong>Grok</strong></span><span>
are said to underperform those earlier baselines,
reinforcing concerns that tighter guardrails may be
suppressing useful generative behavior.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fzg6efc4195lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/BhilRfbHPW_3KfB80KwzbPzWS6JIpFI5oIuwUsvaXsw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fzg6efc4195lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/BhilRfbHPW_3KfB80KwzbPzWS6JIpFI5oIuwUsvaXsw%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw0gZj4Zqq0O3EYsReytzcyA">noooo not gpt-5 as well</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FClaudeAI%2Fcomments%2F1mzmysl%2Fnoooo_not_gpt5_as_well%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/qt-8eNoxgK5hMGE8_E7aNrVfF0QUunsANQF0i0NVLHw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FClaudeAI%252Fcomments%252F1mzmysl%252Fnoooo_not_gpt5_as_well%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/qt-8eNoxgK5hMGE8_E7aNrVfF0QUunsANQF0i0NVLHw%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw3xOn41Mea6i6oBi1g87umu">Score: 428, Comments: 56</a></span><span>): </span><span><strong>Non-technical meme: a screenshot highlighting “codex” and
the canned reply fragment “You’re exactly right —” jokes
that even “GPT‑5” inherits the same LLM catchphrase/style
tics seen in prior OpenAI models (e.g., GPT‑4/ChatGPT),
rather than any new technical capability. The title and
image play on recurring jokes about system prompts and
boilerplate acknowledgments, not any real evidence of
model internals or benchmarks.</strong></span><span>
Comments lean into the running gag about LLMs overusing
phrases like “you’re absolutely/exactly right,” and a
tongue‑in‑cheek claim that OpenAI “got caught using Claude
code,” implying shared stylistic tics or prompt reuse rather
than substantive technical overlap.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fgallery%2F1mzt5r1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/KSQM3iAI09BZakqqse_B6Hggd75l5YDujmqzIK2lWB8=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fgallery%252F1mzt5r1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/KSQM3iAI09BZakqqse_B6Hggd75l5YDujmqzIK2lWB8%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw0-k1WGS1aPeheEyqDPjA_4">Before GPT-5 was released</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzt5r1%2Fbefore_gpt5_was_released%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/mxZjkI8AdI2lylMuVaAKCgAnbvhVFSYVmr_wrWQeg8A=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzt5r1%252Fbefore_gpt5_was_released%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/mxZjkI8AdI2lylMuVaAKCgAnbvhVFSYVmr_wrWQeg8A%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw1mQddVWPC8dKKLLoDSm-TK">Score: 356, Comments: 73</a></span><span>): </span><span><strong>Meta thread about recurring claims that new ChatGPT
releases are “nerfed,” projecting the same cycle for
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">GPT-5</code></span><span><strong> and later </strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">GPT-6</code></span><span><strong>. No benchmarks or implementation details are discussed;
the referenced gallery is inaccessible (HTTP 403) via the
provided link (</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fgallery%2F1mzt5r1/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/96cBNEcRGcaveGHesr5Dtsd0SFGksVOSauGGte9GhMs=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fgallery%252F1mzt5r1/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/96cBNEcRGcaveGHesr5Dtsd0SFGksVOSauGGte9GhMs%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw1FT0Qq-73ZMKJAYzwBrLTb">gallery</a></strong></span><span><strong>).</strong></span><span>
Top comments argue this pattern is perennial and that prior
versions get nostalgically praised once a newer model ships;
several note r/ChatGPT has shifted from use-case sharing to
complaints, with a pragmatic stance of “don’t use it” if
dissatisfied.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Several users note a recurring release pattern: OpenAI
ships major models (e.g., </span><span><strong>o1</strong></span><span>, </span><span><strong>GPT‑4o</strong></span><span>, and even base </span><span><strong>GPT‑4</strong></span><span>) initially with conservative settings—smaller context
windows and stricter/max-token truncation—leading to
early &#39;underbaked&#39; impressions; these are then
relaxed or tuned over subsequent weeks, improving
perceived quality. One example cited is the </span><span><strong>o3</strong></span><span>
release, which drew negative posts at launch but later
became &#39;almost universally&#39; praised,
suggesting staged rollouts and post-deploy calibration
rather than true capability regressions. </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fpreview.redd.it%2Fxrq0r9gtb7lf1.png%3Fwidth=1080%26format=png%26auto=webp%26s=03903e86196901cd997369452c7785e5df8ef51e/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/MCE4kp1WC85UJ9l8Y29_hY-soWml1t6RwWSEeUSh7hA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fpreview.redd.it%252Fxrq0r9gtb7lf1.png%253Fwidth%3D1080%2526format%3Dpng%2526auto%3Dwebp%2526s%3D03903e86196901cd997369452c7785e5df8ef51e/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/MCE4kp1WC85UJ9l8Y29_hY-soWml1t6RwWSEeUSh7hA%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw23g05a5RcxoTVx49TxAdy1">Example screenshot</a></span><span>.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Veteran users argue that claims of random
&#39;lobotomization&#39; have appeared since week one
of ChatGPT and should be treated skeptically absent
longitudinal benchmarks or A/B comparisons; if such
cumulative nerfs were literal, we&#39;d see a reversion
to </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">GPT‑1</code></span><span>-level performance by now. The takeaway is to rely on
reproducible tests (e.g., fixed prompts, controlled
temperature, and context parity) across time rather than
anecdotal impressions.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Far1nq7wl57lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/xN9kAg9nF-OPcKDKOPChe6cTpeV7prOupVCW48VJRKU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Far1nq7wl57lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/xN9kAg9nF-OPcKDKOPChe6cTpeV7prOupVCW48VJRKU%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw26cvXJ7iakT1DywNltODjJ">Sammy,you did it dirty!</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzw4yp%2Fsammyyou_did_it_dirty%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ZYV3RzdxMUXTTx0Dqsb_IYk9p1RxWDo9pnvW0Pu6Hj0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzw4yp%252Fsammyyou_did_it_dirty%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ZYV3RzdxMUXTTx0Dqsb_IYk9p1RxWDo9pnvW0Pu6Hj0%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw1Zu5jcmZCeikCbwEKzz-V1">Score: 185, Comments: 22</a></span><span>): </span><span><strong>Non-technical meme: a two-panel “bus selfie” compares
GPT-4 (intact bus) vs GPT-5 (overturned bus), implying
GPT-5 is a downgrade/regression. The title/selftext
express disappointment and missing GPT-4; no benchmarks,
logs, or technical details are provided. Image:
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Far1nq7wl57lf1.png/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/mQY_VTCqwgLuZ_605GPZwPc8R6-jgvn8CVfK_sYKZDY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Far1nq7wl57lf1.png/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/mQY_VTCqwgLuZ_605GPZwPc8R6-jgvn8CVfK_sYKZDY%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw1hHV2-pnGsWuFo35PvelNC">https://i.redd.it/<wbr>ar1nq7wl57lf1.png</a></strong></span><span>
Comments echo a perception that “4 was better than 5” and
note GPT-4 being removed as an option, while others
criticize the proliferation of 4-vs-5 memes; no measurable
evidence is cited.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>A user claims the ChatGPT UI has </span><span><strong>removed the GPT‑4 selection option</strong></span><span> (</span><span><em>“removed the 4 from the option”</em></span><span>) and asserts 4 performs better than 5. For technical
workflows, this implies a model-availability change or
forced default to newer releases, affecting
reproducibility and evaluation baselines; see OpenAI’s
model availability/deprecation notes: </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fplatform.openai.com%2Fdocs%2Fmodels/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ddhooZlse9x1ZTveNXpEfY8kIAP6OvcQdZw-KrXwFok=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fplatform.openai.com%252Fdocs%252Fmodels/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ddhooZlse9x1ZTveNXpEfY8kIAP6OvcQdZw-KrXwFok%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw0y1hy9V2c3McGgiWQ0oNHs">https://platform.openai.com/<wbr>docs/models</a></span><span>.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Another commenter reports a strict chat cap of </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">10–15</code></span><span>
messages for the current model, after which the session </span><span><em>“returns to a previous model,”</em></span><span>
and asks if this could be used to revert to GPT‑4. This
suggests server-side session caps with potential
automatic model fallback in the consumer UI, but using
caps to select a specific model is likely
unreliable/unsupported; deterministic control over
models is documented for API usage (e.g., specifying the
model name): </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Ftext-generation/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/41Crc8nTvxqkq2bY5BGSVzvr05Cp8wg1byngrzqLgxg=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fplatform.openai.com%252Fdocs%252Fguides%252Ftext-generation/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/41Crc8nTvxqkq2bY5BGSVzvr05Cp8wg1byngrzqLgxg%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw0bomAcKqT-DPMW_S_srGl9">https://platform.openai.com/<wbr>docs/guides/text-generation</a></span><span>.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2F4x47g5mdt3lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ydYYTIpwEp86b4WE3CvMunfWSWXf5WvlX5XUY4PaB14=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252F4x47g5mdt3lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ydYYTIpwEp86b4WE3CvMunfWSWXf5WvlX5XUY4PaB14%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw2Pr-jlip19hvYqoG2KXfsL">Soo uhhh, This just happened?</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FBard%2Fcomments%2F1mzieo0%2Fsoo_uhhh_this_just_happened%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/WCVz88i3BvwLbUhukT9EHFWro0FzxNk7-Z0JPOywhx0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FBard%252Fcomments%252F1mzieo0%252Fsoo_uhhh_this_just_happened%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/WCVz88i3BvwLbUhukT9EHFWro0FzxNk7-Z0JPOywhx0%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw2D_nSLXpELh-DtISYcdeti">Score: 166, Comments: 32</a></span><span>): </span><span><strong>OP shows a screenshot from an AI Studio session where a
custom “Briarheart” jailbreak (used for ERP role-play)
plus an instruction to &quot;focus on thinking mode&quot;
triggered the model to emit an extremely long, repetitive,
aggressive monologue. Technically, this illustrates how
role-play/jailbreak prompts can dominate the model’s
behavior and cause verbosity loops or mode collapse-like
repetition; the behavior is prompt-induced rather than a
spontaneous model failure.</strong></span><span>
Commenters note this isn’t “weird” from the model’s
side—overly specific role-play/jailbreak instructions make
it act this way—while others just find it amusing.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>One commenter argues the observed behavior is a
byproduct of heavy role‑play prompting and persona
conditioning rather than autonomous model drift: </span><span><em>“it’s not them that are losing it. It’s y’all.”</em></span><span>
In instruction‑tuned chat LLMs, the system prompt plus
prior turns act as strong priors that bias next‑token
probabilities; with long context windows and few‑shot
persona examples, the model will remain “in character,”
producing anthropomorphic lines like having a “favorite
user.” This is expected with RLHF‑trained assistants and
can be tested by resetting context, removing persona
priming, and controlling sampling params (e.g., </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">temperature</code></span><span>, </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">top_p</code></span><span>); see </span><span><strong>Anthropic’s</strong></span><span> RLHF overview (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.anthropic.com%2Fresearch%2Frlhf/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ZSmhIvY9mgo0kqqO5_0TNKxAEjAO97249UDqMdfCmcA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.anthropic.com%252Fresearch%252Frlhf/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ZSmhIvY9mgo0kqqO5_0TNKxAEjAO97249UDqMdfCmcA%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw1wJHM6pL12zcVNuDtv1EZs">https://www.anthropic.com/<wbr>research/rlhf</a></span><span>) and </span><span><strong>OpenAI</strong></span><span> prompting docs (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fplatform.openai.com%2Fdocs%2Fguides%2Fprompt-engineering/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/aqKR9y0_th9nhSJ099sh5gY6dZ34oulljU72JAbEWaU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fplatform.openai.com%252Fdocs%252Fguides%252Fprompt-engineering/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/aqKR9y0_th9nhSJ099sh5gY6dZ34oulljU72JAbEWaU%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw00ANb_34omNaPjVKZShQyQ">https://platform.openai.com/<wbr>docs/guides/prompt-engineering</a></span><span><wbr>).</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fpluna8gt54lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/UtePe1wFO5Hzuo1nZ934QCUAe329SIYaK1MnzdeVPqU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fpluna8gt54lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/UtePe1wFO5Hzuo1nZ934QCUAe329SIYaK1MnzdeVPqU%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw239NOICb-QfPsE45Pn46V2">AGI Achieved. Deep Research day dreams about food mid
task</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FOpenAI%2Fcomments%2F1mzjimx%2Fagi_achieved_deep_research_day_dreams_about_food%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/j_TQF8Yba-3qgN8NXrHky2w6r87FXgHeDxUdjJs36SM=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FOpenAI%252Fcomments%252F1mzjimx%252Fagi_achieved_deep_research_day_dreams_about_food%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/j_TQF8Yba-3qgN8NXrHky2w6r87FXgHeDxUdjJs36SM%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw23XbrzQx11eMx1A0KWZeVJ">Score: 1104, Comments: 56</a></span><span>): </span><span><strong>This is a humorous, non-technical screenshot of a “Deep
Research” workflow UI where the model’s surfaced
“thoughts” digress to the “twine method for pie crusts”
mid numeric analysis, highlighting that the tool exposes
intermediate reasoning/trace content that can include
off‑topic associations. The title’s “AGI Achieved” is
tongue‑in‑cheek; technically it underscores the
anthropomorphic feel and potential noisiness of displaying
chain‑of‑thought‑style traces rather than any capability
leap. One commenter adds the task was algo‑trading number
crunching, reinforcing that the digression occurred during
a routine, boring computation task.</strong></span><span>
Commenters note the thought stream can be more entertaining
than answers, joke about “Python” vs “pie,” and liken the
detour to human daydreaming during monotonous work.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Multiple reports show Deep Research injecting whimsical
“thoughts” (e.g., </span><span><em>“Mmmm… pie!”</em></span><span>
or references to bananas) mid-run, even during
quant-heavy/algorithmic trading tasks. Commenters infer
this may be an intentionally added persona/UX flourish
rather than genuine intermediate reasoning, which
reduces the signal-to-noise of audit logs and could
hinder reproducibility in numeric workflows; ideally
this should be toggleable or filtered.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>There’s active interest in applying Deep Research to
investment analysis/algorithms; a commenter building a
stock-focused deep-research tool, </span><span><a href="http://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/http:%2F%2Fdeepvalue.tech/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/6leMDXVRu4sWBK1Tbyk71r-B8AJ_6O4reuPhBzyqxeQ=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=http://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/http:%252F%252Fdeepvalue.tech/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/6leMDXVRu4sWBK1Tbyk71r-B8AJ_6O4reuPhBzyqxeQ%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw2PCyXbbRVQFs26TegfNMKV">deepvalue.tech</a></span><span>, solicited use cases and gaps. The mentioned tasks
involve large-scale number crunching; evaluation
priorities for such tools would include data sourcing
transparency, quantitative error rates, and structuring
multi-step financial analyses.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>A user notes preferring the surfaced “thoughts” over
final answers, highlighting demand for interpretable
intermediate steps. If those “thoughts” include
non-task-related filler, they risk misleading users
about actual reasoning quality and can confound attempts
to audit or benchmark the system’s decision path.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzs3xb%2Fhow_do_you_make_ai_generated_text_undetectable%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/MkF2mrlLKOEhcBudgY05W7DSLRvoArogOpmqLDy4hls=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzs3xb%252Fhow_do_you_make_ai_generated_text_undetectable%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/MkF2mrlLKOEhcBudgY05W7DSLRvoArogOpmqLDy4hls%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw1p3SHrxI1Q8Pr-acILKp5y">How do you make AI generated text undetectable from
Turnitin and other AI detectors</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzs3xb%2Fhow_do_you_make_ai_generated_text_undetectable%2F/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/flc76ajcy7FnZP3E1qTM6nG8QGWvZH53z_nxPp8oWy4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzs3xb%252Fhow_do_you_make_ai_generated_text_undetectable%252F/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/flc76ajcy7FnZP3E1qTM6nG8QGWvZH53z_nxPp8oWy4%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw2-blL0GxYAqcHr0QM7wxbm">Score: 301, Comments: 76</a></span><span>): </span><span><strong>OP asks if there’s a way to make AI‑generated text
undetectable by
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.turnitin.com%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/pXcn3jORBPti8i4VZDYOOC6jdAL43PJDXxVwkBtdZBc=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.turnitin.com%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/pXcn3jORBPti8i4VZDYOOC6jdAL43PJDXxVwkBtdZBc%3D419&amp;source=gmail&amp;ust=1756263078806000&amp;usg=AOvVaw0AFNbUbvl07tZe0sYjA4eB">Turnitin</a></strong></span><span><strong>
and other AI detectors, noting such detectors are
unreliable. Top replies assert there’s no dependable
technical method to guarantee undetectability; the only
robust approach is to author the work yourself, optionally
using AI strictly for proofreading, and to retain a
personal voice (including natural imperfections) rather
than attempting detector evasion.</strong></span><span>
Consensus view: ethically and practically, students should
write their own work; attempts to bypass detectors are
discouraged and seen as contrary to the purpose of
university study.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Commenters highlight unreliability of current
AI-writing detectors (e.g., Turnitin-style tools),
citing false positives; one reports a fully
human-written short story being flagged as </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">25%</code></span><span>
AI-generated. The consensus is that these systems
provide heuristic confidence scores that can
misattribute authorship, so flags should not be treated
as definitive evidence.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Others argue that manual paraphrasing and adding a
personal voice (keeping wording simple and introducing
small imperfections) can reduce detectability, implying
detectors rely on stylometric cues like uniformity and
low lexical diversity rather than robust semantic
attribution. One notes that even prompting a model to
make text </span><span><em>“undetectable”</em></span><span>
sometimes works, underscoring brittleness in current
detector decision boundaries.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Ffortune.com%2F2025%2F08%2F25%2Ftech-agi-hype-vibe-shift-superpowered-ai%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/JDduu9jsAeEJh2AApSrkfC9PnwOIwt57sWyGVGxAFrw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Ffortune.com%252F2025%252F08%252F25%252Ftech-agi-hype-vibe-shift-superpowered-ai%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/JDduu9jsAeEJh2AApSrkfC9PnwOIwt57sWyGVGxAFrw%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0V8gz_NEAMS8ZAjLuqzZX3">AGI talk is out in Silicon Valley’s latest vibe shift,
but worries remain about superpowered AI</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FOpenAI%2Fcomments%2F1mzns63%2Fagi_talk_is_out_in_silicon_valleys_latest_vibe%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Xy9SsNYp69EU9kZAXv8HwOcdUE7RQ0Uegd_fMTb4scg=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FOpenAI%252Fcomments%252F1mzns63%252Fagi_talk_is_out_in_silicon_valleys_latest_vibe%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Xy9SsNYp69EU9kZAXv8HwOcdUE7RQ0Uegd_fMTb4scg%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw13EdX22h6JBZ2iCAXc2uPk">Score: 198, Comments: 55</a></span><span>): </span><span><strong>Thread notes a rhetoric shift in Silicon Valley away from
monolithic &quot;AGI&quot; toward domain-specific
&quot;superintelligences&quot;—i.e., specialized systems
with superhuman capability in constrained domains—while
concerns about &quot;superpowered AI&quot; persist. The
implicit technical reframing prioritizes verticalized
models and products (code, science, robotics) over a
single generally capable system, acknowledging that
current frontier models remain far from
domain-transferable, robust general reasoning despite
scaling. See background on
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fen.wikipedia.org%2Fwiki%2FArtificial_general_intelligence/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/TQFQempf5GEsYlliRLeRVFPJzxJ7k6TYBLE43Ny56Ds=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fen.wikipedia.org%252Fwiki%252FArtificial_general_intelligence/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/TQFQempf5GEsYlliRLeRVFPJzxJ7k6TYBLE43Ny56Ds%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw3gDccumyXiJZddIFXvYv1l">AGI</a></strong></span><span><strong> vs. </strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fen.wikipedia.org%2Fwiki%2FArtificial_narrow_intelligence/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/nNS_jFLT4AdP_iqbLHpHHv1V9lJ4h0CRtWYpFkNuntY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fen.wikipedia.org%252Fwiki%252FArtificial_narrow_intelligence/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/nNS_jFLT4AdP_iqbLHpHHv1V9lJ4h0CRtWYpFkNuntY%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw3gsrBcqGxF9En42HJGH4kJ">narrow AI</a></strong></span><span><strong>.</strong></span><span>
Comments debate whether this is a substantive shift or
narrative repositioning: one quips, </span><span><em>“Someone remind me what the G in AGI stands for?”</em></span><span>, another claims the change admits we’re not close to AGI,
and a third compares expectations to the Web’s early hype
cycle—overestimated short-term progress, underestimated
long-term impact.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Several comments note a shift from chasing a single,
monolithic “AGI” to building domain-specific
“superintelligences,” implying an architecture strategy
of specialized models (e.g., code, bio, search)
orchestrated via tools/agents. This prioritizes
domain-tuned data, bespoke evals, and integration layers
over a one-size-fits-all foundation, since specialists
often outperform generalists on narrow, high-stakes
tasks.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Skeptics argue current LLM scaling is unlikely to yield
AGI due to training objectives (next-token prediction)
that don’t enforce grounded world models, long-horizon
planning, or reliable tool-use. They point to brittle
reasoning, hallucinations, and weak systematic
generalization as evidence and argue for hybrid
approaches (explicit memory, model-based RL,
neuro-symbolic methods, or multimodal world models) if
“general” capabilities are the goal.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>The narrative cooling on AGI is framed as a
recalibration of timelines rather than abandonment:
capability growth is real but uneven, with persistent
bottlenecks (evaluation overfitting, inference
cost/latency, and safety/robustness gaps).
Expectation-setting moves toward multi-year
infrastructure and product cycles, not rapid
step-function leaps, echoing early web-era
hype-versus-delivery dynamics.</span>
</p>
</li>
</ul>
</li>
</ul>
<h3 style="margin:0;padding:0;font-size:1.4em;line-height:1.08em;padding-top:0.389em;font-weight:600;text-align:left">
<span>3. Alibaba WAN 2.2 S2V and Qwen Image Editing Demos +
Generative Media/Art Parodies</span>
</h3>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fv.redd.it%2Fu1iggczq17lf1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/QOHup-gKQo1424-I_FLOi9omj56o5zEuHygnmlEE68M=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fv.redd.it%252Fu1iggczq17lf1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/QOHup-gKQo1424-I_FLOi9omj56o5zEuHygnmlEE68M%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw1jA7cum1-iK2ISqiMM-AVv">WAN will provide a video model with sound 👁️‍🗨️🔊 WAN 2.2
S2V</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1mzvlp2%2Fwan_will_provide_a_video_model_with_sound_wan_22%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/AdXpt_OssgLZljurd0ThZW0pwPdFi3XjWAsLOKqGHN4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FStableDiffusion%252Fcomments%252F1mzvlp2%252Fwan_will_provide_a_video_model_with_sound_wan_22%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/AdXpt_OssgLZljurd0ThZW0pwPdFi3XjWAsLOKqGHN4%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0qXeePUVi4svi3xPsehyfN">Score: 262, Comments: 62</a></span><span>): </span><span><strong>Alibaba’s WAN team teased “WAN </strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2.2</code></span><span><strong> S2V” via </strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2FAlibaba_Wan%2Fstatus%2F1959963989703880866/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/loCXWFoSCVBdu7oaWVZOvUwhCNHEo4sBxhvva0ES8M4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fx.com%252FAlibaba_Wan%252Fstatus%252F1959963989703880866/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/loCXWFoSCVBdu7oaWVZOvUwhCNHEo4sBxhvva0ES8M4%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0HDzAF8HomwICRvtGsgbDp">post 1</a></strong></span><span><strong> and </strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2FAlibaba_Wan%2Fstatus%2F1960012297059057935/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/CbeXRv1FMP-M5j6RkGNHO1-B1jsq86UokvMhG_WtiXw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fx.com%252FAlibaba_Wan%252Fstatus%252F1960012297059057935/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/CbeXRv1FMP-M5j6RkGNHO1-B1jsq86UokvMhG_WtiXw%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw03IngDu-rzg7x_CtO03I22">post 2</a></strong></span><span><strong>, suggesting upcoming sound-enabled video generation.
From the available previews, it appears to be audio-driven
video (speech-to-video/lip-sync) rather than end-to-end
audio synthesis; no model card, training details, metrics,
or release timeline were provided, and the original
</strong></span><span><strong><a href="http://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/http:%2F%2Fv.redd.it/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/EXzwzzq66FDyMxFA4oEqsjYTVSwYTssmaZdh6Y_mJAY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=http://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/http:%252F%252Fv.redd.it/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/EXzwzzq66FDyMxFA4oEqsjYTVSwYTssmaZdh6Y_mJAY%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0KisJ-EfdeRhn7JKbtDE_s">v.redd.it</a></strong></span><span><strong> media is gated (HTTP 403).</strong></span><span>
Technical replies emphasize it looks like an audio-driven
lip-sync pipeline, not a model that generates audio. A
related workflow is cited: </span><span><strong>Kijai’s</strong></span><span>
ComfyUI WanVideoWrapper “Infinite Talk” V2V for adding
custom voice with lip-sync to existing video, with example
workflows here: </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fgithub.com%2Fkijai%2FComfyUI-WanVideoWrapper%2Ftree%2Fmain%2Fexample_workflows/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/pvP_XZwljdJghEInwnGZuFz-0JWpg1VeQ7p0vQGFDZU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fgithub.com%252Fkijai%252FComfyUI-WanVideoWrapper%252Ftree%252Fmain%252Fexample_workflows/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/pvP_XZwljdJghEInwnGZuFz-0JWpg1VeQ7p0vQGFDZU%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw1hNuQDIeueLFYENOXNk7A1">https://github.com/kijai/<wbr>ComfyUI-WanVideoWrapper/tree/<wbr>main/example_workflows</a></span><span>.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Clarification from users: WAN 2.2 S2V appears to be an
audio-driven video pipeline—using an input audio track
to drive visual motion (e.g., lip/mouth sync)—and does
not synthesize or output audio itself. As one notes, </span><span><em>“looks like audio driven video, not a model that
produces audio,”</em></span><span>
implying no V2S (video-to-sound) capability in this
release.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>For adding audio with proper lip sync, </span><span><strong>Kijai</strong></span><span>
provides a ComfyUI workflow: “V2V infinite talk” in the </span><span><strong>ComfyUI-WanVideoWrapper</strong></span><span>
examples. It takes an existing video and a user-provided
voice/sound track and performs lipsync (a V2V pipeline);
see </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fgithub.com%2Fkijai%2FComfyUI-WanVideoWrapper%2Ftree%2Fmain%2Fexample_workflows/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/1UN0hfaJYLLzFKIIUEuU1LGoZ_LJRDwoYDxUq49pofw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fgithub.com%252Fkijai%252FComfyUI-WanVideoWrapper%252Ftree%252Fmain%252Fexample_workflows/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/1UN0hfaJYLLzFKIIUEuU1LGoZ_LJRDwoYDxUq49pofw%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw3DbGBjKimDsaGTaDDRH48f">https://github.com/kijai/<wbr>ComfyUI-WanVideoWrapper/tree/<wbr>main/example_workflows</a></span><span>
and search for the &quot;infinitetalk v2v&quot;
JSON.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Use-case discussion: some prefer V2S over S2V, wanting
automatic Foley/SFX generation (e.g., punches,
explosions) from video rather than turning sound into
video. V2S would synthesize audio conditioned on visual
events/timing, whereas S2V consumes audio to condition
visual generation; the current announcement seems to
deliver the latter, not the former.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fv.redd.it%2F5zizxpo6q3lf1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/sQ-zeL72ZCoJwK5aJjFTQv9bE7czA_aIxmbqX-cmSg8=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fv.redd.it%252F5zizxpo6q3lf1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/sQ-zeL72ZCoJwK5aJjFTQv9bE7czA_aIxmbqX-cmSg8%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw3d8dCXcBC23FD3DkYrPoUL">Qwen Image Edit + Wan 2.2 FFLF - messing around using
both together. More of my dumb face (sorry), but learned
Qwen isn&#39;t the best at keeping faces consistent.
Inpainting was needed.</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1mzi65s%2Fqwen_image_edit_wan_22_fflf_messing_around_using%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/CDaRlDpNrvRkhIcqPFQvDFtIpYkK47Tr_m7wPyFm7QM=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FStableDiffusion%252Fcomments%252F1mzi65s%252Fqwen_image_edit_wan_22_fflf_messing_around_using%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/CDaRlDpNrvRkhIcqPFQvDFtIpYkK47Tr_m7wPyFm7QM%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw04HyUAKv-5-wxwmrY74Xly">Score: 638, Comments: 69</a></span><span>): </span><span><strong>OP demos a hybrid image/video generation workflow
combining Qwen Image Edit with Wan
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2.2 FFLF</code></span><span><strong>, reporting strong visual quality but noting Qwen’s weak
face identity consistency—requiring an inpainting pass to
maintain the subject’s face. Compared to a standard Wan
2.2 workflow, viewers observed higher apparent resolution
and more coherent outputs; sample video link:
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fv.redd.it%2F5zizxpo6q3lf1/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/nEV_Pmwi_9ZPRZ2QqD34RYyqgsmlb3w6cPdN8y9M8Rw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fv.redd.it%252F5zizxpo6q3lf1/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/nEV_Pmwi_9ZPRZ2QqD34RYyqgsmlb3w6cPdN8y9M8Rw%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw2w237hf2g5-ouidXfZPJME">v.redd.it/5zizxpo6q3lf1</a></strong></span><span><strong> (403/login required).</strong></span><span>
Commenters ask for the exact Wan 2.2 high‑quality workflow
and note the combo “doesn’t magically pull spawn items out
of the ether” (i.e., fewer hallucinated insertions),
praising the approach as a solid way to pair both
models.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Combining </span><span><strong>Qwen Image Edit</strong></span><span> with </span><span><strong>Wan 2.2 FFLF</strong></span><span>
appears to produce higher-resolution outputs than a
“standard Wan 2.2 workflow,” but identity consistency is
a weak point for Qwen without explicit inpainting. The
OP indicates inpainting was necessary to keep the same
face across edits, implying a workflow where Qwen
handles broad edits and targeted inpaint passes lock
identity fidelity.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Several users request the exact workflow/pipeline for
achieving the showcased quality with </span><span><strong>Wan 2.2 FFLF</strong></span><span>, noting their own results are lower-res with the
default Wan 2.2 setup. There’s specific interest in
reproducibility details (e.g., step order, edit vs.
inpaint passes) rather than generic prompts, to
replicate the higher-fidelity outputs shown.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>A technical observation highlights that Qwen’s edit
pass “doesn’t magically pull spawn items out of the
ether” and remains coherent with the source image,
suggesting lower hallucination under constrained edits.
However, this coherence likely necessitates inpainting
for controlled insertions or identity preservation,
trading off free-form generation for adherence to the
original scene.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fv.redd.it%2Fdd1zfqjqi5lf1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/9WvtxFxAfkI6ARktLJX9pgLGvHHwzhj91JzfZlN5w9U=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fv.redd.it%252Fdd1zfqjqi5lf1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/9WvtxFxAfkI6ARktLJX9pgLGvHHwzhj91JzfZlN5w9U%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0IHlBuzrcilyM4cOcSxP60">Using AI to play inside Magic the Gathering artworks
and worlds</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2Fsingularity%2Fcomments%2F1mzo0ku%2Fusing_ai_to_play_inside_magic_the_gathering%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/SbY7zGF1MeGMBilXsunCoRJKm41hC1d-qFnVaguUUjY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252Fsingularity%252Fcomments%252F1mzo0ku%252Fusing_ai_to_play_inside_magic_the_gathering%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/SbY7zGF1MeGMBilXsunCoRJKm41hC1d-qFnVaguUUjY%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0pLfq_eNUs9HDGa4kHe52O">Score: 1436, Comments: 133</a></span><span>): </span><span><strong>The post claims an AI-driven interactive experience that
lets users &quot;play inside&quot; Magic: The Gathering
card artworks/worlds (i.e., navigable environments derived
from 2D art), but the linked media
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fv.redd.it%2Fdd1zfqjqi5lf1/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Mo3v6V1wJLMvcMUa85jMtjvWFuIUSgG7bxVOTYnFbMs=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fv.redd.it%252Fdd1zfqjqi5lf1/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Mo3v6V1wJLMvcMUa85jMtjvWFuIUSgG7bxVOTYnFbMs%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw3QR0vGLFHgzMyLpJeWaruH">v.redd.it/dd1zfqjqi5lf1</a></strong></span><span><strong> is currently inaccessible (HTTP </strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">403</code></span><span><strong>), so model, pipeline, or implementation details cannot
be verified from the thread. No code, benchmarks, or named
models are provided; the discussion lacks technical
specifics beyond interest and requests for
attribution/source.</strong></span><span>
Top comments are mostly non-technical hype; one asks for
provenance and speculates it may use a Google engine—</span><span><em>“Share the source please… Guessing it’s Google’s engine.
Can a mortal access it?”</em></span><span>—but no confirmation or access details are given.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>The only technical-leaning thread is a request for the
specific engine/model used to generate the playable
MTG-style environments; one commenter speculates it
might be a Google system and asks if it’s publicly
accessible so they can try it on other card art. No
implementation details, model names, or performance
notes (e.g., latency, FPS, or training/inference setup)
were provided in the thread, so readers are seeking
attribution and access details rather than debating
techniques.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fv.redd.it%2Fk6vrey0eb3lf1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/qsjr6T0SsziE2kDUtLraHEV-be79vukoby4KsIq3eR0=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fv.redd.it%252Fk6vrey0eb3lf1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/qsjr6T0SsziE2kDUtLraHEV-be79vukoby4KsIq3eR0%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0LeiL3ygaswFyiDG4Er69i">Nicolas Cage is Barbie (2026) - Trailer</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2Faivideo%2Fcomments%2F1mzgoq8%2Fnicolas_cage_is_barbie_2026_trailer%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/qBGX3Nf9pSF7r9S2D_g4gHXLc1tg09eLL_jqLsZovAM=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252Faivideo%252Fcomments%252F1mzgoq8%252Fnicolas_cage_is_barbie_2026_trailer%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/qBGX3Nf9pSF7r9S2D_g4gHXLc1tg09eLL_jqLsZovAM%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw3VcECpG9k3xxZxHZleGUbZ">Score: 195, Comments: 30</a></span><span>): </span><span><strong>Reddit post shares a parody trailer titled “Nicolas Cage
is Barbie (2026) – Trailer,” but the hosted video at
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fv.redd.it%2Fk6vrey0eb3lf1/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/nRLjRLwFurcxHu4QNIriv_DyDJP6LHOToLLmLSwh73k=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fv.redd.it%252Fk6vrey0eb3lf1/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/nRLjRLwFurcxHu4QNIriv_DyDJP6LHOToLLmLSwh73k%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0LPAA_j5oXN2F533kb9EJd">https://v.redd.it/<wbr>k6vrey0eb3lf1</a></strong></span><span><strong> returns HTTP </strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">403 Forbidden</code></span><span><strong>
without Reddit authentication, so the underlying media
could not be retrieved or analyzed. Consequently, no
technical details about the editing/VFX pipeline,
potential AI face-swap usage, audio design, or source
material can be verified from the link alone.</strong></span><span>
Top comments are non-technical, expressing positive
reception (humor and watchability) with no substantive
critique of production methods or tools.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fabjtmbasx4lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ecWmW77Hk2FsuR7osO8c5sBOU42s_2MuJyOLoK9Hc5c=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fabjtmbasx4lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ecWmW77Hk2FsuR7osO8c5sBOU42s_2MuJyOLoK9Hc5c%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw1oijxZw4aLbD7FHxL5zzz1">The anti-AI crowd would be less upset if we rebranded
it as AI art mining</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FStableDiffusion%2Fcomments%2F1mzlwb0%2Fthe_antiai_crowd_would_be_less_upset_if_we%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ET_iEkm2y67Zqk45HyJ6yElxduOleZRgnyA-OLYVb8Q=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FStableDiffusion%252Fcomments%252F1mzlwb0%252Fthe_antiai_crowd_would_be_less_upset_if_we%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ET_iEkm2y67Zqk45HyJ6yElxduOleZRgnyA-OLYVb8Q%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0M3qY9hnVUw685-avXB-mr">Score: 222, Comments: 98</a></span><span>): </span><span><strong>Discussion post suggests rebranding AI image generation
as “AI art mining” (i.e., exploring/model “latent space”)
to defuse backlash against “vibe prompting” (LLM-assisted
prompt crafting). The attached image—a whimsical forest
scene with a person in leaf attire holding a cat—serves as
an example output of text-to-image generation rather than
a new model/technique; no implementation details or
benchmarks are provided.</strong></span><span>
Comments split: a former pro artist uses AI as a disability
aid via open-source tools and emphasizes low energy use
(“about three light bulbs”), others argue rebranding is
pointless and critique some ‘prompt engineers’ for weak art
fundamentals, while some artists say they simply use AI as a
complementary tool.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>A commenter distinguishes two image‑generation
workflows: exploratory prompting (akin to scouting
photos/screenshots) versus directed composition with
positional control. They note that quality depends
heavily on tuning diffusion parameters like </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">steps</code></span><span> and </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">sampler</code></span><span>, and that using tools to control object placement
(e.g., ControlNet‑style conditioning: </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Farxiv.org%2Fabs%2F2302.05543/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/vSSLw0HUfUFygiIGCejSPV3vpmaUwZsxcWtNdJQNvnw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Farxiv.org%252Fabs%252F2302.05543/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/vSSLw0HUfUFygiIGCejSPV3vpmaUwZsxcWtNdJQNvnw%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0XrUpJgwZBdX40iaFBP6OM">https://arxiv.org/abs/2302.<wbr>05543</a></span><span>) can transform outputs from random exploration to
intentional layouts; scheduler choice materially impacts
sharpness/speed (see Diffusers schedulers: </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fhuggingface.co%2Fdocs%2Fdiffusers%2Fusing-diffusers%2Fschedulers/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/hHdEQCCVjhSspvWLNEYUW0r1lZ37YA1MyPk-zptdsRY=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fhuggingface.co%252Fdocs%252Fdiffusers%252Fusing-diffusers%252Fschedulers/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/hHdEQCCVjhSspvWLNEYUW0r1lZ37YA1MyPk-zptdsRY%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw38nqHMxDPLN6jpqpQLEqfg">https://huggingface.co/docs/<wbr>diffusers/using-diffusers/<wbr>schedulers</a></span><span>). They mention working with &quot;qwen image,&quot;
underscoring that not all AI art is just text
prompts—some workflows approach full compositional
control.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Another commenter highlights using open‑source, local
tooling for accessibility (assistive/disability use
case) with very low power draw (&quot;about three light
bulbs&quot;), implying on‑device inference rather than
cloud GPUs. This aligns with running Stable Diffusion
pipelines on consumer hardware via tools like </span><span><strong>AUTOMATIC1111</strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fgithub.com%2FAUTOMATIC1111%2Fstable-diffusion-webui/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ixcFUEfOzq1vPMPH3zC7xpb4HWpC1HiQx7NPM2OCubE=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fgithub.com%252FAUTOMATIC1111%252Fstable-diffusion-webui/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/ixcFUEfOzq1vPMPH3zC7xpb4HWpC1HiQx7NPM2OCubE%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw1ZjxZA1roDD6Vo1XmHOfi3">https://github.com/<wbr>AUTOMATIC1111/stable-<wbr>diffusion-webui</a></span><span>) or </span><span><strong>ComfyUI</strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fgithub.com%2Fcomfyanonymous%2FComfyUI/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/F7yJC8VTonENLeClGxlUBpyusXVFobqcAW-ZNt-beKw=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fgithub.com%252Fcomfyanonymous%252FComfyUI/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/F7yJC8VTonENLeClGxlUBpyusXVFobqcAW-ZNt-beKw%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0g9gMkcndOImHUVWIfT9NP">https://github.com/<wbr>comfyanonymous/ComfyUI</a></span><span>), trading peak throughput for privacy, cost control,
and offline availability.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fmyt2f9wwo4lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/rFLbuyorgq0HwsSz55gCHIJQcV2MGlxeEu9dsk2TO90=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fmyt2f9wwo4lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/rFLbuyorgq0HwsSz55gCHIJQcV2MGlxeEu9dsk2TO90%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw2IoW9emu8WdzOlDriPqlZr">Asked ChatGPT to show me how to roll a wrap.</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzl4rx%2Fasked_chatgpt_to_show_me_how_to_roll_a_wrap%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Rd3fI25jcObT9iIQ7OztBbePee1QpR_pjQlOWKLF528=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzl4rx%252Fasked_chatgpt_to_show_me_how_to_roll_a_wrap%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/Rd3fI25jcObT9iIQ7OztBbePee1QpR_pjQlOWKLF528%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw1vw6xAJUxpI6wO-mKLrlTI">Score: 2031, Comments: 166</a></span><span>): </span><span><strong>Non-technical/meme example highlighting an LLM
limitation: when asked to show how to roll a wrap, ChatGPT
produced a step-by-step diagram that mimics an
envelope/letter fold rather than a correct burrito-style
roll (side folds, bottom up, then a neat “parcel”),
underscoring poor visuospatial/procedural reasoning and
unreliable autogenerated diagrams without physical
grounding. It illustrates how LLMs can confidently output
incorrect action sequences and malformed instructional
graphics.</strong></span><span>
Commenters note it looks like “sending a letter,” agree it’s
“not much better,” and report that ChatGPT often offers
diagrams unprompted and they’re consistently
wrong—reinforcing the model’s weakness at diagram synthesis
and step ordering.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Multiple users highlight a recurrent LLM failure mode
with ASCII/diagram generation: models often propose
diagrams unprompted and produce structurally incorrect
or misaligned visuals. This likely stems from
token-level next-word training without geometric
constraints, plus whitespace handling and
proportional-font rendering that breaks intended layout;
even with monospaced code blocks, alignment is brittle
and non-deterministic. Practically, users should disable
unsolicited ASCII via explicit instructions and prefer
tool-assisted outputs (e.g., SVG or image generation
with a renderer) if spatial fidelity is required.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Examples of contradictory or nonsensical step-by-step
instructions (e.g., adding ingredients then discarding
them, duplicating tortillas) illustrate planning
consistency issues in LLMs, especially for procedural
tasks with physical constraints. These are classic
coherence errors from weak grounded reasoning and lack
of constraint checks; mitigation includes requiring
state-tracking, validating steps against constraints,
and enforcing structured outputs (checklists with
pre/post-conditions) instead of free-form prose.
Deterministic decoding (low temperature) reduces
variance but does not eliminate logical contradictions
without explicit constraints or external
validators.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fmppmscmth7lf1.jpeg/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/1iLZNtq6L18puS8oR-o9hpRsktyULT35IgT8w4wZnwo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fmppmscmth7lf1.jpeg/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/1iLZNtq6L18puS8oR-o9hpRsktyULT35IgT8w4wZnwo%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw1bd5tLAXTuvOIyAgSzIVDD">My attempt at generating a generic ChatGPT response as
my dating app opening message</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzy0pm%2Fmy_attempt_at_generating_a_generic_chatgpt%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/TRoocYAuN0DSrlwHzvAn9JSTivwrpncMgvmXcbF_gcQ=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzy0pm%252Fmy_attempt_at_generating_a_generic_chatgpt%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/TRoocYAuN0DSrlwHzvAn9JSTivwrpncMgvmXcbF_gcQ%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw1F1ME4N-cZ7iXCrILxcOBW">Score: 197, Comments: 104</a></span><span>): </span><span><strong>Non-technical/meme post: a dating app opener formatted
like a ChatGPT response that humorously “analyzes” a
match’s scenic photos (e.g., attributing them to real
Colorado scenery, good lighting, and a DSLR) with a
tongue‑in‑cheek disclaimer. The technical angle is purely
cultural: it references ChatGPT’s response style as a
social icebreaker; no models, benchmarks, or
implementation details are discussed.</strong></span><span>
Comments split between finding it funny and calling it
cringe; top replies encourage authenticity over optimizing
for reactions.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fv.redd.it%2Fnhsq3lwcv5lf1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/DPXkrWrEKTyb0CcRq8hVplpKQsGz2oTz1Lr1grFZ4f8=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fv.redd.it%252Fnhsq3lwcv5lf1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/DPXkrWrEKTyb0CcRq8hVplpKQsGz2oTz1Lr1grFZ4f8%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw20-8IxQin1NlhlfZZYGdmI">I am a lazyfck so i built this</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPTCoding%2Fcomments%2F1mzpg7f%2Fi_am_a_lazyfck_so_i_built_this%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/vLkhb4-yLPSxYNGf9BSHUehuDaSW4PMAddJ0Qgfp0AA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPTCoding%252Fcomments%252F1mzpg7f%252Fi_am_a_lazyfck_so_i_built_this%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/vLkhb4-yLPSxYNGf9BSHUehuDaSW4PMAddJ0Qgfp0AA%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw2BYVxobZdZtnhQNKO34clI">Score: 291, Comments: 61</a></span><span>): </span><span><strong>Indie app uses on‑device computer vision via the phone
camera to track workouts offline (&quot;no cloud&quot;),
auto‑count reps, and flag cheating/bad posture across
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">28</code></span><span><strong>
exercises; it also &quot;roasts&quot; missed sessions and
gates social apps (e.g., Instagram/TikTok) behind a quick
push‑up task. Early preview only; waitlist is open at
</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Flazyfcks.vercel.app/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/pZLVNry4kHQfbwOMtXBBRcS0JmyiGFpvhHmWcToctEI=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Flazyfcks.vercel.app/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/pZLVNry4kHQfbwOMtXBBRcS0JmyiGFpvhHmWcToctEI%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw0DJNGudJNZB1Jlpls84_Tr">https://lazyfcks.vercel.app</a></strong></span><span><strong>
and the demo video is hosted on Reddit (</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fv.redd.it%2Fnhsq3lwcv5lf1/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/gvpqCo2L7vyfcjJ8unuCnZg9_qLRF5yvsNed9inHcsA=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fv.redd.it%252Fnhsq3lwcv5lf1/2/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/gvpqCo2L7vyfcjJ8unuCnZg9_qLRF5yvsNed9inHcsA%3D419&amp;source=gmail&amp;ust=1756263078807000&amp;usg=AOvVaw2osAGt_3S_U6S6VmOUchkh">https://v.redd.it/<wbr>nhsq3lwcv5lf1</a></strong></span><span><strong>) but currently returns HTTP 403 without authenticated
access. Focus is privacy and low‑latency on‑device
inference rather than cloud processing.</strong></span><span>
One commenter suggests the final rep should not be counted,
implying stricter rep‑validation heuristics to discourage
form breakdown near failure; other top comments are
non‑technical.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Form/ROM critique for valid push-ups: one commenter
notes you should get the chest to the floor (or very
close) and avoid flaring the elbows. Translated into
objective criteria, that implies a depth threshold
(e.g., chest/shoulder midpoint within ~</span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">3–5 cm</code></span><span> of floor or upper-arm angle past </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">90°</code></span><span>
at the bottom) and an elbow abduction limit of roughly </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">≤45°</code></span><span>
relative to the torso to reduce shoulder stress. These
cues help ensure full range of motion and more reliable
rep validation if you’re automating counting or
feedback.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>Rep-quality and termination logic: feedback like “the
last rep shouldn’t count” and “0, 0, 0… terminated”
implies adding stricter validity checks and a robust
state machine. Require both bottom depth and top lockout
thresholds plus temporal hysteresis (e.g., maintain
threshold crossing for </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">≥150–250 ms</code></span><span> or </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">≥5–8</code></span><span>
frames) to debounce noisy detections, and invalidate
reps that don’t meet minimum
amplitude/time-under-tension. Define end-of-set
conditions such as </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">N</code></span><span> consecutive invalid reps or a timeout </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">T</code></span><span>
without a valid cycle to gracefully terminate and
reset.</span>
</p>
</li>
</ul>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fi.redd.it%2Fhjh3mj4985lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/5u0b5LtYghZCjZ5KxJqQ8-hXavMFrDDMUfz8xNZuUyE=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fi.redd.it%252Fhjh3mj4985lf1.png/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/5u0b5LtYghZCjZ5KxJqQ8-hXavMFrDDMUfz8xNZuUyE%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw3Y5Sm2AEnPTNL0tkBgK35d">Baby in Colombia Registered as ‘Chat Yipiti,’ Name
Inspired by ChatGPT</a></strong></span><span> (</span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fwww.reddit.com%2Fr%2FChatGPT%2Fcomments%2F1mzmwri%2Fbaby_in_colombia_registered_as_chat_yipiti_name%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/4GP62MSVbUcbhgQiUD1Gtdnt62IuGf67eXbUaNGc7Ho=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fwww.reddit.com%252Fr%252FChatGPT%252Fcomments%252F1mzmwri%252Fbaby_in_colombia_registered_as_chat_yipiti_name%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/4GP62MSVbUcbhgQiUD1Gtdnt62IuGf67eXbUaNGc7Ho%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw0F0Vqgi-kLMdvhq_uQ9uxM">Score: 2097, Comments: 153</a></span><span>): </span><span><strong>A viral post claims a newborn in Cereté, Colombia was
officially registered as “Chat Yipiti,” inspired by
ChatGPT, illustrated by a hospital bassinet label in the
photo and linked coverage (</strong></span><span><strong><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fcolombiaone.com%2F2025%2F08%2F18%2Fcolombia-baby-chat-yipiti-name-chatgpt%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/f33xaTmmMI2x8MFfk6nYMjElvrGkf-egh9xuasEYWCU=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fcolombiaone.com%252F2025%252F08%252F18%252Fcolombia-baby-chat-yipiti-name-chatgpt%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/f33xaTmmMI2x8MFfk6nYMjElvrGkf-egh9xuasEYWCU%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw26USM4nnC8U1J4NbbkSOkB">Colombia One</a></strong></span><span><strong>). However, the National Civil Registry stated on
</strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2025-08-19</code></span><span><strong> that </strong></span><span><em><strong>“after consulting the databases… there is currently no
birth registration under the name ‘Chat
Yipiti’,”</strong></em></span><span><strong> contradicting the purported </strong></span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">2025-08-15</code></span><span><strong>
registration and indicating the story/image is likely
staged or unverified.</strong></span><span>
Commenters largely question authenticity and raise practical
concerns (e.g., bullying) about novelty AI-branded names;
the rest are mostly jokes/puns rather than technical
discussion.</span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:0">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span>An official statement from Colombia’s National Civil
Registry (Registraduría Nacional del Estado Civil)
reportedly says that, after querying its databases,
there is currently no birth registration under the name
“Chat Yipiti.” This directly contradicts claims the
registration occurred on </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">August 15</code></span><span>, with the registry’s note dated </span><span><code style="padding:0.25em 0.4em;background:#e5e7eb;color:#1e293b;border-radius:4px">Tuesday, August 19</code></span><span>. Absent a matching record in the civil registry
databases, the claim appears unverified and likely
misinformation until corroborated by an official
entry.</span>
</p>
</li>
</ul>
</li>
</ul>
<br>
<hr style="width:100%;border:none;border-top:1px solid #eaeaea;padding-bottom:1em;border-width:2px">
<h1 style="margin:0;padding:0;font-size:2.25em;line-height:1.44em;padding-top:0.389em;font-weight:600;text-align:left">
<span>AI Discord Recap</span>
</h1>
<blockquote style="border-left:3px solid #acb3be;color:#7e8a9a;margin-left:0;padding-left:0.8em;font-size:1.1em;font-family:-apple-system,BlinkMacSystemFont,&#39;Segoe UI&#39;,&#39;Roboto&#39;,&#39;Oxygen&#39;,&#39;Ubuntu&#39;,&#39;Cantarell&#39;,&#39;Fira Sans&#39;,&#39;Droid Sans&#39;,&#39;Helvetica Neue&#39;,sans-serif;text-align:left">
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span>A summary of Summaries of Summaries by </span><span><a href="http://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/http:%2F%2FX.ai/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/N9Ki5rUHUh2t_46NKH_hLOrXtJmB2wiAEy2e1185DzQ=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=http://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/http:%252F%252FX.ai/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/N9Ki5rUHUh2t_46NKH_hLOrXtJmB2wiAEy2e1185DzQ%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw3tVu1dEv0sDtMe9i25Wpk0">X.ai</a></span><span> Grok-4</span>
</p>
</blockquote>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Theme 1. DeepSeek V3.1 Debuts with Mixed Reviews</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>DeepSeek V3.1 Enters Arenas, Sparks Hype</strong></span><span>: </span><span><strong>DeepSeek V3.1</strong></span><span>
launched across platforms like LMArena and Cursor, scoring </span><span><strong>66</strong></span><span>
on SWE-bench in non-thinking mode but drawing criticism for
weaker creative writing and roleplay. Users noted it&#39;s
a </span><span><em>slightly worse version of Gemini 2.5 pro</em></span><span>
yet promising for coding, with pricing rising to </span><span><strong>$0.25</strong></span><span> input on </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fopenrouter.ai%2F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/OvzyOVWHYWgToun0A98ZV66zhIB3Vr4bOLzgv_g1IXo=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fopenrouter.ai%252F/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/OvzyOVWHYWgToun0A98ZV66zhIB3Vr4bOLzgv_g1IXo%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw2gZCv1AuxhTBg34CDWZ98S">OpenRouter</a></span><span> starting September 5, 2025.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>DeepSeek V3.1 Thinks Hard, Integrates Wide</strong></span><span>: The model supports </span><span><strong>Anthropic API</strong></span><span> integration for expanded use, as announced on </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2Fdeepseek_ai%2Fstatus%2F1958417062008918312/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/2vwnUX9eLV1emc_dadTwpQNAynoU7KALCxuehycyVqs=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fx.com%252Fdeepseek_ai%252Fstatus%252F1958417062008918312/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/2vwnUX9eLV1emc_dadTwpQNAynoU7KALCxuehycyVqs%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw1jP7oPVGpOQvxoQzLuMRDI">DeepSeek&#39;s X post</a></span><span>, but members in Moonshot AI called it an </span><span><em>incremental improvement</em></span><span> with regressions, per </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fhuggingface.co%2Fdeepseek-ai%2FDeepSeek-V3.1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/fmY-w57xAwI1t77DXbEfuI0VQ4s1nut9nRAxXkZQhyk=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fhuggingface.co%252Fdeepseek-ai%252FDeepSeek-V3.1/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/fmY-w57xAwI1t77DXbEfuI0VQ4s1nut9nRAxXkZQhyk%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw3gwTGbQDTP_C6OkqBT90l0">Hugging Face page</a></span><span>.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>DeepSeek V3.1 Quants and Thinking Tested</strong></span><span>: In Unsloth AI, </span><span><strong>DeepSeek V3.1</strong></span><span>
hyped for thinking skills but flagged for lacking
instruction-following in hybrid modes, with </span><span><em>hybrid models lack the instruction following and
creativity in the non-think mode</em></span><span>.</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Theme 2. ByteDance Seeds New OSS Models</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>ByteDance Drops Seed-OSS 36B Vanilla Beast</strong></span><span>: ByteDance released </span><span><strong>Seed-OSS-36B-Base-woSyn</strong></span><span>, a dense </span><span><strong>36B</strong></span><span> model with </span><span><strong>512K</strong></span><span> context trained on </span><span><strong>12T tokens</strong></span><span>
without synthetic data, exciting Unsloth AI members for
tuning, per </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fhuggingface.co%2Fmodels/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/MbkVgQPwYNH8rYW-MMyR1kmzNhBeymdp7PuZwjFaqzI=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fhuggingface.co%252Fmodels/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/MbkVgQPwYNH8rYW-MMyR1kmzNhBeymdp7PuZwjFaqzI%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw0AqS-y1JYchUTQzYDD08YT">Hugging Face model</a></span><span>.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>Seed-OSS Architecture Stumps GGUF Fans</strong></span><span>: In Nous Research AI, </span><span><strong>Seed-OSS</strong></span><span>
features custom MLP, dropout, and qkv bias but lacks GGUF
support due to unsupported </span><span><em>architectures: [&quot;SeedOssForCausalLM&quot;]</em></span><span>, sparking ASIC speculation via </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fx.com%2Fadityastomar_%2Fstatus%2F1958048129275805867/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/3oR-TNS16SoPbeH6t1dkeFirP_zsm9KvCtgN84sb2bk=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fx.com%252Fadityastomar_%252Fstatus%252F1958048129275805867/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/3oR-TNS16SoPbeH6t1dkeFirP_zsm9KvCtgN84sb2bk%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw32OytLBuCe9QNnzxXsHUbY">X post</a></span><span>.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>Seed-OSS Invites Community Tests</strong></span><span>: Latent Space highlighted </span><span><strong>Seed-OSS</strong></span><span> family on </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fgithub.com%2Forgs%2Fbytedance%2Frepositories/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_f0Xx4pf8yLRuiWn5tH0eTwrOTeSVjjDLxG27KIWbsk=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fgithub.com%252Forgs%252Fbytedance%252Frepositories/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/_f0Xx4pf8yLRuiWn5tH0eTwrOTeSVjjDLxG27KIWbsk%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw2_LetpkEXnvSopSCJweP5x">GitHub</a></span><span>
and Hugging Face, urging feedback on models, code, and
weights for open-source growth.</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Theme 3. Hardware Upgrades and Benchmarks Buzz</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>RTX 5090 Price Ignites Upgrade Wars</strong></span><span>: Unsloth AI debated </span><span><strong>RTX 5090</strong></span><span> at </span><span><strong>$2000</strong></span><span>
for VRAM perks in training, but slammed NVIDIA&#39;s
missing </span><span><strong>P2P or NVLink</strong></span><span>, while GPU MODE eyed Infiniband for </span><span><strong>4090-5090</strong></span><span> distributed setups.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>AMD Debugger Alpha Steals Spotlight</strong></span><span>: GPU MODE unveiled an alpha </span><span><strong>AMD GPU debugger</strong></span><span>
with disassembly and wave stepping, independent of </span><span><strong>amdkfd KMD</strong></span><span>, shown in </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fcdn.discordapp.com%2Fattachments%2F1233704710389764236%2F1407932291912695949%2F2025-08-21_06-20-14.mp4%3Fex=68a88f60%26is=68a73de0%26hm=6e9ca7ceed29674c6943e989940a6c8e144707797c5abd571e1cfe60d3f3210d/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/VkGAAB13MCOIULaDwlEhspyr8NTFTHXCgRfIIEv3y3g=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fcdn.discordapp.com%252Fattachments%252F1233704710389764236%252F1407932291912695949%252F2025-08-21_06-20-14.mp4%253Fex%3D68a88f60%2526is%3D68a73de0%2526hm%3D6e9ca7ceed29674c6943e989940a6c8e144707797c5abd571e1cfe60d3f3210d/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/VkGAAB13MCOIULaDwlEhspyr8NTFTHXCgRfIIEv3y3g%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw3EYXUXDuHY7UTsMoSkjJzW">video demo</a></span><span>.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>M4 Max Melts GGUF in MLX Benchmarks</strong></span><span>: LM Studio tests showed </span><span><strong>MLX GPU</strong></span><span> hitting </span><span><strong>76.6 t/s</strong></span><span> at </span><span><strong>32W</strong></span><span> versus </span><span><strong>GGUF CPU</strong></span><span> at </span><span><strong>26.2 t/s</strong></span><span> on </span><span><strong>GPT-OSS-20b</strong></span><span> with </span><span><strong>4bit quants</strong></span><span> and </span><span><strong>4k context</strong></span><span>, proving MLX&#39;s edge in efficiency.</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Theme 4. Datasets and Training Tricks Emerge</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>WildChat-4M Dataset Dedupes English Prompts</strong></span><span>: Unsloth AI released </span><span><strong>WildChat-4M-English-Semantic-<wbr>Deduplicated</strong></span><span> on </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fhuggingface.co%2Fdatasets%2FMasonMac%2FWildChat-4M-English-Semantic-Deduplicated/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/38ug1tlem7le3BXDb9KFeOCF-Nuf9j4gn8skk54hLdI=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fhuggingface.co%252Fdatasets%252FMasonMac%252FWildChat-4M-English-Semantic-Deduplicated/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/38ug1tlem7le3BXDb9KFeOCF-Nuf9j4gn8skk54hLdI%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw3TeKMCU3m6jbLc8mNfF-7B">Hugging Face</a></span><span>, filtering to </span><span><strong>&lt;=2000 tokens</strong></span><span>
with semantic methods for cleaner training data.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>GRPO Demands Step-by-Step Datasets</strong></span><span>: Unsloth AI advised splitting multi-step game datasets for </span><span><strong>GRPO</strong></span><span>, noting full PPO suits games better since GRPO works for
LLMs that </span><span><em>roughly know what to do to begin with</em></span><span>.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>Imatrix Calibration Boosts Qwen Scaling</strong></span><span>: Nous Research AI used </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fhuggingface.co%2Fdatasets%2Feaddario%2Fimatrix-calibration/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/s8KI5mefJYAwTuJAfuPR9vB8bC4R6ucRU9F_d1ZQtWE=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fhuggingface.co%252Fdatasets%252Feaddario%252Fimatrix-calibration/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/s8KI5mefJYAwTuJAfuPR9vB8bC4R6ucRU9F_d1ZQtWE%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw0lNE2noTkEHPBtE_BfF6-2">Ed Addorio&#39;s datasets</a></span><span> for importance matrices, enabling </span><span><strong>Qwen 2507</strong></span><span> to hit </span><span><strong>512k</strong></span><span>
context via RoPE scaling and minimize quantization
errors.</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span><strong>Theme 5. API Woes and Security Scares</strong></span>
</p>
<ul style="margin:0;padding:0;padding-left:1.1em;padding-bottom:1em">
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>OpenRouter Keys Leak, Cost Users $300</strong></span><span>: OpenRouter users reported </span><span><strong>$300</strong></span><span>
losses from leaked API keys, with threats using proxies to
hide IPs, and no recovery options since users bear
responsibility.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>Gemini Bans Send Users Back to 2023</strong></span><span>: OpenRouter discussed mass </span><span><strong>Gemini</strong></span><span>
bans reminiscent of AI Dungeon purges, with users lamenting </span><span><em>we&#39;re being sent back to 2023</em></span><span> and seeking alternatives.</span>
</p>
</li>
<li style="margin:0;padding:0;margin-left:1em;margin-bottom:0.3em;margin-top:0.3em;text-align:left">
<p style="margin:0;padding:0;text-align:left">
<span><strong>Command A Reasoning Tackles Enterprise Needs</strong></span><span>: Cohere launched </span><span><strong>Command A Reasoning</strong></span><span> for agentic tasks, running on single </span><span><strong>H100</strong></span><span> with </span><span><strong>128k</strong></span><span>
context, featuring token budgets for cost control, per </span><span><a href="https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%2F%2Fcohere.com%2Fblog%2Fcommand-a-reasoning/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/wKWpvnoTh82i3PE22q4uX6Yp7TmDTZOpiJNxLtYlmn4=419" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://41598e5c38d3cd55e335e985614d0883.us-east-1.resend-links.com/CL0/https:%252F%252Fcohere.com%252Fblog%252Fcommand-a-reasoning/1/01000198e4416cc5-6f44891b-ca7b-47a4-9b3c-6b40a0bdb694-000000/wKWpvnoTh82i3PE22q4uX6Yp7TmDTZOpiJNxLtYlmn4%3D419&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw2Jy58l3_Ss2zPx0QdMG44c">Cohere blog</a></span><span>.</span>
</p>
</li>
</ul>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left"></p>
<table align="center" width="100%" border="0" cellpadding="0" cellspacing="0" role="presentation" style="font-size:0.8em">
<tbody>
<tr>
<td>
<br>
<hr style="width:100%;border:none;border-top:1px solid #eaeaea;padding-bottom:1em;border-width:2px">
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span>You are receiving this email because you opted in via
our site.</span><br><br><span>Want to change how you receive these emails?</span><br><span>You can </span><span><a href="https://unsubscribe.resend.com/?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJjb250YWN0SWQiOiJmYzJkMDVlMC02OTU0LTQ3NjUtYTI4ZS1hNGViNjFmMWU3MGUiLCJhdWRpZW5jZUlkIjoiZDQzYjcyMjgtZjE4Zi00ODNjLTkwY2ItYjY2NGEzOWQ0ZjBjIiwiYnJvYWRjYXN0SWQiOiJhNTY2NDJjOC05NGJjLTRmNmUtYmMwZC02MWU4ZDc3Y2Q2YTIiLCJ0ZWFtSWQiOiJkYjI4ZmVlNy0xNWM2LTQ4NjMtYmU1Zi04NzBiMWM5ZTQ5ZTkiLCJpYXQiOjE3NTYxNzU4MzcsImV4cCI6MTc4NzcxMTgzN30.VgNBcVaNiGBVUqhpViFiWafvNX816GUN7y5R42XPxJ0" rel="noopener noreferrer nofollow" style="color:#0670db;text-decoration-line:none;text-decoration:underline;font-weight:400" target="_blank" data-saferedirecturl="https://www.google.com/url?hl=en&amp;q=https://unsubscribe.resend.com/?token%3DeyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJjb250YWN0SWQiOiJmYzJkMDVlMC02OTU0LTQ3NjUtYTI4ZS1hNGViNjFmMWU3MGUiLCJhdWRpZW5jZUlkIjoiZDQzYjcyMjgtZjE4Zi00ODNjLTkwY2ItYjY2NGEzOWQ0ZjBjIiwiYnJvYWRjYXN0SWQiOiJhNTY2NDJjOC05NGJjLTRmNmUtYmMwZC02MWU4ZDc3Y2Q2YTIiLCJ0ZWFtSWQiOiJkYjI4ZmVlNy0xNWM2LTQ4NjMtYmU1Zi04NzBiMWM5ZTQ5ZTkiLCJpYXQiOjE3NTYxNzU4MzcsImV4cCI6MTc4NzcxMTgzN30.VgNBcVaNiGBVUqhpViFiWafvNX816GUN7y5R42XPxJ0&amp;source=gmail&amp;ust=1756263078808000&amp;usg=AOvVaw3XLkXAJvK5q0lClx7xPOoJ">unsubscribe from this list</a></span><span>.</span>
</p>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left">
<span>Company Name</span><br><span>99 Street Address</span><br><span>City, STATE 000-000</span>
</p>
</td>
</tr>
</tbody>
</table>
<p style="margin:0;padding:0;font-size:1em;padding-top:0.5em;padding-bottom:0.5em;text-align:left"></p>
</td>
</tr>
</tbody>
</table>
</div>
</font></div></table></table></div></div></body>